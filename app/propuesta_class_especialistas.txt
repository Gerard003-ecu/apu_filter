"""
Motor de Física RLC Refinado con Topología Algebraica
=====================================================
Versión: 2.0 (Refinada)

Correcciones principales:
1. Maxwell discreto con complejo de de Rham
2. Laplaciano de Hodge correcto
3. Integración simpléctica
4. Entropía bayesiana corregida
5. Conservación numérica verificable
"""

from __future__ import annotations
import math
import time
import logging
from typing import Dict, List, Tuple, Optional, Any, Set, Callable
from collections import deque
from dataclasses import dataclass, field
from enum import Enum, auto
import numpy as np

# Detección de scipy
try:
    import scipy.sparse as sparse
    from scipy.sparse.linalg import eigsh, spsolve
    from scipy.special import digamma, gammaln
    from scipy.linalg import expm
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    logging.warning("SciPy no disponible - funcionalidad reducida")


# ============================================================================
# CONSTANTES Y CONFIGURACIÓN
# ============================================================================
class SystemConstants:
    """Constantes físicas y numéricas del sistema."""
    EPSILON: float = 1e-12
    MAX_WATER_HAMMER_PRESSURE: float = 1000.0
    STIFFNESS_THRESHOLD: float = 50.0
    OVERHEAT_POWER_THRESHOLD: float = 100.0
    DEFAULT_TEMPERATURE: float = 293.15  # Kelvin
    BOLTZMANN_K: float = 1.380649e-23    # J/K
    
    # Tolerancias de conservación
    ENERGY_CONSERVATION_TOL: float = 0.01   # 1%
    CHARGE_CONSERVATION_TOL: float = 0.001  # 0.1%
    
    # Límites de integración
    MIN_TIMESTEP: float = 1e-8
    MAX_TIMESTEP: float = 0.1
    MAX_NEWTON_ITERATIONS: int = 20
    NEWTON_TOLERANCE: float = 1e-10


class DampingType(Enum):
    """Tipos de amortiguamiento del circuito RLC."""
    UNDERDAMPED = auto()
    CRITICALLY_DAMPED = auto()
    OVERDAMPED = auto()
    UNDAMPED = auto()


class ConfigurationError(Exception):
    """Error de configuración de parámetros físicos."""
    pass


class NumericalInstabilityError(Exception):
    """Error de inestabilidad numérica detectada."""
    pass


# ============================================================================
# CÁLCULO VECTORIAL DISCRETO (Complejo de de Rham)
# ============================================================================
@dataclass
class DiscreteVectorCalculus:
    """
    Cálculo vectorial discreto en grafos usando el complejo de de Rham.
    
    Implementa los operadores:
    - d₀: 0-formas (nodos) → 1-formas (aristas) [gradiente discreto]
    - d₁: 1-formas (aristas) → 2-formas (caras) [rotacional discreto]
    - δ₀ = d₀ᵀ: co-diferencial [divergencia negativa]
    
    El complejo: C⁰ --d₀--> C¹ --d₁--> C²
    """
    adjacency: Dict[int, Set[int]]
    
    def __post_init__(self):
        self._build_complex()
    
    def _build_complex(self):
        """Construye matrices del complejo de cadenas."""
        # Nodos (0-celdas)
        self.nodes = sorted(self.adjacency.keys())
        self.num_nodes = len(self.nodes)
        self.node_index = {n: i for i, n in enumerate(self.nodes)}
        
        # Aristas (1-celdas) - orientación canónica: i < j
        self.edges: List[Tuple[int, int]] = []
        self.edge_index: Dict[Tuple[int, int], int] = {}
        
        for i in self.nodes:
            for j in self.adjacency.get(i, set()):
                if i < j:
                    idx = len(self.edges)
                    self.edges.append((i, j))
                    self.edge_index[(i, j)] = idx
        
        self.num_edges = len(self.edges)
        
        # Lista de incidencia para iteración eficiente
        self.incidence = [
            (idx, self.node_index[i], self.node_index[j]) 
            for idx, (i, j) in enumerate(self.edges)
        ]
        
        # Detectar caras (2-celdas) como ciclos mínimos (triángulos)
        self._detect_faces()
        
        # Construir matrices de operadores
        self._build_operators()
    
    def _detect_faces(self):
        """Detecta caras (triángulos) en el grafo."""
        self.faces: List[Tuple[int, int, int]] = []
        self.face_index: Dict[Tuple[int, int, int], int] = {}
        
        # Buscar triángulos: para cada arista (i,j), buscar k tal que
        # i-k y j-k también sean aristas
        for i in self.nodes:
            neighbors_i = self.adjacency.get(i, set())
            for j in neighbors_i:
                if j > i:
                    neighbors_j = self.adjacency.get(j, set())
                    # Vértices comunes forman triángulos
                    common = neighbors_i & neighbors_j
                    for k in common:
                        if k > j:
                            # Triángulo (i, j, k) con i < j < k
                            face = (i, j, k)
                            if face not in self.face_index:
                                idx = len(self.faces)
                                self.faces.append(face)
                                self.face_index[face] = idx
        
        self.num_faces = len(self.faces)
    
    def _build_operators(self):
        """Construye matrices de operadores diferenciales."""
        # d₀: Operador de co-borde 0 → 1 (gradiente discreto)
        # (d₀ φ)_e = φ(j) - φ(i) para arista e = (i,j)
        if SCIPY_AVAILABLE:
            row, col, data = [], [], []
            for edge_idx, (i, j) in enumerate(self.edges):
                ni, nj = self.node_index[i], self.node_index[j]
                row.extend([edge_idx, edge_idx])
                col.extend([ni, nj])
                data.extend([-1.0, 1.0])
            
            self.d0 = sparse.csr_matrix(
                (data, (row, col)),
                shape=(self.num_edges, self.num_nodes)
            )
            
            # d₁: Operador de co-borde 1 → 2 (rotacional discreto)
            if self.num_faces > 0:
                row, col, data = [], [], []
                for face_idx, (i, j, k) in enumerate(self.faces):
                    # Orientación del borde: (i,j) + (j,k) - (i,k)
                    edges_in_face = [
                        ((i, j), 1),
                        ((j, k), 1),
                        ((i, k), -1)
                    ]
                    for (a, b), sign in edges_in_face:
                        edge_key = (min(a, b), max(a, b))
                        if edge_key in self.edge_index:
                            edge_idx = self.edge_index[edge_key]
                            # Ajustar signo según orientación
                            actual_sign = sign if a < b else -sign
                            row.append(face_idx)
                            col.append(edge_idx)
                            data.append(float(actual_sign))
                
                self.d1 = sparse.csr_matrix(
                    (data, (row, col)),
                    shape=(self.num_faces, self.num_edges)
                )
            else:
                self.d1 = sparse.csr_matrix((0, self.num_edges))
            
            # Laplaciano de Hodge: Δ₀ = d₀ᵀ d₀
            self.laplacian_0 = self.d0.T @ self.d0
            
            # Laplaciano de aristas: Δ₁ = d₀ d₀ᵀ + d₁ᵀ d₁
            self.laplacian_1 = self.d0 @ self.d0.T
            if self.num_faces > 0:
                self.laplacian_1 += self.d1.T @ self.d1
        else:
            # Versión sin scipy - arrays densos
            self.d0 = np.zeros((self.num_edges, self.num_nodes))
            for edge_idx, (i, j) in enumerate(self.edges):
                self.d0[edge_idx, self.node_index[i]] = -1.0
                self.d0[edge_idx, self.node_index[j]] = 1.0
            
            self.laplacian_0 = self.d0.T @ self.d0
    
    def gradient(self, phi: np.ndarray) -> np.ndarray:
        """Gradiente discreto: 0-forma → 1-forma."""
        if SCIPY_AVAILABLE:
            return self.d0 @ phi
        return self.d0 @ phi
    
    def divergence(self, psi: np.ndarray) -> np.ndarray:
        """Divergencia discreta: 1-forma → 0-forma (negativo del adjunto)."""
        if SCIPY_AVAILABLE:
            return -self.d0.T @ psi
        return -self.d0.T @ psi
    
    def curl_edge_to_face(self, E: np.ndarray) -> np.ndarray:
        """Rotacional discreto: 1-forma → 2-forma."""
        if SCIPY_AVAILABLE and self.num_faces > 0:
            return self.d1 @ E
        return np.zeros(self.num_faces)


# ============================================================================
# SOLVER DE MAXWELL DISCRETO
# ============================================================================
class MaxwellSolver:
    """
    Solver de ecuaciones de Maxwell en grafos usando formas diferenciales discretas.
    
    Formulación:
    - E ∈ C¹ (1-forma en aristas): campo eléctrico
    - B ∈ C² (2-forma en caras): campo magnético
    - ρ ∈ C⁰ (0-forma en nodos): densidad de carga
    - J ∈ C¹ (1-forma en aristas): densidad de corriente
    
    Ecuaciones:
    - Ley de Faraday: ∂B/∂t = -d₁E (rotacional)
    - Ley de Ampère-Maxwell: ε∂E/∂t = δ₁B - J + σE
    
    Nota: En grafos sin 2-celdas, B vive en nodos como aproximación.
    """
    
    def __init__(self, vector_calc: DiscreteVectorCalculus,
                 permittivity: float = 1.0,
                 permeability: float = 1.0,
                 electric_conductivity: float = 0.0):
        
        self.vc = vector_calc
        self.epsilon = max(permittivity, SystemConstants.EPSILON)
        self.mu = max(permeability, SystemConstants.EPSILON)
        self.sigma = max(0.0, electric_conductivity)
        
        # Velocidad de propagación
        self.c = 1.0 / math.sqrt(self.epsilon * self.mu)
        
        # Campos electromagnéticos
        self.E = np.zeros(self.vc.num_edges)  # 1-forma
        
        # B en caras si existen, sino aproximación en nodos
        if self.vc.num_faces > 0:
            self.B = np.zeros(self.vc.num_faces)  # 2-forma
            self._use_face_B = True
        else:
            self.B = np.zeros(self.vc.num_nodes)  # Aproximación 0-forma
            self._use_face_B = False
        
        # Fuentes
        self.J_e = np.zeros(self.vc.num_edges)  # Corriente en aristas
        self.rho = np.zeros(self.vc.num_nodes)  # Carga en nodos
        
        # Historial para análisis
        self._energy_history: deque = deque(maxlen=100)
        
    def step_faraday(self, dt: float):
        """
        Ley de Faraday discreta: ∂B/∂t = -d₁E
        Evoluciona B usando el rotacional de E.
        """
        if self._use_face_B and self.vc.num_faces > 0:
            # Rotacional propio: B en caras
            curl_E = self.vc.curl_edge_to_face(self.E)
            self.B -= curl_E * dt / self.mu
        else:
            # Aproximación: B en nodos, usar divergencia del dual
            # ∂B/∂t ≈ -δ₀(★E) donde ★ es el Hodge discreto
            div_E = np.zeros(self.vc.num_nodes)
            for edge_idx, ni, nj in self.vc.incidence:
                contribution = self.E[edge_idx]
                div_E[ni] -= contribution
                div_E[nj] += contribution
            
            self.B -= div_E * dt / self.mu
    
    def step_ampere_maxwell(self, dt: float):
        """
        Ley de Ampère-Maxwell discreta: ε∂E/∂t = curl(B)/μ - J - σE
        """
        # Término de corriente de desplazamiento
        dE_dt = np.zeros(self.vc.num_edges)
        
        if self._use_face_B and SCIPY_AVAILABLE:
            # δ₁B = d₁ᵀB (adjunto del rotacional)
            curl_B = self.vc.d1.T @ self.B
            dE_dt += curl_B / self.mu
        else:
            # Aproximación usando gradiente de B
            for edge_idx, ni, nj in self.vc.incidence:
                grad_B = (self.B[nj] - self.B[ni]) / self.mu
                dE_dt[edge_idx] += grad_B
        
        # Corriente libre
        dE_dt -= self.J_e
        
        # Actualizar E
        self.E += dE_dt * dt / self.epsilon
        
        # Disipación óhmica (implícita para estabilidad)
        if self.sigma > 0:
            decay_factor = math.exp(-self.sigma * dt / self.epsilon)
            self.E *= decay_factor
    
    def step(self, dt: float):
        """Paso de tiempo completo (Leapfrog/Yee para estabilidad)."""
        # Medio paso de B
        self.step_faraday(0.5 * dt)
        # Paso completo de E
        self.step_ampere_maxwell(dt)
        # Medio paso de B
        self.step_faraday(0.5 * dt)
    
    def compute_energy(self) -> Dict[str, float]:
        """
        Calcula la energía electromagnética.
        U = (1/2)ε∫E² + (1/2μ)∫B²
        """
        energy_E = 0.5 * self.epsilon * np.sum(self.E**2)
        energy_B = 0.5 * np.sum(self.B**2) / self.mu
        total = energy_E + energy_B
        
        # Flujo de Poynting aproximado S = E × H
        poynting = np.zeros(self.vc.num_edges)
        if not self._use_face_B:
            for edge_idx, ni, nj in self.vc.incidence:
                H_avg = 0.5 * (self.B[ni] + self.B[nj]) / self.mu
                poynting[edge_idx] = self.E[edge_idx] * H_avg
        
        self._energy_history.append(total)
        
        return {
            "total_energy": float(total),
            "electric_energy": float(energy_E),
            "magnetic_energy": float(energy_B),
            "energy_ratio_EB": float(energy_E / max(energy_B, 1e-12)),
            "poynting_mean": float(np.mean(poynting)),
            "poynting_max": float(np.max(np.abs(poynting))) if len(poynting) > 0 else 0.0,
            "field_E_rms": float(np.sqrt(np.mean(self.E**2))),
            "field_B_rms": float(np.sqrt(np.mean(self.B**2)))
        }
    
    def check_gauss_law(self) -> float:
        """Verifica ley de Gauss: div(E) = ρ/ε (devuelve residuo)."""
        div_E = self.vc.divergence(self.E)
        expected = self.rho / self.epsilon
        residual = np.linalg.norm(div_E - expected)
        return float(residual)


# ============================================================================
# CONTROLADOR PORT-HAMILTONIANO
# ============================================================================
class PortHamiltonianController:
    """
    Controlador basado en sistemas Port-Hamiltonianos con disipación.
    
    Estructura: ẋ = (J - R)∇H(x) + g(x)u
                y = gᵀ(x)∇H(x)
    
    donde:
    - J: matriz antisimétrica (estructura)
    - R: matriz simétrica semidefinida positiva (disipación)
    - H: Hamiltoniano (energía)
    - g: matriz de entrada
    - u: control
    """
    
    def __init__(self, maxwell_solver: MaxwellSolver,
                 kp: float = 1.0,
                 ki: float = 0.1,
                 kd: float = 0.1,
                 target_energy: float = 1.0):
        
        self.solver = maxwell_solver
        self.kp = max(0.0, kp)  # Proporcional
        self.ki = max(0.0, ki)  # Integral
        self.kd = max(0.0, kd)  # Derivativo
        self.target_energy = max(0.0, target_energy)
        
        # Estados internos del controlador
        self._error_integral = 0.0
        self._prev_error = 0.0
        self._prev_time = time.time()
        
        # Límites anti-windup
        self._integral_limit = 10.0
        self._control_limit = 100.0
        
        # Parámetros de suavizado
        self._alpha_filter = 0.8  # Filtro exponencial para derivada
        self._filtered_derivative = 0.0
    
    def compute_error(self) -> Tuple[float, Dict[str, float]]:
        """Calcula error de energía respecto al objetivo."""
        energy_data = self.solver.compute_energy()
        current_energy = energy_data["total_energy"]
        error = self.target_energy - current_energy
        
        return error, energy_data
    
    def apply_control(self, dt: float) -> np.ndarray:
        """
        Aplica control PID con estructura port-Hamiltoniana.
        
        Returns:
            Vector de control para cada arista
        """
        if dt < SystemConstants.MIN_TIMESTEP:
            dt = SystemConstants.MIN_TIMESTEP
        
        # Calcular error
        error, energy_data = self.compute_error()
        
        # Término proporcional
        P = self.kp * error
        
        # Término integral con anti-windup
        self._error_integral += error * dt
        self._error_integral = np.clip(
            self._error_integral,
            -self._integral_limit,
            self._integral_limit
        )
        I = self.ki * self._error_integral
        
        # Término derivativo con filtrado
        raw_derivative = (error - self._prev_error) / dt
        self._filtered_derivative = (
            self._alpha_filter * self._filtered_derivative +
            (1 - self._alpha_filter) * raw_derivative
        )
        D = self.kd * self._filtered_derivative
        
        # Control total
        control_scalar = P + I + D
        control_scalar = np.clip(control_scalar, -self._control_limit, self._control_limit)
        
        # Distribuir control según gradiente de energía (estructura simpléctica)
        E_field = self.solver.E
        E_norm = np.linalg.norm(E_field)
        
        if E_norm > SystemConstants.EPSILON:
            # Dirección del gradiente de energía
            direction = E_field / E_norm
            # Control inyecta/extrae energía proporcionalmente
            u = control_scalar * direction
        else:
            # Sin campo, distribución uniforme
            u = np.full(self.solver.vc.num_edges, control_scalar / max(1, self.solver.vc.num_edges))
        
        # Actualizar estado
        self._prev_error = error
        
        return u
    
    def get_control_state(self) -> Dict[str, float]:
        """Retorna estado interno del controlador."""
        return {
            "error": self._prev_error,
            "error_integral": self._error_integral,
            "filtered_derivative": self._filtered_derivative,
            "target_energy": self.target_energy
        }
    
    def reset(self):
        """Reinicia el estado del controlador."""
        self._error_integral = 0.0
        self._prev_error = 0.0
        self._filtered_derivative = 0.0


# ============================================================================
# ANALIZADOR TOPOLÓGICO
# ============================================================================
class TopologicalAnalyzer:
    """
    Analizador de topología algebraica para grafos de correlación.
    
    Calcula:
    - Números de Betti (β₀: componentes, β₁: ciclos independientes)
    - Característica de Euler: χ = β₀ - β₁
    - Homología persistente (básica)
    
    Usa el método espectral cuando está disponible scipy.
    """

    def __init__(self):
        self._adjacency_list: Dict[int, Set[int]] = {}
        self._vertex_count: int = 0
        self._edge_count: int = 0
        self._distance_matrix: Optional[np.ndarray] = None
        self._metric_labels: List[str] = []
        
        # Cache de resultados
        self._betti_cache: Optional[Dict[int, int]] = None
        self._laplacian_eigenvalues: Optional[np.ndarray] = None

    def _robust_normalize(self, values: List[float]) -> Tuple[np.ndarray, float, float]:
        """
        Normalización robusta al rango [0, 1] con manejo de outliers.
        Usa normalización por rango intercuartil si hay outliers.
        """
        if not values:
            return np.array([]), 0.0, 1.0
        
        arr = np.array(values, dtype=np.float64)
        
        # Detectar caso degenerado
        v_range = np.ptp(arr)
        if v_range < SystemConstants.EPSILON:
            return np.full_like(arr, 0.5), float(arr[0]), float(arr[0])
        
        # Verificar outliers usando IQR
        q1, q3 = np.percentile(arr, [25, 75])
        iqr = q3 - q1
        
        if iqr > SystemConstants.EPSILON:
            # Hay variabilidad, usar normalización robusta
            lower = q1 - 1.5 * iqr
            upper = q3 + 1.5 * iqr
            # Winsorización suave
            arr_clipped = np.clip(arr, lower, upper)
            v_min, v_max = arr_clipped.min(), arr_clipped.max()
        else:
            v_min, v_max = arr.min(), arr.max()
        
        # Normalización min-max
        if abs(v_max - v_min) < SystemConstants.EPSILON:
            normalized = np.full_like(arr, 0.5)
        else:
            normalized = (arr - v_min) / (v_max - v_min)
        
        return normalized, float(v_min), float(v_max)

    def _compute_similarity_matrix(self, normalized: np.ndarray) -> np.ndarray:
        """
        Matriz de similitud usando kernel gaussiano.
        
        sim(i,j) = exp(-|xᵢ - xⱼ|² / (2σ²))
        
        Más robusto que distancia coseno para valores escalares.
        """
        n = len(normalized)
        if n < 2:
            return np.zeros((0, 0))
        
        # Calcular distancias al cuadrado
        diff = normalized.reshape(-1, 1) - normalized.reshape(1, -1)
        dist_sq = diff ** 2
        
        # Ancho de banda adaptativo (regla de Silverman)
        std = np.std(normalized)
        bandwidth = 1.06 * std * (n ** (-0.2)) if std > 0 else 1.0
        
        # Kernel gaussiano
        similarity = np.exp(-dist_sq / (2 * bandwidth**2))
        
        return similarity

    def build_metric_graph(self, metrics: Dict[str, float],
                          threshold_strategy: str = "adaptive") -> None:
        """
        Construye grafo de correlación desde métricas del sistema.
        
        Args:
            metrics: Diccionario de métricas
            threshold_strategy: "fixed", "adaptive" o "percentile"
        """
        # Métricas de interés (orden consistente)
        metric_keys = [
            "saturation", "complexity", "current_I",
            "potential_energy", "kinetic_energy", "entropy_shannon"
        ]
        
        # Extraer valores válidos
        values = []
        self._metric_labels = []
        for k in metric_keys:
            if k in metrics and np.isfinite(metrics[k]):
                values.append(float(metrics[k]))
                self._metric_labels.append(k)
        
        self._vertex_count = len(values)
        self._edge_count = 0
        self._adjacency_list = {i: set() for i in range(self._vertex_count)}
        self._betti_cache = None  # Invalidar cache
        
        if self._vertex_count < 2:
            self._distance_matrix = None
            return
        
        # Normalización robusta
        normalized, _, _ = self._robust_normalize(values)
        
        # Matriz de similitud
        similarity = self._compute_similarity_matrix(normalized)
        self._distance_matrix = 1.0 - similarity  # Convertir a distancia
        
        # Determinar umbral
        threshold = self._compute_threshold(similarity, threshold_strategy)
        
        # Construir grafo
        for i in range(self._vertex_count):
            for j in range(i + 1, self._vertex_count):
                if similarity[i, j] > threshold:
                    self._adjacency_list[i].add(j)
                    self._adjacency_list[j].add(i)
                    self._edge_count += 1

    def _compute_threshold(self, similarity: np.ndarray, 
                          strategy: str) -> float:
        """Calcula umbral para conectividad del grafo."""
        if strategy == "fixed":
            return 0.5
        
        # Extraer valores del triángulo superior (sin diagonal)
        upper_tri = similarity[np.triu_indices_from(similarity, k=1)]
        
        if len(upper_tri) == 0:
            return 0.5
        
        if strategy == "percentile":
            # Conectar el 30% de las aristas más fuertes
            return float(np.percentile(upper_tri, 70))
        
        # Estrategia adaptativa
        mean_sim = np.mean(upper_tri)
        std_sim = np.std(upper_tri)
        
        # Umbral basado en estadísticas
        adaptive = mean_sim + 0.5 * std_sim
        
        # Limitar a rango razonable
        return float(np.clip(adaptive, 0.3, 0.8))

    def _compute_laplacian_eigenvalues(self) -> np.ndarray:
        """Calcula valores propios del Laplaciano del grafo."""
        if self._vertex_count == 0:
            return np.array([])
        
        # Construir Laplaciano L = D - A
        L = np.zeros((self._vertex_count, self._vertex_count))
        
        for i in range(self._vertex_count):
            degree = len(self._adjacency_list.get(i, set()))
            L[i, i] = degree
            for j in self._adjacency_list.get(i, set()):
                L[i, j] = -1.0
        
        # Calcular valores propios
        try:
            eigenvalues = np.linalg.eigvalsh(L)
            # Ordenar y manejar errores numéricos
            eigenvalues = np.sort(np.real(eigenvalues))
            eigenvalues[eigenvalues < SystemConstants.EPSILON] = 0.0
        except np.linalg.LinAlgError:
            eigenvalues = np.zeros(self._vertex_count)
        
        self._laplacian_eigenvalues = eigenvalues
        return eigenvalues

    def compute_betti_numbers(self) -> Dict[int, int]:
        """
        Calcula números de Betti usando múltiples métodos.
        
        β₀ = dim(ker(L)) = multiplicidad del valor propio 0
        β₁ = |E| - |V| + β₀ (fórmula de Euler para grafos)
        """
        if self._betti_cache is not None:
            return self._betti_cache
        
        if self._vertex_count == 0:
            self._betti_cache = {0: 0, 1: 0}
            return self._betti_cache
        
        # Método espectral para β₀
        eigenvalues = self._compute_laplacian_eigenvalues()
        
        # β₀ = número de valores propios cero
        tolerance = 1e-8
        beta_0 = int(np.sum(np.abs(eigenvalues) < tolerance))
        
        # Verificar con BFS
        beta_0_bfs = self._count_components_bfs()
        
        # Usar el valor más robusto
        if beta_0 != beta_0_bfs:
            # Preferir BFS si hay discrepancia
            beta_0 = beta_0_bfs
        
        # β₁ usando característica de Euler
        # χ = V - E + F, para grafos planares F=1 (cara externa)
        # β₀ - β₁ + β₂ = χ, con β₂ = 0 para grafos
        # → β₁ = E - V + β₀
        beta_1 = max(0, self._edge_count - self._vertex_count + beta_0)
        
        self._betti_cache = {0: beta_0, 1: beta_1}
        return self._betti_cache

    def _count_components_bfs(self) -> int:
        """Cuenta componentes conexas usando BFS."""
        visited = set()
        components = 0
        
        for start in range(self._vertex_count):
            if start not in visited:
                components += 1
                queue = deque([start])
                
                while queue:
                    node = queue.popleft()
                    if node not in visited:
                        visited.add(node)
                        for neighbor in self._adjacency_list.get(node, set()):
                            if neighbor not in visited:
                                queue.append(neighbor)
        
        return components

    def get_spectral_gap(self) -> float:
        """
        Retorna el gap espectral (λ₂ - λ₁ = λ₂ para grafos conexos).
        Indica la robustez de la conectividad.
        """
        if self._laplacian_eigenvalues is None:
            self._compute_laplacian_eigenvalues()
        
        eigenvalues = self._laplacian_eigenvalues
        if len(eigenvalues) < 2:
            return 0.0
        
        # Segundo valor propio más pequeño (Fiedler value)
        # El primero es 0 para cualquier grafo
        return float(eigenvalues[1])

    def compute_euler_characteristic(self) -> int:
        """Característica de Euler: χ = V - E (para grafos sin caras)."""
        return self._vertex_count - self._edge_count

    def get_graph_statistics(self) -> Dict[str, Any]:
        """Estadísticas completas del grafo."""
        betti = self.compute_betti_numbers()
        
        # Grados de vértices
        degrees = [len(self._adjacency_list.get(i, set())) 
                  for i in range(self._vertex_count)]
        
        if degrees:
            avg_degree = np.mean(degrees)
            max_degree = max(degrees)
            degree_variance = np.var(degrees)
        else:
            avg_degree = max_degree = degree_variance = 0.0
        
        # Densidad del grafo
        max_edges = self._vertex_count * (self._vertex_count - 1) / 2
        density = self._edge_count / max_edges if max_edges > 0 else 0.0
        
        return {
            "vertices": self._vertex_count,
            "edges": self._edge_count,
            "betti_0": betti[0],
            "betti_1": betti[1],
            "euler_characteristic": self.compute_euler_characteristic(),
            "spectral_gap": self.get_spectral_gap(),
            "density": float(density),
            "average_degree": float(avg_degree),
            "max_degree": int(max_degree),
            "degree_variance": float(degree_variance),
            "metric_labels": self._metric_labels
        }


# ============================================================================
# CALCULADORA DE ENTROPÍA
# ============================================================================
class EntropyCalculator:
    """
    Calculadora de entropía con estimadores bayesianos y espectro de Rényi.
    
    Implementa:
    - Entropía de Shannon clásica y bayesiana
    - Corrección de Miller-Madow para sesgo
    - Espectro de Rényi para α ∈ [0, ∞)
    - Entropía de Tsallis
    - Divergencia KL
    """

    def __init__(self, cache_size: int = 128):
        self._cache: Dict[Tuple, Dict[str, float]] = {}
        self._cache_size = cache_size

    def _nsl_correction(self, n: int, k: int) -> float:
        """
        Corrección de Nemenman-Shafee-Bialek para entropía.
        Aproximación de la entropía esperada bajo prior uniforme.
        """
        if n <= 0 or k <= 0:
            return 0.0
        
        # Corrección de Miller-Madow
        miller_madow = (k - 1) / (2 * n)
        
        return miller_madow

    def calculate_shannon(self, counts: Dict[str, int],
                         correction: str = "miller") -> Dict[str, float]:
        """
        Entropía de Shannon con corrección de sesgo.
        
        Args:
            counts: Diccionario de conteos por categoría
            correction: "none", "miller", o "bayesian"
        """
        total = sum(counts.values())
        k = len([c for c in counts.values() if c > 0])
        
        if total == 0 or k == 0:
            return {
                "entropy": 0.0,
                "entropy_bits": 0.0,
                "max_entropy": 0.0,
                "normalized": 0.0
            }
        
        # Probabilidades empíricas
        probs = np.array([c/total for c in counts.values() if c > 0])
        
        # Entropía en nats
        entropy_nats = -np.sum(probs * np.log(probs + SystemConstants.EPSILON))
        
        # Corrección
        if correction == "miller":
            bias = self._nsl_correction(total, k)
            entropy_nats += bias
        elif correction == "bayesian":
            # Prior de Jeffreys: agregar 0.5 a cada conteo
            pseudo_counts = np.array([c + 0.5 for c in counts.values()])
            pseudo_total = pseudo_counts.sum()
            probs_bayes = pseudo_counts / pseudo_total
            entropy_nats = -np.sum(probs_bayes * np.log(probs_bayes))
        
        # Convertir a bits
        entropy_bits = entropy_nats / np.log(2)
        
        # Entropía máxima (distribución uniforme)
        max_entropy = np.log2(k) if k > 0 else 0.0
        
        # Normalizada (relativa a la máxima)
        normalized = entropy_bits / max_entropy if max_entropy > 0 else 0.0
        
        return {
            "entropy": float(entropy_nats),
            "entropy_bits": float(entropy_bits),
            "max_entropy": float(max_entropy),
            "normalized": float(min(1.0, normalized)),
            "effective_categories": int(k),
            "total_samples": int(total)
        }

    def calculate_bayesian(self, counts: Dict[str, int],
                          prior: str = "jeffreys") -> Dict[str, float]:
        """
        Entropía bayesiana con estimación de incertidumbre.
        
        Usa posterior Dirichlet para calcular:
        - Entropía esperada E[H|data]
        - Varianza Var[H|data]
        - Intervalo creíble
        """
        total = sum(counts.values())
        k = len(counts)
        
        if total == 0 or k == 0:
            return {
                "entropy_expected": 0.0,
                "entropy_variance": 0.0,
                "credible_interval": (0.0, 0.0)
            }
        
        # Selección de hiperparámetro alpha del prior Dirichlet
        prior_alphas = {
            "jeffreys": 0.5,      # Jeffreys (no informativo)
            "laplace": 1.0,       # Laplace (uniforme)
            "perks": 1.0 / k,     # Perks
            "minimax": math.sqrt(total) / k,  # Minimax
            "bdi": 1.0 / k        # BDI/BDeu
        }
        alpha = prior_alphas.get(prior, 0.5)
        
        # Parámetros posteriores
        alpha_post = np.array([alpha + counts.get(cat, 0) for cat in counts])
        alpha_0 = alpha_post.sum()
        
        # Entropía esperada usando digamma
        if SCIPY_AVAILABLE:
            # E[H] = ψ(α₀+1) - Σᵢ (αᵢ/α₀) ψ(αᵢ+1)
            expected = digamma(alpha_0 + 1)
            for alpha_i in alpha_post:
                if alpha_i > 0:
                    expected -= (alpha_i / alpha_0) * digamma(alpha_i + 1)
        else:
            # Aproximación asintótica
            expected = np.log(alpha_0) - np.sum(
                (alpha_post / alpha_0) * np.log(alpha_post + 0.5)
            )
        
        # Varianza (aproximación)
        # Var[H] ≈ Σᵢ (αᵢ/α₀²) [ψ'(αᵢ+1) - ψ'(α₀+1)]
        # Aproximación simple: 1/(α₀ * ln(2)²)
        variance = 1.0 / (alpha_0 * (np.log(2)**2)) if alpha_0 > k else 0.0
        
        # Intervalo creíble (95%)
        std = math.sqrt(max(0, variance))
        ci_low = max(0, expected - 1.96 * std)
        ci_high = expected + 1.96 * std
        
        return {
            "entropy_expected": float(expected) / np.log(2),  # En bits
            "entropy_variance": float(variance),
            "credible_interval": (float(ci_low), float(ci_high)),
            "effective_sample_size": float(alpha_0),
            "prior": prior
        }

    def calculate_renyi(self, probabilities: np.ndarray,
                       alpha: float) -> float:
        """
        Entropía de Rényi de orden α.
        
        H_α(P) = (1/(1-α)) log(Σᵢ pᵢ^α)
        
        Casos especiales:
        - α → 0: log(|support|) (Hartley)
        - α → 1: Shannon
        - α → ∞: -log(max p) (min-entropy)
        """
        probs = probabilities[probabilities > SystemConstants.EPSILON]
        
        if len(probs) == 0:
            return 0.0
        
        if alpha == 0:
            return math.log2(len(probs))
        
        if abs(alpha - 1.0) < 1e-10:
            # Límite de Shannon
            return float(-np.sum(probs * np.log2(probs)))
        
        if alpha == float('inf') or alpha > 100:
            return float(-math.log2(np.max(probs)))
        
        # Caso general
        power_sum = np.sum(probs ** alpha)
        if power_sum <= 0:
            return 0.0
        
        return float((1.0 / (1 - alpha)) * math.log2(power_sum))

    def calculate_renyi_spectrum(self, probabilities: np.ndarray,
                                alphas: Optional[List[float]] = None) -> Dict[str, float]:
        """
        Calcula espectro completo de Rényi.
        """
        if alphas is None:
            alphas = [0, 0.5, 1.0, 2.0, 3.0, 5.0, 10.0]
        
        spectrum = {}
        for alpha in alphas:
            key = f"H_{alpha}" if alpha != float('inf') else "H_inf"
            spectrum[key] = self.calculate_renyi(probabilities, alpha)
        
        return spectrum

    def calculate_tsallis(self, probabilities: np.ndarray, q: float = 2.0) -> float:
        """
        Entropía de Tsallis de orden q.
        
        S_q(P) = (1 - Σᵢ pᵢ^q) / (q - 1)
        
        Converge a Shannon cuando q → 1.
        """
        probs = probabilities[probabilities > SystemConstants.EPSILON]
        
        if len(probs) == 0:
            return 0.0
        
        if abs(q - 1.0) < 1e-10:
            # Límite de Shannon
            return float(-np.sum(probs * np.log(probs)))
        
        power_sum = np.sum(probs ** q)
        return float((1.0 - power_sum) / (q - 1))

    def calculate_kl_divergence(self, p: np.ndarray, q: np.ndarray) -> float:
        """
        Divergencia de Kullback-Leibler: D_KL(P||Q).
        
        D_KL(P||Q) = Σᵢ pᵢ log(pᵢ/qᵢ)
        """
        # Normalizar
        p = p / (np.sum(p) + SystemConstants.EPSILON)
        q = q / (np.sum(q) + SystemConstants.EPSILON)
        
        # Evitar log(0) y división por cero
        mask = (p > SystemConstants.EPSILON) & (q > SystemConstants.EPSILON)
        
        if not np.any(mask):
            return 0.0
        
        kl = np.sum(p[mask] * np.log(p[mask] / q[mask]))
        
        return float(max(0.0, kl))


# ============================================================================
# ESTADO FÍSICO UNIFICADO
# ============================================================================
class UnifiedPhysicalState:
    """
    Estado físico unificado con integración simpléctica.
    
    Variables de estado (extensivas):
    - Q: carga eléctrica [C]
    - Φ: flujo magnético concatenado [Wb]
    - S: entropía [J/K]
    - L: momento angular [kg·m²/s]
    
    Variables conjugadas (intensivas):
    - V = Q/C: voltaje [V]
    - I = Φ/L: corriente [A]
    - T: temperatura [K]
    - ω: velocidad angular [rad/s]
    """

    def __init__(self, capacitance: float = 1.0,
                 inductance: float = 1.0,
                 resistance: float = 1.0,
                 temperature: float = 293.15):
        
        # Validar parámetros
        if capacitance <= 0:
            raise ConfigurationError(f"Capacitancia debe ser positiva: {capacitance}")
        if inductance <= 0:
            raise ConfigurationError(f"Inductancia debe ser positiva: {inductance}")
        if resistance < 0:
            raise ConfigurationError(f"Resistencia no puede ser negativa: {resistance}")
        if temperature <= 0:
            raise ConfigurationError(f"Temperatura debe ser positiva: {temperature}")
        
        # Parámetros del sistema
        self.C = float(capacitance)
        self.L = float(inductance)
        self.R = float(resistance)
        
        # Variables de estado
        self.charge: float = 0.0           # Q [C]
        self.flux_linkage: float = 0.0     # Φ = L·I [Wb]
        self.entropy: float = 0.0          # S [J/K]
        self.temperature: float = float(temperature)  # T [K]
        
        # Estado mecánico (para analogía giroscópica)
        self.angular_momentum = np.zeros(3, dtype=np.float64)  # L [kg·m²/s]
        self.angular_velocity = np.zeros(3, dtype=np.float64)  # ω [rad/s]
        self.inertia_tensor = np.eye(3, dtype=np.float64)      # I [kg·m²]
        
        # Historial para conservación
        self._hamiltonian_history: deque = deque(maxlen=100)
        self._charge_history: deque = deque(maxlen=100)

    @property
    def current(self) -> float:
        """Corriente eléctrica I = Φ/L [A]."""
        return self.flux_linkage / self.L if self.L > 0 else 0.0
    
    @current.setter
    def current(self, I: float):
        """Establece corriente actualizando el flujo."""
        self.flux_linkage = I * self.L

    @property
    def voltage(self) -> float:
        """Voltaje V = Q/C [V]."""
        return self.charge / self.C if self.C > 0 else 0.0

    def compute_hamiltonian(self) -> float:
        """
        Hamiltoniano total del sistema.
        
        H = H_elec + H_mag + H_mech
        H = Q²/(2C) + Φ²/(2L) + (1/2)ω·I·ω
        
        No incluye términos disipativos (R) que violarían conservación.
        """
        # Energía eléctrica (capacitor)
        H_elec = 0.5 * self.charge**2 / self.C
        
        # Energía magnética (inductor)
        H_mag = 0.5 * self.flux_linkage**2 / self.L
        
        # Energía mecánica rotacional
        H_mech = 0.5 * np.dot(self.angular_momentum, self.angular_velocity)
        
        total = H_elec + H_mag + H_mech
        
        # Registrar para verificación
        self._hamiltonian_history.append(total)
        self._charge_history.append(self.charge)
        
        return total

    def compute_dissipation_rate(self) -> float:
        """
        Tasa de disipación de potencia.
        P_diss = R·I² [W]
        """
        return self.R * self.current**2

    def evolve_thermal(self, dt: float, ambient_temp: float = 293.15):
        """
        Evolución termodinámica del sistema.
        
        Producción de entropía por efecto Joule:
        dS/dt = R·I²/T
        
        Enfriamiento por conducción (ley de Newton):
        dT/dt = -k(T - T_amb)/C_th
        """
        I = self.current
        
        # Producción de entropía por disipación
        if self.R > 0 and self.temperature > 0:
            power_diss = self.R * I**2
            entropy_production = power_diss / self.temperature
            self.entropy += entropy_production * dt
        
        # Enfriamiento (asumiendo capacidad térmica proporcional a L)
        thermal_conductance = 0.1  # [W/K]
        thermal_capacity = self.L * 1000  # Aproximación [J/K]
        
        if thermal_capacity > 0:
            dT_dt = -thermal_conductance * (self.temperature - ambient_temp) / thermal_capacity
            # También calentar por disipación
            if self.R > 0:
                dT_dt += self.R * I**2 / thermal_capacity
            
            self.temperature += dT_dt * dt
            self.temperature = max(10.0, self.temperature)  # Mínimo físico

    def check_conservation(self, tolerance: float = 0.01) -> Dict[str, Any]:
        """Verifica conservación de energía en sistema cerrado."""
        if len(self._hamiltonian_history) < 2:
            return {"status": "INSUFFICIENT_DATA"}
        
        H_initial = self._hamiltonian_history[0]
        H_current = self._hamiltonian_history[-1]
        
        # Para sistema con disipación, la energía debe decrecer
        if self.R > 0:
            # Verificar monotonía decreciente
            history = list(self._hamiltonian_history)
            is_decreasing = all(
                history[i] >= history[i+1] - tolerance * abs(history[i])
                for i in range(len(history) - 1)
            )
            return {
                "status": "DISSIPATIVE",
                "energy_decrease": H_initial - H_current,
                "monotonic_decrease": is_decreasing,
                "dissipation_expected": True
            }
        else:
            # Sistema conservativo
            drift = abs(H_current - H_initial)
            relative_drift = drift / max(abs(H_initial), 1e-12)
            
            return {
                "status": "CONSERVATIVE",
                "absolute_drift": drift,
                "relative_drift": relative_drift,
                "is_conserved": relative_drift < tolerance
            }

    def reset(self):
        """Reinicia el estado a condiciones iniciales."""
        self.charge = 0.0
        self.flux_linkage = 0.0
        self.entropy = 0.0
        self.angular_momentum = np.zeros(3)
        self.angular_velocity = np.zeros(3)
        self._hamiltonian_history.clear()
        self._charge_history.clear()


# ============================================================================
# MÉTRICAS DE CALIDAD DE CÓDIGO
# ============================================================================
class CodeQualityMetrics:
    """
    Métricas para verificar calidad numérica y leyes de conservación.
    """
    
    def __init__(self, 
                 energy_tolerance: float = 0.01,
                 charge_tolerance: float = 0.001):
        self.energy_tol = energy_tolerance
        self.charge_tol = charge_tolerance

    def calculate_conservation_laws(self, 
                                    state_history: List[Dict]) -> Dict[str, Any]:
        """
        Verifica conservación de cantidades físicas.
        
        En sistema disipativo: energía debe decrecer monótonamente.
        En sistema conservativo: energía constante.
        """
        if not state_history or len(state_history) < 2:
            return {"status": "INSUFFICIENT_DATA", "samples": len(state_history) if state_history else 0}
        
        initial = state_history[0]
        final = state_history[-1]
        
        # Análisis de energía
        energies = [s.get('energy', s.get('hamiltonian', 0)) for s in state_history]
        E_init = energies[0]
        E_final = energies[-1]
        
        # Estadísticas de energía
        E_max = max(energies)
        E_min = min(energies)
        E_range = E_max - E_min
        
        # Verificar monotonía DECRECIENTE (sistema disipativo normal)
        is_monotonic_decreasing = all(
            energies[i] >= energies[i+1] - self.energy_tol * abs(energies[i])
            for i in range(len(energies) - 1) if energies[i] != 0
        )
        
        # Drift de energía
        energy_drift = abs(E_final - E_init)
        relative_energy_drift = energy_drift / max(abs(E_init), 1e-12)
        
        # Análisis de carga
        charges = [s.get('Q', s.get('charge', 0)) for s in state_history]
        Q_init = charges[0]
        Q_final = charges[-1]
        charge_drift = abs(Q_final - Q_init)
        relative_charge_drift = charge_drift / max(abs(Q_init), 1e-12)
        
        # Detección de oscilaciones espurias
        if len(energies) > 5:
            diffs = np.diff(energies)
            sign_changes = sum(1 for i in range(1, len(diffs)) 
                              if diffs[i] * diffs[i-1] < 0)
            oscillation_ratio = sign_changes / (len(energies) - 2)
        else:
            oscillation_ratio = 0.0
        
        return {
            "status": "OK",
            "num_samples": len(state_history),
            "energy": {
                "initial": E_init,
                "final": E_final,
                "drift_absolute": energy_drift,
                "drift_relative": relative_energy_drift,
                "is_conserved": relative_energy_drift < self.energy_tol,
                "is_monotonic_decreasing": is_monotonic_decreasing,
                "range": E_range
            },
            "charge": {
                "initial": Q_init,
                "final": Q_final,
                "drift_absolute": charge_drift,
                "drift_relative": relative_charge_drift,
                "is_conserved": relative_charge_drift < self.charge_tol
            },
            "stability": {
                "oscillation_ratio": oscillation_ratio,
                "is_stable": oscillation_ratio < 0.3
            }
        }

    def calculate_numerical_quality(self, 
                                   metrics_sequence: List[Dict[str, float]]) -> Dict[str, float]:
        """Evalúa calidad numérica de la simulación."""
        if len(metrics_sequence) < 3:
            return {"status": "INSUFFICIENT_DATA", "quality_score": 0.5}
        
        # Extraer series temporales de métricas clave
        metrics_to_analyze = ['current_I', 'total_energy', 'entropy_shannon']
        
        stability_scores = []
        for metric_name in metrics_to_analyze:
            values = [m.get(metric_name, 0) for m in metrics_sequence if metric_name in m]
            
            if len(values) > 1:
                mean_val = np.mean(values)
                std_val = np.std(values)
                
                # Coeficiente de variación (menor es más estable)
                if abs(mean_val) > SystemConstants.EPSILON:
                    cv = std_val / abs(mean_val)
                    stability = 1.0 / (1.0 + cv)
                else:
                    stability = 1.0 if std_val < 1e-6 else 0.5
                
                stability_scores.append(stability)
        
        avg_stability = np.mean(stability_scores) if stability_scores else 0.5
        
        # Detección de divergencia
        if metrics_sequence:
            last_energy = metrics_sequence[-1].get('total_energy', 0)
            first_energy = metrics_sequence[0].get('total_energy', 0)
            
            if abs(last_energy) > 1e6 or (first_energy > 0 and last_energy / first_energy > 100):
                divergence_detected = True
            else:
                divergence_detected = False
        else:
            divergence_detected = False
        
        quality_score = avg_stability * (0.0 if divergence_detected else 1.0)
        
        return {
            "status": "OK",
            "stability_coefficient": float(avg_stability),
            "divergence_detected": divergence_detected,
            "quality_score": float(quality_score),
            "num_samples": len(metrics_sequence)
        }


# ============================================================================
# MOTOR DE FÍSICA REFINADO
# ============================================================================
class RefinedFluxPhysicsEngine:
    """
    Motor de física RLC con integración numérica robusta y análisis topológico.
    
    Características:
    1. Integración simpléctica (Störmer-Verlet) para conservación
    2. Método implícito para sistemas rígidos
    3. Análisis topológico espectral
    4. Entropía bayesiana
    5. Diagnóstico avanzado
    """

    def __init__(self, capacitance: float, resistance: float, inductance: float):
        # Configurar logger
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # Validación
        self._validate_parameters(capacitance, resistance, inductance)
        
        # Parámetros físicos
        self.C = float(capacitance)
        self.R = float(resistance)
        self.L = float(inductance)
        
        # Parámetros derivados
        self._compute_derived_parameters()
        
        # Componentes especializados
        self._topology = TopologicalAnalyzer()
        self._entropy = EntropyCalculator()
        self._state = UnifiedPhysicalState(self.C, self.L, self.R)
        self._quality = CodeQualityMetrics()
        
        # Inicializar Maxwell si scipy disponible
        self._init_maxwell()
        
        # Historiales
        self._state_history: deque = deque(maxlen=500)
        self._metrics_history: deque = deque(maxlen=500)
        
        # Estado interno
        self._last_current = 0.0
        self._last_time = time.time()
        self._initialized = False
        self._timestep_factor = 1.0
        
        # Estado giroscópico
        self._gyro = {
            "omega": np.zeros(3),
            "nutation": 0.0,
            "stability": 1.0
        }

    def _validate_parameters(self, C: float, R: float, L: float):
        """Validación rigurosa de parámetros físicos."""
        errors = []
        
        if C <= 0:
            errors.append(f"Capacitancia debe ser positiva: {C} F")
        if R < 0:
            errors.append(f"Resistencia debe ser no-negativa: {R} Ω")
        if L <= 0:
            errors.append(f"Inductancia debe ser positiva: {L} H")
        
        if errors:
            raise ConfigurationError("\n".join(errors))
        
        # Advertencias para valores extremos
        if C > 0 and L > 0:
            omega_0 = 1.0 / math.sqrt(L * C)
            if omega_0 > 1e10:
                self.logger.warning(f"Frecuencia natural muy alta: {omega_0:.2e} rad/s")

    def _compute_derived_parameters(self):
        """Calcula parámetros derivados del circuito."""
        self._omega_0 = 1.0 / math.sqrt(self.L * self.C)  # Frecuencia natural
        self._alpha = self.R / (2.0 * self.L)             # Factor de amortiguamiento
        self._zeta = self._alpha / self._omega_0          # Coeficiente de amortiguamiento
        
        # Factor de calidad
        self._Q_factor = math.sqrt(self.L / self.C) / self.R if self.R > 0 else float('inf')
        
        # Tipo de amortiguamiento
        if abs(self._zeta - 1.0) < 1e-6:
            self._damping_type = DampingType.CRITICALLY_DAMPED
            self._omega_d = 0.0
        elif self._zeta > 1.0:
            self._damping_type = DampingType.OVERDAMPED
            self._omega_d = self._omega_0 * math.sqrt(self._zeta**2 - 1)
        elif self._zeta > 0:
            self._damping_type = DampingType.UNDERDAMPED
            self._omega_d = self._omega_0 * math.sqrt(1 - self._zeta**2)
        else:
            self._damping_type = DampingType.UNDAMPED
            self._omega_d = self._omega_0

    def _init_maxwell(self):
        """Inicializa componentes electromagnéticos."""
        if SCIPY_AVAILABLE:
            try:
                # Grafo completo K6 para métricas
                nodes = list(range(6))
                adj = {i: set(nodes) - {i} for i in nodes}
                
                self._vector_calc = DiscreteVectorCalculus(adj)
                
                self._maxwell = MaxwellSolver(
                    self._vector_calc,
                    permittivity=self.C,
                    permeability=self.L,
                    electric_conductivity=1.0/self.R if self.R > 0 else 0.0
                )
                
                self._hamiltonian_ctrl = PortHamiltonianController(self._maxwell)
                self.logger.info("Componentes Maxwell inicializados")
                
            except Exception as e:
                self.logger.warning(f"No se pudo inicializar Maxwell: {e}")
                self._maxwell = None
                self._hamiltonian_ctrl = None
        else:
            self._maxwell = None
            self._hamiltonian_ctrl = None

    def _system_ode(self, y: np.ndarray, V_in: float) -> np.ndarray:
        """
        Sistema de ecuaciones diferenciales del circuito RLC.
        
        dy/dt = f(y), donde y = [Q, I]
        
        dQ/dt = I
        dI/dt = (V_in - R*I - Q/C) / L
        """
        Q, I = y
        
        dQ_dt = I
        dI_dt = (V_in - self.R * I - Q / self.C) / self.L
        
        return np.array([dQ_dt, dI_dt])

    def _evolve_symplectic(self, V_in: float, dt: float) -> Tuple[float, float]:
        """
        Integración simpléctica (Störmer-Verlet) para conservación de energía.
        
        Mejor para sistemas Hamiltonianos con R pequeño.
        """
        Q = self._state.charge
        I = self._state.current
        
        # Medio paso de momento (I)
        a_half = (V_in - self.R * I - Q / self.C) / self.L
        I_half = I + 0.5 * dt * a_half
        
        # Paso completo de posición (Q)
        Q_new = Q + dt * I_half
        
        # Medio paso final de momento
        a_new = (V_in - self.R * I_half - Q_new / self.C) / self.L
        I_new = I_half + 0.5 * dt * a_new
        
        return Q_new, I_new

    def _evolve_rk4(self, V_in: float, dt: float) -> Tuple[float, float]:
        """Integración Runge-Kutta 4to orden."""
        y = np.array([self._state.charge, self._state.current])
        
        k1 = self._system_ode(y, V_in)
        k2 = self._system_ode(y + 0.5 * dt * k1, V_in)
        k3 = self._system_ode(y + 0.5 * dt * k2, V_in)
        k4 = self._system_ode(y + dt * k3, V_in)
        
        y_new = y + (dt / 6.0) * (k1 + 2*k2 + 2*k3 + k4)
        
        return y_new[0], y_new[1]

    def _evolve_implicit(self, V_in: float, dt: float) -> Tuple[float, float]:
        """
        Método trapezoidal implícito para sistemas rígidos.
        
        Resuelve: y_{n+1} = y_n + (dt/2)(f(y_n) + f(y_{n+1}))
        """
        Q = self._state.charge
        I = self._state.current
        y = np.array([Q, I])
        
        f_n = self._system_ode(y, V_in)
        
        # Newton-Raphson
        y_new = y + dt * f_n  # Predictor
        
        for _ in range(SystemConstants.MAX_NEWTON_ITERATIONS):
            f_new = self._system_ode(y_new, V_in)
            
            # Residuo
            residual = y_new - y - 0.5 * dt * (f_n + f_new)
            
            if np.linalg.norm(residual) < SystemConstants.NEWTON_TOLERANCE:
                break
            
            # Jacobiano del sistema
            J = np.array([
                [0.0, 1.0],
                [-1.0/(self.L * self.C), -self.R/self.L]
            ])
            
            # Jacobiano implícito
            J_impl = np.eye(2) - 0.5 * dt * J
            
            try:
                delta = np.linalg.solve(J_impl, -residual)
                y_new += delta
            except np.linalg.LinAlgError:
                # Fallback
                y_new -= 0.5 * residual
        
        return y_new[0], y_new[1]

    def _select_integrator(self, dt: float) -> Callable:
        """Selecciona el integrador más apropiado."""
        # Rigidez del sistema
        stiffness = abs(self._alpha * dt)
        
        if stiffness > 1.0:
            return self._evolve_implicit
        elif self.R < 0.1 * math.sqrt(self.L / self.C):
            # Sistema casi conservativo
            return self._evolve_symplectic
        else:
            return self._evolve_rk4

    def calculate_gyroscopic_stability(self, current_I: float, dt: float) -> float:
        """
        Calcula estabilidad giroscópica basada en dinámica de Euler.
        
        Analogía: el circuito RLC es como un giroscopio donde:
        - Corriente ↔ velocidad angular axial
        - Cambios de corriente ↔ nutación
        """
        if not self._initialized:
            self._last_current = current_I
            self._initialized = True
            return 1.0
        
        # Velocidad angular principal
        omega_z = 10.0 * abs(current_I)
        
        # Excitación por cambio de corriente (nutación)
        dI_dt = (current_I - self._last_current) / max(dt, 1e-6)
        nutation_excitation = 0.1 * abs(dI_dt)
        
        # Evolución de nutación con amortiguamiento
        damping = 0.95
        self._gyro["nutation"] = damping * self._gyro["nutation"] + (1 - damping) * nutation_excitation
        
        # Factores de estabilidad
        # 1. Velocidad crítica
        speed_factor = math.tanh(2.0 * max(0, omega_z - 0.5))
        
        # 2. Nutación relativa
        nutation_ratio = self._gyro["nutation"] / max(omega_z, 0.1)
        nutation_factor = 1.0 / (1.0 + 3.0 * nutation_ratio**2)
        
        # Estabilidad combinada
        stability = speed_factor * nutation_factor
        stability = max(0.0, min(1.0, stability))
        
        # Suavizado
        self._gyro["stability"] = 0.9 * self._gyro["stability"] + 0.1 * stability
        
        self._last_current = current_I
        
        return self._gyro["stability"]

    def calculate_metrics(self, total_records: int, cache_hits: int,
                         error_count: int = 0, 
                         processing_time: float = 1.0) -> Dict[str, float]:
        """
        Calcula todas las métricas del sistema.
        """
        if total_records <= 0:
            return self._get_default_metrics()
        
        current_time = time.time()
        dt = max(1e-6, current_time - self._last_time)
        self._last_time = current_time
        
        # Corriente normalizada
        current_I = cache_hits / total_records
        complexity = 1.0 - current_I
        
        # Voltaje de entrada (señal de driving)
        V_in = 10.0 * math.tanh(2.0 * (current_I - 0.5))
        
        # Evolución del estado
        integrator = self._select_integrator(dt)
        Q_new, I_new = integrator(V_in, dt)
        
        # Actualizar estado
        self._state.charge = Q_new
        self._state.current = I_new
        self._state.evolve_thermal(dt)
        
        # Hamiltoniano
        hamiltonian = self._state.compute_hamiltonian()
        
        # Componentes de energía
        potential_E = 0.5 * Q_new**2 / self.C
        kinetic_E = 0.5 * self.L * I_new**2
        total_E = potential_E + kinetic_E
        
        # Entropía del sistema
        counts = {
            "success": total_records - error_count,
            "error": error_count
        }
        entropy_result = self._entropy.calculate_shannon(counts)
        
        # Construir métricas para topología
        base_metrics = {
            "saturation": math.tanh(Q_new),
            "complexity": complexity,
            "current_I": I_new,
            "potential_energy": potential_E,
            "kinetic_energy": kinetic_E,
            "entropy_shannon": entropy_result["entropy_bits"]
        }
        
        # Análisis topológico
        self._topology.build_metric_graph(base_metrics)
        betti = self._topology.compute_betti_numbers()
        topo_stats = self._topology.get_graph_statistics()
        
        # Estabilidad giroscópica
        gyro_stability = self.calculate_gyroscopic_stability(current_I, dt)
        
        # Métricas electromagnéticas
        em_metrics = {}
        if self._maxwell:
            try:
                self._maxwell.J_e = np.full(self._vector_calc.num_edges, current_I)
                self._maxwell.step(dt)
                em_metrics = self._maxwell.compute_energy()
            except Exception:
                pass
        
        # Ensamblar métricas finales
        metrics = {
            # Base
            **base_metrics,
            
            # Energía
            "total_energy": total_E,
            "total_hamiltonian": hamiltonian,
            "dissipated_power": self._state.compute_dissipation_rate(),
            
            # Circuito
            "voltage": Q_new / self.C,
            "charge": Q_new,
            "flux_linkage": I_new * self.L,
            "damping_ratio": self._zeta,
            "quality_factor": self._Q_factor,
            "resonant_frequency_hz": self._omega_0 / (2 * math.pi),
            
            # Entropía
            "entropy_bits": entropy_result["entropy_bits"],
            "entropy_normalized": entropy_result["normalized"],
            "temperature": self._state.temperature,
            
            # Topología
            "betti_0": betti[0],
            "betti_1": betti[1],
            "euler_characteristic": topo_stats["euler_characteristic"],
            "spectral_gap": topo_stats["spectral_gap"],
            "graph_density": topo_stats["density"],
            
            # Estabilidad
            "gyroscopic_stability": gyro_stability,
            
            # EM
            **{f"em_{k}": v for k, v in em_metrics.items()}
        }
        
        # Almacenar en historial
        self._store_state(Q_new, I_new, total_E, hamiltonian)
        self._metrics_history.append(metrics.copy())
        
        return metrics

    def _get_default_metrics(self) -> Dict[str, float]:
        """Métricas por defecto cuando no hay datos."""
        return {
            "saturation": 0.0,
            "complexity": 1.0,
            "current_I": 0.0,
            "potential_energy": 0.0,
            "kinetic_energy": 0.0,
            "total_energy": 0.0,
            "total_hamiltonian": 0.0,
            "dissipated_power": 0.0,
            "voltage": 0.0,
            "charge": 0.0,
            "flux_linkage": 0.0,
            "damping_ratio": self._zeta,
            "quality_factor": self._Q_factor,
            "resonant_frequency_hz": self._omega_0 / (2 * math.pi),
            "entropy_bits": 0.0,
            "entropy_normalized": 0.0,
            "temperature": self._state.temperature,
            "betti_0": 0,
            "betti_1": 0,
            "euler_characteristic": 0,
            "spectral_gap": 0.0,
            "graph_density": 0.0,
            "gyroscopic_stability": 1.0
        }

    def _store_state(self, Q: float, I: float, E: float, H: float):
        """Almacena estado en historial."""
        self._state_history.append({
            "Q": Q,
            "I": I,
            "energy": E,
            "hamiltonian": H,
            "time": time.time()
        })

    def get_system_diagnosis(self) -> Dict[str, Any]:
        """Diagnóstico completo del sistema."""
        if not self._metrics_history:
            return {"status": "NO_DATA"}
        
        latest = self._metrics_history[-1]
        
        # Análisis de conservación
        conservation = self._quality.calculate_conservation_laws(
            list(self._state_history)
        )
        
        # Calidad numérica
        quality = self._quality.calculate_numerical_quality(
            list(self._metrics_history)
        )
        
        # Estado del sistema
        saturation = latest.get("saturation", 0)
        if saturation > 0.95:
            system_state = "SATURATED"
            priority = "MEDIUM"
        elif saturation < 0.05:
            system_state = "IDLE"
            priority = "LOW"
        else:
            system_state = "ACTIVE"
            priority = "LOW"
        
        # Verificar estabilidad
        gyro = latest.get("gyroscopic_stability", 1.0)
        if gyro < 0.3:
            priority = "HIGH"
            system_state = "UNSTABLE"
        
        # Verificar entropía
        entropy_norm = latest.get("entropy_normalized", 0)
        if entropy_norm > 0.9:
            priority = "HIGH" if priority == "LOW" else priority
            entropy_state = "CRITICAL"
        elif entropy_norm > 0.7:
            entropy_state = "HIGH"
        else:
            entropy_state = "NORMAL"
        
        return {
            "system_state": system_state,
            "priority": priority,
            "entropy_state": entropy_state,
            "conservation": conservation,
            "numerical_quality": quality,
            "damping_type": self._damping_type.name,
            "recommendations": self._generate_recommendations(
                system_state, entropy_state, conservation, quality
            )
        }

    def _generate_recommendations(self, state: str, entropy: str,
                                  conservation: Dict, quality: Dict) -> List[str]:
        """Genera recomendaciones basadas en diagnóstico."""
        recs = []
        
        if state == "SATURATED":
            recs.append("Reducir carga del sistema")
        if state == "UNSTABLE":
            recs.append("Verificar estabilidad numérica")
        
        if entropy == "CRITICAL":
            recs.append("Reducir tasa de errores")
        
        if not conservation.get("energy", {}).get("is_conserved", True):
            recs.append("Revisar integrador numérico")
        
        if quality.get("divergence_detected", False):
            recs.append("URGENTE: Sistema divergente, reducir dt")
        
        return recs if recs else ["Sistema operando normalmente"]

    def reset(self, preserve_history: bool = False):
        """Reinicia el estado del sistema."""
        self._state.reset()
        self._topology = TopologicalAnalyzer()
        self._last_current = 0.0
        self._initialized = False
        self._gyro = {"omega": np.zeros(3), "nutation": 0.0, "stability": 1.0}
        
        if not preserve_history:
            self._state_history.clear()
            self._metrics_history.clear()
        
        self.logger.info("Sistema reiniciado")