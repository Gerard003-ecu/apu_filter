"""
M√≥dulo para el parseo crudo de reportes de An√°lisis de Precios Unitarios (APU).

Este m√≥dulo proporciona una clase `ReportParserCrudo` que implementa una m√°quina
de estados robusta para procesar, l√≠nea por l√≠nea, archivos de APU con un
formato semi-estructurado. Su objetivo principal es identificar y extraer los
registros de insumos asociados a cada APU, manteniendo el contexto del APU
al que pertenecen.
"""

import logging
import re
from collections import Counter
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

from .utils import clean_apu_code

logger = logging.getLogger(__name__)


@dataclass
class LineValidationResult:
    """Resultado de la validaci√≥n de una l√≠nea."""

    is_valid: bool
    reason: str = ""
    fields_count: int = 0
    has_numeric_fields: bool = False


class ParserError(Exception):
    """Excepci√≥n base para errores ocurridos durante el parseo."""

    pass


class FileReadError(ParserError):
    """Indica un error al leer el archivo de entrada."""

    pass


class ParseStrategyError(ParserError):
    """Indica un error en la l√≥gica de la estrategia de parseo."""

    pass


@dataclass
class ParserConfig:
    """
    Configuraci√≥n simplificada para el parser.

    Attributes:
        encodings: Lista de codificaciones a intentar al leer el archivo.
        default_unit: Unidad por defecto a asignar si no se puede extraer.
        max_lines_to_process: L√≠mite de l√≠neas a procesar para evitar sobrecargas.
    """

    encodings: List[str] = field(
        default_factory=lambda: ["utf-8", "latin1", "cp1252", "iso-8859-1"]
    )
    default_unit: str = "UND"
    max_lines_to_process: int = 100000


@dataclass
class APUContext:
    """
    Almacena el contexto de un APU mientras se procesan sus l√≠neas.

    Attributes:
        apu_code: El c√≥digo (ITEM) del APU.
        apu_desc: La descripci√≥n del APU.
        apu_unit: La unidad de medida del APU.
        source_line: El n√∫mero de l√≠nea donde se detect√≥ el APU.
    """

    apu_code: str
    apu_desc: str
    apu_unit: str
    source_line: int

    def __post_init__(self):
        """Realiza validaci√≥n y normalizaci√≥n despu√©s de la inicializaci√≥n."""
        self.apu_code = self.apu_code.strip() if self.apu_code else ""
        self.apu_desc = self.apu_desc.strip() if self.apu_desc else ""
        self.apu_unit = self.apu_unit.strip().upper() if self.apu_unit else self.default_unit
        if not self.apu_code:
            raise ValueError("El c√≥digo del APU no puede estar vac√≠o.")

    @property
    def is_valid(self) -> bool:
        """Comprueba si el contexto del APU es v√°lido."""
        return bool(self.apu_code and len(self.apu_code) >= 2)


class ReportParserCrudo:
    """
    Parser robusto tipo m√°quina de estados para archivos APU semi-estructurados.

    Esta clase procesa un archivo l√≠nea por l√≠nea, identificando bloques que
    pertenecen a un APU espec√≠fico. Utiliza un enfoque de m√°quina de estados
    simple:
    1. Busca un encabezado de APU (l√≠neas con "UNIDAD:" y "ITEM:").
    2. Una vez en un contexto de APU, procesa las l√≠neas subsecuentes como
       posibles insumos, categor√≠as o l√≠neas de "ruido" a ignorar.
    3. Repite el proceso hasta el final del archivo.

    El resultado es una lista de registros "crudos", donde cada registro
    contiene la l√≠nea del insumo y el contexto del APU al que pertenece.
    """

    CATEGORY_KEYWORDS = {
        "MATERIALES": {"MATERIALES", "MATERIAL", "MAT.", "INSUMOS"},
        "MANO DE OBRA": {"MANO DE OBRA", "MANO OBRA", "M.O.", "MO", "PERSONAL", "OBRERO"},
        "EQUIPO": {"EQUIPO", "EQUIPOS", "MAQUINARIA", "MAQ."},
        "TRANSPORTE": {"TRANSPORTE", "TRANSPORTES", "TRANS.", "ACARREO"},
        "HERRAMIENTA": {"HERRAMIENTA", "HERRAMIENTAS", "HERR.", "UTILES"},
        "OTROS": {"OTROS", "OTRO", "VARIOS", "ADICIONALES"},
    }

    JUNK_KEYWORDS = {
        "SUBTOTAL",
        "COSTO DIRECTO",
        "DESCRIPCION",
        "IMPUESTOS",
        "POLIZAS",
        "TOTAL",
        "IVA",
        "AIU",
    }

    def __init__(
        self,
        file_path: Union[str, Path],
        profile: dict,
        config: Optional[ParserConfig] = None,
    ):
        """
        Inicializa el parser.

        Args:
            file_path: La ruta al archivo a ser parseado.
            config: Un objeto `ParserConfig` opcional con la configuraci√≥n.
        """
        self.file_path = Path(file_path)
        self.profile = profile or {}
        self.config = config or ParserConfig()
        self.numeric_pattern = self._build_numeric_pattern()
        self.validation_stats = {
            "total_lines_evaluated": 0,
            "valid_insumos": 0,
            "rejected_insufficient_fields": 0,
            "rejected_no_numeric_data": 0,
            "rejected_empty_key_field": 0,
            "rejected_subtotal_line": 0,
        }
        self._validate_file_path()

        self.raw_records: List[Dict[str, Any]] = []
        self.stats: Counter = Counter()
        self._parsed: bool = False

    def _build_numeric_pattern(self) -> re.Pattern:
        """Construye el patr√≥n regex para validar n√∫meros seg√∫n el perfil."""
        number_format = self.profile.get("number_format", {})
        decimal_separator = number_format.get("decimal_separator")

        if decimal_separator == "comma":
            decimal_char = ","
            thousands_char = r"\."
        elif decimal_separator == "dot":
            decimal_char = r"\."
            thousands_char = ","
        else:
            # Si no se especifica, permitir ambos formatos
            decimal_char = r"[,.]"
            thousands_char = r"[.,]"

        # Patr√≥n mejorado que es m√°s flexible
        pattern = (
            r"^\s*[-+]?"  # Signo opcional
            r"(\d{1,3}(" + thousands_char + r"\d{3})*|\d+)"  # Parte entera con o sin separadores de miles
            r"(" + decimal_char + r"\d+)?"  # Parte decimal opcional
            r"\s*$"
        )
        return re.compile(pattern)

    def _validate_insumo_line(self, line: str, fields: List[str]) -> LineValidationResult:
        """Validaci√≥n estricta de una l√≠nea candidata a insumo ANTES de enviarla a Lark."""
        # 1. N√∫mero m√≠nimo de campos
        if len(fields) < 5:
            return LineValidationResult(
                is_valid=False, reason=f"Insuficientes campos: {len(fields)} < 5"
            )

        # 2. Descripci√≥n no vac√≠a
        if not fields[0] or not fields[0].strip():
            return LineValidationResult(is_valid=False, reason="Campo de descripci√≥n vac√≠o")

        # 3. Detectar l√≠neas de subtotal/total
        if any(keyword in line.upper() for keyword in self.JUNK_KEYWORDS):
            return LineValidationResult(
                is_valid=False, reason="L√≠nea de subtotal/junk detectada"
            )

        # 4. Al menos 2 campos num√©ricos v√°lidos
        numeric_fields_found = 0
        for field in fields[1:]:  # Saltar descripci√≥n
            if field and self.numeric_pattern.match(field.strip()):
                numeric_fields_found += 1

        if numeric_fields_found < 2:
            return LineValidationResult(
                is_valid=False,
                reason=f"Campos num√©ricos insuficientes: {numeric_fields_found} < 2",
            )

        return LineValidationResult(is_valid=True)

    def _validate_file_path(self) -> None:
        """Valida que la ruta del archivo sea un archivo v√°lido y no vac√≠o."""
        if not self.file_path.exists():
            raise FileNotFoundError(f"Archivo no encontrado: {self.file_path}")
        if not self.file_path.is_file():
            raise ValueError(f"La ruta no es un archivo: {self.file_path}")
        if self.file_path.stat().st_size == 0:
            raise ValueError(f"El archivo est√° vac√≠o: {self.file_path}")

    def parse_to_raw(self) -> List[Dict[str, Any]]:
        """
        Punto de entrada principal para parsear el archivo.

        Lee el archivo de forma segura, lo divide en l√≠neas y orquesta el
        proceso de parseo a trav√©s de la m√°quina de estados `_parse_by_lines`.

        Returns:
            Una lista de diccionarios, donde cada uno es un registro crudo de insumo.

        Raises:
            ParseStrategyError: Si ocurre un error cr√≠tico durante el parseo.
        """
        if self._parsed:
            return self.raw_records

        logger.info(f"Iniciando parseo l√≠nea por l√≠nea de: {self.file_path.name}")

        try:
            content = self._read_file_safely()
            lines = content.split("\n")
            self.stats["total_lines"] = len(lines)

            self._parse_by_lines(lines)

            self._parsed = True
            logger.info(
                f"Parseo completo. Extra√≠dos {self.stats['insumos_extracted']} "
                "registros crudos."
            )
            if self.stats["insumos_extracted"] == 0:
                logger.warning(
                    "No se extrajeron registros. El archivo puede estar vac√≠o o "
                    "en un formato inesperado."
                )

        except Exception as e:
            logger.error(f"Error cr√≠tico de parseo: {e}", exc_info=True)
            raise ParseStrategyError(
                f"Fall√≥ el parseo con estrategia l√≠nea por l√≠nea: {e}"
            ) from e

        return self.raw_records

    def _read_file_safely(self) -> str:
        """
        Lee el contenido del archivo intentando m√∫ltiples codificaciones.

        Returns:
            El contenido del archivo como una cadena de texto.

        Raises:
            FileReadError: Si no se puede leer el archivo con ninguna de las
                           codificaciones especificadas.
        """
        # CAMBIO: Usar el encoding del perfil como primera opci√≥n
        encodings_to_try = [self.profile.get("encoding")] + self.config.encodings

        for encoding in filter(
            None, encodings_to_try
        ):  # filter(None, ...) para saltar si el perfil no tiene encoding
            try:
                with open(self.file_path, "r", encoding=encoding, errors="strict") as f:
                    content = f.read()
                self.stats["encoding_used"] = encoding
                logger.info(f"Archivo le√≠do exitosamente con codificaci√≥n: {encoding}")
                return content
            except (UnicodeDecodeError, TypeError, LookupError):
                continue
        raise FileReadError(
            f"No se pudo leer el archivo {self.file_path} con ninguna de las "
            "codificaciones especificadas."
        )

    def _detect_category(self, line_upper: str) -> Optional[str]:
        """
        Detecta si una l√≠nea representa una categor√≠a de insumos.

        Args:
            line_upper: La l√≠nea de texto en may√∫sculas.

        Returns:
            El nombre can√≥nico de la categor√≠a si se detecta una, o None.
        """
        if len(line_upper) > 50 or sum(c.isdigit() for c in line_upper) > 3:
            return None
        for canonical, variations in self.CATEGORY_KEYWORDS.items():
            for variation in variations:
                pattern = (
                    r"\b" + re.escape(variation) + r"\b"
                    if "." not in variation
                    else re.escape(variation)
                )
                if re.search(pattern, line_upper):
                    return canonical
        return None

    def _is_junk_line(self, line_upper: str) -> bool:
        """
        Determina si una l√≠nea debe ser ignorada por ser "ruido".

        Se considera "ruido" a l√≠neas vac√≠as, subtotales, totales, o l√≠neas
        puramente decorativas (ej. '-----').

        Args:
            line_upper: La l√≠nea de texto en may√∫sculas.

        Returns:
            True si la l√≠nea es "ruido", False en caso contrario.
        """
        if len(line_upper.strip()) < 3:
            return True
        for keyword in self.JUNK_KEYWORDS:
            if keyword in line_upper:
                return True
        # Lines with decorative characters
        if re.search(r"^[=\-_\s*]+$", line_upper):
            return True
        return False

    def _parse_by_lines(self, lines: List[str]) -> bool:
        """
        M√°quina de estados que procesa el archivo l√≠nea por l√≠nea.

        Itera sobre cada l√≠nea y, dependiendo del estado actual (si se est√°
        dentro de un contexto de APU o no), decide c√≥mo procesarla.

        Args:
            lines: La lista de todas las l√≠neas del archivo.

        Returns:
            True si se extrajo al menos un insumo, False en caso contrario.
        """
        current_apu_context: Optional[APUContext] = None
        current_category = "INDEFINIDO"
        i = 0

        while i < len(lines):
            line = lines[i].strip()

            if not line:
                i += 1
                continue

            # Estado 1: Buscar un encabezado de APU.
            # Un encabezado se define por una l√≠nea "UNIDAD:" seguida de "ITEM:".
            is_header_line = "UNIDAD:" in line.upper()
            is_item_line_next = (i + 1) < len(lines) and "ITEM:" in lines[i + 1].upper()

            if is_header_line and is_item_line_next:
                header_line = line
                item_line = lines[i + 1].strip()

                try:
                    apu_desc = header_line.split(";")[0].strip()
                    unit_match = re.search(r"UNIDAD:\s*(\S+)", header_line, re.IGNORECASE)
                    apu_unit = (
                        unit_match.group(1) if unit_match else self.config.default_unit
                    )

                    item_match = re.search(r"ITEM:\s*([\S,]+)", item_line, re.IGNORECASE)
                    apu_code_raw = (
                        item_match.group(1) if item_match else f"UNKNOWN_APU_{i + 1}"
                    )
                    apu_code = clean_apu_code(apu_code_raw)

                    current_apu_context = APUContext(
                        apu_code=apu_code,
                        apu_desc=apu_desc,
                        apu_unit=apu_unit,
                        source_line=i + 1,
                    )
                    current_category = "INDEFINIDO"  # Reiniciar categor√≠a para nuevo APU
                    self.stats["apus_detected"] += 1
                    logger.debug(
                        f"Nuevo contexto de APU encontrado en l√≠nea {i + 1}: {apu_code}"
                    )
                    i += 2  # Saltar las dos l√≠neas del encabezado
                    continue
                except Exception as e:
                    logger.warning(
                        f"Fallo al parsear encabezado de APU en l√≠nea {i + 1}: {e}"
                    )
                    current_apu_context = None
                    i += 1
                    continue

            # Estado 2: Procesar l√≠neas dentro de un contexto de APU.
            if current_apu_context:
                line_upper = line.upper()

                # Comprobar si es una nueva categor√≠a
                new_category = self._detect_category(line_upper)
                if new_category:
                    current_category = new_category
                    self.stats[f"category_{current_category}"] += 1
                    i += 1
                    continue

                # Comprobar si es una l√≠nea de "ruido"
                if self._is_junk_line(line_upper):
                    self.stats["junk_lines_skipped"] += 1
                    i += 1
                    continue

                # --- INICIO DE LA MODIFICACI√ìN ---
                # Asumir que es una l√≠nea de insumo y VALIDARLA ESTRICTAMENTE
                fields = [f.strip() for f in line.split(";")]
                self.validation_stats["total_lines_evaluated"] += 1

                validation_result = self._validate_insumo_line(line, fields)

                if validation_result.is_valid:
                    # ‚úÖ L√≠nea V√ÅLIDA - Agregar a registros
                    record = {
                        "apu_code": current_apu_context.apu_code,
                        "apu_desc": current_apu_context.apu_desc,
                        "apu_unit": current_apu_context.apu_unit,
                        "category": current_category,
                        "insumo_line": line,
                        "source_line": i + 1,
                    }
                    self.raw_records.append(record)
                    self.stats["insumos_extracted"] += 1
                    self.validation_stats["valid_insumos"] += 1
                    logger.debug(f" ‚úì Insumo v√°lido [l√≠nea {i + 1}]: {fields[0][:50]}...")
                else:
                    # ‚ùå L√≠nea RECHAZADA - Registrar y continuar
                    if "Insuficientes campos" in validation_result.reason:
                        self.validation_stats["rejected_insufficient_fields"] += 1
                    elif "num√©ricos insuficientes" in validation_result.reason:
                        self.validation_stats["rejected_no_numeric_data"] += 1
                    elif "descripci√≥n vac√≠o" in validation_result.reason:
                        self.validation_stats["rejected_empty_key_field"] += 1
                    elif "subtotal" in validation_result.reason:
                        self.validation_stats["rejected_subtotal_line"] += 1
                    logger.debug(
                        f" ‚úó L√≠nea rechazada [l√≠nea {i + 1}]: {validation_result.reason} -> Contenido: {line[:80]}..."
                    )
                    self.stats["lines_ignored_in_context"] += 1
                # --- FIN DE LA MODIFICACI√ìN ---

            i += 1
        self._log_validation_summary()  # A√±adir esta llamada al final
        return self.stats["insumos_extracted"] > 0

    def _log_validation_summary(self):
        """Registra un resumen detallado de la validaci√≥n."""
        total_eval = self.validation_stats["total_lines_evaluated"]
        valid = self.validation_stats["valid_insumos"]

        if total_eval == 0:
            logger.warning("‚ö†Ô∏è  No se evaluaron l√≠neas para validaci√≥n")
            return

        logger.info("=" * 70)
        logger.info("üìä RESUMEN DE VALIDACI√ìN DE L√çNEAS")
        logger.info("=" * 70)
        logger.info(f"Total l√≠neas evaluadas:        {total_eval}")
        if total_eval > 0:
            logger.info(
                f"‚úì Insumos v√°lidos:             {valid} ({valid/total_eval*100:.1f}%)"
            )
        else:
            logger.info("‚úì Insumos v√°lidos:             0 (0.0%)")
        logger.info(
            f"‚úó Rechazados - Campos insuf.:  {self.validation_stats['rejected_insufficient_fields']}"
        )
        logger.info(
            f"‚úó Rechazados - Sin num√©ricos:  {self.validation_stats['rejected_no_numeric_data']}"
        )
        logger.info(
            f"‚úó Rechazados - Desc. vac√≠a:    {self.validation_stats['rejected_empty_key_field']}"
        )
        logger.info(
            f"‚úó Rechazados - Subtotales:     {self.validation_stats['rejected_subtotal_line']}"
        )
        logger.info("=" * 70)

        if valid == 0 and total_eval > 0:
            logger.error(
                "üö® CR√çTICO: 0 insumos v√°lidos encontrados. "
                "Revise el formato del archivo o el perfil de configuraci√≥n."
            )
