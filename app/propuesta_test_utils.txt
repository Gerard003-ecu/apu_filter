
### propuesta 1 ###

"""
Pruebas robustas y exhaustivas para el módulo de utilidades de APU.

Este archivo utiliza pytest para garantizar la calidad, robustez y 
correctitud de todas las funciones del módulo utils.py.
Se enfoca en cubrir casos típicos, límites y de error.
"""

import pytest
import pandas as pd
import numpy as np
from pathlib import Path
import logging
from unittest.mock import patch

# Asumimos que el módulo original se llama utils.py y está en el mismo directorio
# o en el PYTHONPATH. Si tiene otro nombre, ajústalo aquí.
# from your_package import utils
from utils import (  # Importa todas las funciones públicas a probar
    normalize_text, normalize_text_series, parse_number, clean_apu_code,
    normalize_unit, safe_read_dataframe, validate_numeric_value,
    validate_series, create_apu_signature, detect_outliers,
    find_and_rename_columns, sanitize_for_json, calculate_statistics,
    batch_process_dataframe, STANDARD_UNITS, UNIT_MAPPING
)

# Configurar logger para capturar advertencias durante las pruebas
logging.basicConfig(level=logging.DEBUG)

# ============================================================================
# FIXTURES
# ============================================================================

@pytest.fixture
def sample_dataframe():
    """Proporciona un DataFrame de ejemplo para las pruebas."""
    return pd.DataFrame({
        'CODIGO_APU': ['A01', 'A02', 'B01', 'C01'],
        'DESCRIPCION': ['Cemento', 'Arena', 'Hormigón', 'Acero'],
        'UNIDAD': ['KG', 'M3', 'M3', 'TON'],
        'VALOR_UNITARIO': [150.50, 25000, 180000, 850.75],
        'CANTIDAD': [100, 15.5, 2, 50.2],
        'VALOR_TOTAL': [15050, 387500, 360000, 42707.65]
    })

@pytest.fixture
def sample_series():
    """Proporciona una Serie de ejemplo para las pruebas."""
    return pd.Series([10, 20, 30, 40, 50])

@pytest.fixture
def temp_csv_with_semicolon(tmp_path):
    """Crea un archivo CSV temporal con separador punto y coma."""
    file_path = tmp_path / "test_semicolon.csv"
    content = "col1;col2;col3\n1;2;3\n4;5;6"
    file_path.write_text(content, encoding='utf-8')
    return file_path

@pytest.fixture
def temp_excel_file(tmp_path):
    """Crea un archivo Excel temporal."""
    file_path = tmp_path / "test.xlsx"
    df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
    df.to_excel(file_path, index=False)
    return file_path

# ============================================================================
# PRUEBAS DE NORMALIZACIÓN DE TEXTO
# ============================================================================

class TestTextNormalization:
    """Pruebas para las funciones de normalización de texto."""

    @pytest.mark.parametrize("input_text, preserve_special, expected", [
        ("  Hola MUNDO  ", False, "hola mundo"),
        ("Soy una prueba con ácentos y ñ", False, "soy una prueba con acentos y n"),
        ("Texto #1 con-caracteres.especiales@", True, "texto #1 con-caracteres.especiales@"),
        ("Otro texto con $ y %", False, "otro texto con y"),
        ("", False, ""),
        (123, False, "123"),
        (None, False, ""),
        ("  Múltiples   espacios  ", False, "multiples espacios"),
        ("Descripción Técnica (Ref. #A-01)", True, "descripcion tecnica ref #a-01")
    ])
    def test_normalize_text(self, input_text, preserve_special, expected):
        assert normalize_text(input_text, preserve_special_chars=preserve_special) == expected

    def test_normalize_text_cache(self):
        # La primera llamada llena la caché
        result1 = normalize_text("Prueba de caché")
        # La segunda llamada debería usar la caché
        result2 = normalize_text("Prueba de caché")
        assert result1 == result2
        # Verificamos que el resultado sea el esperado
        assert result1 == "prueba de cache"

    def test_normalize_text_series(self, sample_dataframe):
        series = pd.Series(["  Texto A  ", "TEXTO B", "Texto con ácentos"])
        expected = pd.Series(["texto a", "texto b", "texto con acentos"])
        pd.testing.assert_series_equal(normalize_text_series(series), expected)

    def test_normalize_text_series_empty(self):
        empty_series = pd.Series([], dtype=str)
        result = normalize_text_series(empty_series)
        assert result.empty

# ============================================================================
# PRUEBAS DE CONVERSIÓN NUMÉRICA
# ============================================================================

class TestNumericConversion:
    """Pruebas para las funciones de conversión de números."""

    @pytest.mark.parametrize("input_str, expected", [
        ("123.45", 123.45),
        ("1,234.56", 1234.56),
        ("1.234,56", 1234.56), # Caso europeo
        ("1.234.567,89", 1234567.89),
        ("  50  ", 50.0),
        ("$1,000.50", 1000.50),
        ("25%", 25.0),
        ("-100.5", -100.5),
        ("1.5e2", 150.0),
        ("1,5e2", 150.0), # Coma decimal con notación científica
        ("", 0.0),
        (None, 0.0),
        ("no es un número", 0.0),
        (123, 123.0),
        (45.6, 45.6),
        (np.nan, 0.0),
        ("1.000.000", 1000000.0), # Múltiples puntos, sin parte decimal
        ("0", 0.0)
    ])
    def test_parse_number(self, input_str, expected):
        assert parse_number(input_str) == expected

    def test_parse_number_custom_default(self):
        assert parse_number("invalido", default_value=-1) == -1

    def test_parse_number_explicit_separator(self):
        assert parse_number("1.234,56", decimal_separator="comma") == 1234.56
        assert parse_number("1,234.56", decimal_separator="dot") == 1234.56

# ============================================================================
# PRUEBAS DE LIMPIEZA Y VALIDACIÓN
# ============================================================================

class TestCodeAndUnitNormalization:
    """Pruebas para limpieza de códigos y normalización de unidades."""

    @pytest.mark.parametrize("input_code, expected", [
        ("  A01-01  ", "A01-01"),
        ("Código_Inválido#@", "CODIGOINVALIDO"),
        ("B.01", "B.01"),
        ("", ValueError), # Debe lanzar ValueError
        ("A", ValueError), # Demasiado corto
        ("SIN NUMEROS", "SINNUMEROS"), # Advertencia, pero no error
        (123, "123"),
    ])
    def test_clean_apu_code(self, input_code, expected):
        if isinstance(expected, type) and issubclass(expected, Exception):
            with pytest.raises(expected):
                clean_apu_code(input_code)
        else:
            assert clean_apu_code(input_code) == expected

    @pytest.mark.parametrize("input_unit, expected", [
        ("Metros", "M"),
        ("Hora", "HR"),
        ("Jornales", "JOR"),
        ("Unidad", "UND"),
        ("m3", "M3"),
        ("", "UND"),
        (None, "UND"),
        ("UNIDAD_DESCONOCIDA", "UND"),
        ("KG", "KG"),
        ("TONELADAS", "TON"),
    ])
    def test_normalize_unit(self, input_unit, expected):
        assert normalize_unit(input_unit) == expected

# ============================================================================
# PRUEBAS DE LECTURA DE ARCHIVOS
# ============================================================================

class TestFileReading:
    """Pruebas para la función robusta de lectura de archivos."""

    def test_read_csv_success(self, tmp_path):
        file_path = tmp_path / "test.csv"
        file_path.write_text("a,b,c\n1,2,3", encoding='utf-8')
        df = safe_read_dataframe(file_path)
        assert not df.empty
        assert list(df.columns) == ['a', 'b', 'c']

    def test_read_csv_semicolon(self, temp_csv_with_semicolon):
        df = safe_read_dataframe(temp_csv_with_semicolon)
        assert not df.empty
        assert list(df.columns) == ['col1', 'col2', 'col3']

    def test_read_excel_success(self, temp_excel_file):
        df = safe_read_dataframe(temp_excel_file)
        assert not df.empty
        assert list(df.columns) == ['A', 'B']

    def test_read_file_not_found(self, tmp_path):
        non_existent = tmp_path / "no_existe.csv"
        df = safe_read_dataframe(non_existent)
        assert df.empty

    def test_read_unsupported_format(self, tmp_path):
        file_path = tmp_path / "test.txt"
        file_path.write_text("hola")
        df = safe_read_dataframe(file_path)
        assert df.empty

    def test_read_with_nrows_and_usecols(self, temp_csv_with_semicolon):
        df = safe_read_dataframe(temp_csv_with_semicolon, nrows=1, usecols=['col1'])
        assert len(df) == 1
        assert list(df.columns) == ['col1']

# ============================================================================
# PRUEBAS DE VALIDACIÓN
# ============================================================================

class TestValidation:
    """Pruebas para las funciones de validación numérica."""

    @pytest.mark.parametrize("value, min_val, max_val, allow_neg, expected_valid", [
        (100, 0, 1000, False, True),
        (-10, 0, 1000, False, False),
        (-10, 0, 1000, True, True),
        (1500, 0, 1000, False, False),
        (0, 1, 1000, False, False), # allow_zero es True por defecto, pero min_val es 1
        (np.nan, 0, 1000, False, False),
        (np.inf, 0, 1000, False, False),
    ])
    def test_validate_numeric_value(self, value, min_val, max_val, allow_neg, expected_valid):
        is_valid, _ = validate_numeric_value(
            value, "test_val",
            min_value=min_val,
            max_value=max_val,
            allow_negative=allow_neg
        )
        assert is_valid == expected_valid

    def test_validate_series(self, sample_series):
        # Validar que todos los valores estén entre 5 y 55
        mask = validate_series(sample_series, min_value=5, max_value=55)
        assert mask.all()

        # Validar que ningún valor sea mayor a 40
        mask = validate_series(sample_series, max_value=40)
        expected_mask = pd.Series([True, True, True, True, False])
        pd.testing.assert_series_equal(mask, expected_mask)

# ============================================================================
# PRUEBAS DE ANÁLISIS Y DETECCIÓN
# ============================================================================

class TestAnalysisAndDetection:
    """Pruebas para funciones de análisis y detección de datos."""

    def test_create_apu_signature_default(self):
        data = {'CODIGO_APU': 'A01', 'DESCRIPCION_APU': 'Cemento', 'UNIDAD_APU': 'KG'}
        expected = "a01|cemento|kg"
        assert create_apu_signature(data) == expected

    def test_create_apu_signature_custom_fields(self):
        data = {'CODIGO_APU': 'A01', 'OTRO_CAMPO': 'valor'}
        expected = "a01|valor"
        assert create_apu_signature(data, key_fields=['CODIGO_APU', 'OTRO_CAMPO']) == expected

    @pytest.mark.parametrize("method", ["iqr", "zscore", "modified_zscore"])
    def test_detect_outliers_with_outliers(self, method):
        data = pd.Series([10, 12, 11, 13, 9, 100]) # 100 es un outlier claro
        outliers_mask = detect_outliers(data, method=method)
        assert outliers_mask.sum() == 1
        assert outliers_mask.iloc[-1] == True

    @pytest.mark.parametrize("method", ["iqr", "zscore", "modified_zscore"])
    def test_detect_outliers_without_outliers(self, method):
        data = pd.Series([10, 12, 11, 13, 9, 8])
        outliers_mask = detect_outliers(data, method=method)
        assert not outliers_mask.any()

    def test_detect_outliers_return_bounds(self):
        data = pd.Series([1, 2, 3, 4, 50])
        outliers, bounds = detect_outliers(data, method="iqr", return_bounds=True)
        assert 'Q1' in bounds
        assert 'Q3' in bounds
        assert 'lower_bound' in bounds
        assert 'upper_bound' in bounds
        assert bounds['upper_bound'] < 50

# ============================================================================
# PRUEBAS DE MANIPULACIÓN DE DATAFRAMES
# ============================================================================

class TestDataFrameManipulation:
    """Pruebas para funciones de manipulación de DataFrames."""

    def test_find_and_rename_columns(self):
        df = pd.DataFrame({
            'Codigo APU': ['A01', 'A02'],
            'Descripcion del Item': ['Item A', 'Item B'],
            'Unid': ['KG', 'M3'],
            'Otra Columna': [1, 2]
        })
        column_map = {
            'CODIGO_APU': ['codigo apu', 'cod_apu'],
            'DESCRIPCION_APU': ['descripcion del item', 'descripcion'],
            'UNIDAD_APU': ['unid', 'unidad']
        }
        df_renamed = find_and_rename_columns(df, column_map, case_sensitive=False)
        
        expected_cols = ['CODIGO_APU', 'DESCRIPCION_APU', 'UNIDAD_APU', 'Otra Columna']
        assert list(df_renamed.columns) == expected_cols

# ============================================================================
# PRUEBAS DE SERIALIZACIÓN
# ============================================================================

class TestSerialization:
    """Pruebas para la función de sanitización para JSON."""

    def test_sanitize_for_json_basic_types(self):
        data = {'int': 1, 'float': 1.1, 'str': 'test', 'bool': True, 'none': None}
        assert sanitize_for_json(data) == data

    def test_sanitize_for_json_numpy_types(self):
        data = {
            'np_int': np.int64(10),
            'np_float': np.float64(3.14),
            'np_nan': np.nan,
            'np_inf': np.inf
        }
        expected = {
            'np_int': 10,
            'np_float': 3.14,
            'np_nan': None,
            'np_inf': None
        }
        assert sanitize_for_json(data) == expected

    def test_sanitize_for_json_pandas_objects(self, sample_dataframe):
        # Probar DataFrame
        sanitized_df = sanitize_for_json(sample_dataframe)
        assert isinstance(sanitized_df, list)
        assert len(sanitized_df) == len(sample_dataframe)
        assert sanitized_df[0]['CODIGO_APU'] == 'A01'
        
        # Probar Serie
        sanitized_series = sanitize_for_json(sample_dataframe['CODIGO_APU'])
        assert isinstance(sanitized_series, list)
        assert sanitized_series == ['A01', 'A02', 'B01', 'C01']

    def test_sanitize_for_json_recursion_depth(self):
        # Crear una estructura recursiva simple
        a = {}
        a['self'] = a
        
        with pytest.raises(RecursionError):
            sanitize_for_json(a, max_depth=5)

# ============================================================================
# PRUEBAS DE FUNCIONES ADICIONALES
# ============================================================================

class TestUtilityFunctions:
    """Pruebas para funciones de utilidad adicionales."""

    def test_calculate_statistics(self, sample_series):
        stats = calculate_statistics(sample_series)
        assert stats['count'] == 5
        assert stats['mean'] == 30.0
        assert stats['null_count'] == 0

    def test_calculate_statistics_with_nan(self):
        series_with_nan = pd.Series([10, 20, np.nan, 40])
        stats = calculate_statistics(series_with_nan)
        assert stats['count'] == 3
        assert stats['null_count'] == 1
        assert stats['mean'] == (10 + 20 + 40) / 3

    def test_batch_process_dataframe_small(self, sample_dataframe):
        # Tamaño menor que batch_size, se procesa en una sola pasada
        def dummy_func(df, multiplier=1):
            df['new_col'] = df['VALOR_UNITARIO'] * multiplier
            return df
        
        result = batch_process_dataframe(sample_dataframe, dummy_func, batch_size=10, multiplier=2)
        assert len(result) == len(sample_dataframe)
        assert result['new_col'].iloc[0] == sample_dataframe['VALOR_UNITARIO'].iloc[0] * 2

    def test_batch_process_dataframe_large(self, sample_dataframe):
        # Simular un DataFrame grande concatenando el pequeño varias veces
        large_df = pd.concat([sample_dataframe] * 5, ignore_index=True)
        
        processed_chunks = []
        def dummy_func(df, multiplier=1):
            processed_chunks.append(len(df))
            df['processed'] = True
            return df

        result = batch_process_dataframe(large_df, dummy_func, batch_size=7)
        
        assert len(result) == len(large_df)
        # Verificar que se procesó en los chunks correctos
        assert processed_chunks == [7, 7, 6] # 21 filas totales, batch de 7
        assert result['processed'].all()

### propuesta 2 ###

"""
Suite de pruebas para el módulo utils.py

Este módulo contiene pruebas exhaustivas para todas las funciones de utilidades
del procesamiento de datos APU, incluyendo casos normales, casos límite y 
manejo de errores.

"""

import unittest
from unittest.mock import Mock, patch, mock_open, MagicMock
import tempfile
import json
import warnings
from pathlib import Path
from typing import Any, Dict
import sys
import os

import numpy as np
import pandas as pd
from pandas.testing import assert_series_equal, assert_frame_equal
import pytest

# Importar el módulo a probar
import utils

# ============================================================================
# FIXTURES Y UTILIDADES DE PRUEBA
# ============================================================================

class TestDataFactory:
    """Factory para generar datos de prueba consistentes."""
    
    @staticmethod
    def create_sample_dataframe(n_rows: int = 100) -> pd.DataFrame:
        """Crea un DataFrame de muestra para pruebas."""
        np.random.seed(42)
        return pd.DataFrame({
            'codigo': [f'APU{i:03d}' for i in range(n_rows)],
            'descripcion': [f'Descripción {i}' for i in range(n_rows)],
            'unidad': np.random.choice(['M', 'M2', 'KG', 'HR'], n_rows),
            'cantidad': np.random.uniform(0.1, 100, n_rows),
            'precio': np.random.uniform(10, 1000, n_rows),
            'texto_mixto': [f'Texto con Ñ, é, ü #{i}' for i in range(n_rows)]
        })
    
    @staticmethod
    def create_numeric_series_with_outliers() -> pd.Series:
        """Crea una serie numérica con valores atípicos."""
        np.random.seed(42)
        normal_data = np.random.normal(100, 15, 95)
        outliers = [500, -100, 1000, 0.001, 999]
        return pd.Series(np.concatenate([normal_data, outliers]))


# ============================================================================
# PRUEBAS DE NORMALIZACIÓN DE TEXTO
# ============================================================================

class TestTextNormalization(unittest.TestCase):
    """Pruebas para funciones de normalización de texto."""
    
    def setUp(self):
        """Configuración inicial para cada prueba."""
        utils.normalize_text.cache_clear()  # Limpiar cache LRU
    
    def test_normalize_text_basic(self):
        """Prueba normalización básica de texto."""
        test_cases = [
            ("TEXTO EN MAYÚSCULAS", "texto en mayusculas"),
            ("  espacios  extras  ", "espacios extras"),
            ("Ñoño con eñes", "nono con enes"),
            ("Café, té y más!", "cafe te y mas"),
            ("", ""),
            ("123 números 456", "123 numeros 456"),
        ]
        
        for input_text, expected in test_cases:
            with self.subTest(input=input_text):
                result = utils.normalize_text(input_text)
                self.assertEqual(result, expected)
    
    def test_normalize_text_with_special_chars(self):
        """Prueba normalización preservando caracteres especiales."""
        test_cases = [
            ("archivo_2024.txt", "archivo_2024.txt"),
            ("user@email.com", "user@email.com"),
            ("path/to/file", "path/to/file"),
            ("item#123", "item#123"),
        ]
        
        for input_text, expected in test_cases:
            with self.subTest(input=input_text):
                result = utils.normalize_text(input_text, preserve_special_chars=True)
                self.assertIn(expected.split('@')[0], result)  # Verificar parte esencial
    
    def test_normalize_text_type_conversion(self):
        """Prueba conversión de tipos a string."""
        test_cases = [
            (123, "123"),
            (45.67, "45.67"),
            (True, "true"),
            (None, "none"),
        ]
        
        for input_val, expected in test_cases:
            with self.subTest(input=input_val):
                result = utils.normalize_text(input_val)
                self.assertEqual(result, expected)
    
    def test_normalize_text_series(self):
        """Prueba normalización de Series de pandas."""
        series = pd.Series(["TEXTO 1", "Texto 2", "  texto 3  ", None, 123])
        result = utils.normalize_text_series(series)
        
        expected = pd.Series(["texto 1", "texto 2", "texto 3", "none", "123"])
        assert_series_equal(result, expected)
    
    def test_normalize_text_series_large(self):
        """Prueba normalización de Series grandes con chunks."""
        large_series = pd.Series([f"Texto {i}" for i in range(15000)])
        result = utils.normalize_text_series(large_series, chunk_size=5000)
        
        self.assertEqual(len(result), 15000)
        self.assertTrue(all(result.str.startswith("texto")))
    
    def test_normalize_text_cache_performance(self):
        """Prueba que el cache LRU funcione correctamente."""
        text = "Texto para cachear"
        
        # Primera llamada (no cacheada)
        result1 = utils.normalize_text(text)
        
        # Segunda llamada (debería venir del cache)
        result2 = utils.normalize_text(text)
        
        self.assertEqual(result1, result2)
        # Verificar que el cache tiene información
        self.assertGreater(utils.normalize_text.cache_info().hits, 0)

# ============================================================================
# PRUEBAS DE CONVERSIÓN NUMÉRICA
# ============================================================================

class TestNumericConversion(unittest.TestCase):
    """Pruebas para funciones de conversión numérica."""
    
    def test_parse_number_basic(self):
        """Prueba conversión básica de números."""
        test_cases = [
            ("123", 123.0),
            ("123.45", 123.45),
            ("-67.89", -67.89),
            ("1e3", 1000.0),
            ("1.23E-4", 0.000123),
            (123, 123.0),
            (45.67, 45.67),
        ]
        
        for input_val, expected in test_cases:
            with self.subTest(input=input_val):
                result = utils.parse_number(input_val)
                self.assertAlmostEqual(result, expected, places=7)
    
    def test_parse_number_with_separators(self):
        """Prueba conversión con diferentes separadores."""
        test_cases = [
            ("1,234.56", 1234.56),  # Formato US
            ("1.234,56", 1234.56),  # Formato EU
            ("1 234.56", 1234.56),  # Con espacios
            ("$1,234.56", 1234.56),  # Con símbolo de moneda
            ("€ 1.234,56", 1234.56),  # Euro
        ]
        
        for input_val, expected in test_cases:
            with self.subTest(input=input_val):
                result = utils.parse_number(input_val)
                self.assertAlmostEqual(result, expected, places=2)
    
    def test_parse_number_edge_cases(self):
        """Prueba casos límite en conversión numérica."""
        test_cases = [
            (None, 0.0),
            ("", 0.0),
            ("   ", 0.0),
            ("abc", 0.0),
            (float('nan'), 0.0),
            (float('inf'), 0.0),
        ]
        
        for input_val, expected in test_cases:
            with self.subTest(input=input_val):
                result = utils.parse_number(input_val, default_value=0.0)
                self.assertEqual(result, expected)
    
    def test_parse_number_custom_default(self):
        """Prueba valor por defecto personalizado."""
        result = utils.parse_number("invalid", default_value=-999.0)
        self.assertEqual(result, -999.0)
    
    def test_detect_decimal_separator(self):
        """Prueba detección de separador decimal."""
        test_cases = [
            ("1.234,56", "comma"),
            ("1,234.56", "dot"),
            ("1234.56", "dot"),
            ("1234,56", "comma"),
            ("1.234.567", "dot"),
        ]
        
        for input_val, expected in test_cases:
            with self.subTest(input=input_val):
                result = utils._detect_decimal_separator(input_val)
                self.assertEqual(result, expected)

# ============================================================================
# PRUEBAS DE CÓDIGOS APU
# ============================================================================

class TestAPUCode(unittest.TestCase):
    """Pruebas para funciones de códigos APU."""
    
    def setUp(self):
        utils.clean_apu_code.cache_clear()
    
    def test_clean_apu_code_basic(self):
        """Prueba limpieza básica de códigos APU."""
        test_cases = [
            ("apu-001", "APU-001"),
            ("  APU.002  ", "APU.002"),
            ("APU#003$", "APU003"),
            ("apu_004-.", "APU_004"),
            ("APU.005.", "APU.005"),
        ]
        
        for input_code, expected in test_cases:
            with self.subTest(input=input_code):
                result = utils.clean_apu_code(input_code, validate_format=False)
                self.assertEqual(result, expected)
    
    def test_clean_apu_code_validation(self):
        """Prueba validación de formato de códigos APU."""
        # Códigos válidos
        valid_codes = ["APU001", "APU-002", "APU.003", "APU_004"]
        for code in valid_codes:
            with self.subTest(code=code):
                result = utils.clean_apu_code(code, validate_format=True)
                self.assertIsNotNone(result)
        
        # Códigos inválidos
        with self.assertRaises(ValueError):
            utils.clean_apu_code("", validate_format=True)
        
        with self.assertRaises(ValueError):
            utils.clean_apu_code("A", validate_format=True)
    
    def test_clean_apu_code_type_conversion(self):
        """Prueba conversión de tipos en códigos APU."""
        test_cases = [
            (123, "123"),
            (45.67, "45.67"),
        ]
        
        for input_val, expected in test_cases:
            with self.subTest(input=input_val):
                result = utils.clean_apu_code(input_val, validate_format=False)
                self.assertEqual(result, expected)

# ============================================================================
# PRUEBAS DE NORMALIZACIÓN DE UNIDADES
# ============================================================================

class TestUnitNormalization(unittest.TestCase):
    """Pruebas para normalización de unidades."""
    
    def setUp(self):
        utils.normalize_unit.cache_clear()
    
    def test_normalize_unit_standard(self):
        """Prueba normalización de unidades estándar."""
        test_cases = [
            ("m", "M"),
            ("M2", "M2"),
            ("kg", "KG"),
            ("HORA", "HR"),
            ("und", "UND"),
        ]
        
        for input_unit, expected in test_cases:
            with self.subTest(input=input_unit):
                result = utils.normalize_unit(input_unit)
                self.assertEqual(result, expected)
    
    def test_normalize_unit_mapping(self):
        """Prueba mapeo de unidades equivalentes."""
        test_cases = [
            ("DIAS", "DIA"),
            ("METROS", "M"),
            ("KILOGRAMOS", "KG"),
            ("GALONES", "GAL"),
            ("UNIDADES", "UND"),
        ]
        
        for input_unit, expected in test_cases:
            with self.subTest(input=input_unit):
                result = utils.normalize_unit(input_unit)
                self.assertEqual(result, expected)
    
    def test_normalize_unit_invalid(self):
        """Prueba unidades inválidas."""
        test_cases = [
            ("", "UND"),
            (None, "UND"),
            ("INVALID_UNIT_XYZ", "UND"),
            ("@#$%", "UND"),
        ]
        
        for input_unit, expected in test_cases:
            with self.subTest(input=input_unit):
                result = utils.normalize_unit(input_unit)
                self.assertEqual(result, expected)

# ============================================================================
# PRUEBAS DE LECTURA DE ARCHIVOS
# ============================================================================

class TestFileReading(unittest.TestCase):
    """Pruebas para funciones de lectura de archivos."""
    
    def setUp(self):
        """Crear archivos temporales para pruebas."""
        self.temp_dir = tempfile.mkdtemp()
        self.csv_file = Path(self.temp_dir) / "test.csv"
        self.excel_file = Path(self.temp_dir) / "test.xlsx"
        
        # Crear CSV de prueba
        df = TestDataFactory.create_sample_dataframe(10)
        df.to_csv(self.csv_file, index=False)
        df.to_excel(self.excel_file, index=False)
    
    def tearDown(self):
        """Limpiar archivos temporales."""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_safe_read_csv(self):
        """Prueba lectura segura de CSV."""
        df = utils.safe_read_dataframe(self.csv_file)
        self.assertFalse(df.empty)
        self.assertEqual(len(df), 10)
        self.assertIn('codigo', df.columns)
    
    def test_safe_read_excel(self):
        """Prueba lectura segura de Excel."""
        df = utils.safe_read_dataframe(self.excel_file)
        self.assertFalse(df.empty)
        self.assertEqual(len(df), 10)
        self.assertIn('codigo', df.columns)
    
    def test_safe_read_nonexistent(self):
        """Prueba lectura de archivo inexistente."""
        df = utils.safe_read_dataframe("nonexistent.csv")
        self.assertTrue(df.empty)
    
    def test_safe_read_with_parameters(self):
        """Prueba lectura con parámetros específicos."""
        df = utils.safe_read_dataframe(
            self.csv_file,
            nrows=5,
            usecols=['codigo', 'descripcion']
        )
        self.assertEqual(len(df), 5)
        self.assertEqual(len(df.columns), 2)
    
    @patch('builtins.open', mock_open(read_data='col1,col2,col3\n1,2,3\n4,5,6'))
    def test_detect_csv_separator_comma(self):
        """Prueba detección de separador coma."""
        result = utils._detect_csv_separator(Path("test.csv"), 'utf-8')
        self.assertEqual(result, ',')
    
    @patch('builtins.open', mock_open(read_data='col1;col2;col3\n1;2;3\n4;5;6'))
    def test_detect_csv_separator_semicolon(self):
        """Prueba detección de separador punto y coma."""
        result = utils._detect_csv_separator(Path("test.csv"), 'utf-8')
        self.assertEqual(result, ';')

# ============================================================================
# PRUEBAS DE VALIDACIÓN
# ============================================================================

class TestValidation(unittest.TestCase):
    """Pruebas para funciones de validación."""
    
    def test_validate_numeric_value_valid(self):
        """Prueba validación de valores numéricos válidos."""
        test_cases = [
            (100.0, {}),
            (0.0, {'allow_zero': True}),
            (-50.0, {'allow_negative': True}),
            (1e6, {'max_value': 1e7}),
        ]
        
        for value, kwargs in test_cases:
            with self.subTest(value=value, kwargs=kwargs):
                is_valid, error = utils.validate_numeric_value(value, **kwargs)
                self.assertTrue(is_valid)
                self.assertEqual(error, "")
    
    def test_validate_numeric_value_invalid(self):
        """Prueba validación de valores numéricos inválidos."""
        test_cases = [
            (None, {}, "debe ser numérico"),
            (float('nan'), {}, "no puede ser nulo"),
            (float('inf'), {'allow_inf': False}, "no puede ser infinito"),
            (0.0, {'allow_zero': False}, "no puede ser cero"),
            (-50.0, {'allow_negative': False}, "no puede ser negativo"),
            (1e10, {'max_value': 1e9}, "no puede ser mayor"),
            (10.0, {'min_value': 100.0}, "no puede ser menor"),
        ]
        
        for value, kwargs, expected_msg_part in test_cases:
            with self.subTest(value=value):
                is_valid, error = utils.validate_numeric_value(value, **kwargs)
                self.assertFalse(is_valid)
                self.assertIn(expected_msg_part, error)
    
    def test_validate_series_mask(self):
        """Prueba validación de series con máscara booleana."""
        series = pd.Series([1, 2, 0, -1, None, 100])
        mask = utils.validate_series(
            series, 
            return_mask=True,
            allow_zero=False,
            allow_negative=False
        )
        
        expected_mask = pd.Series([True, True, False, False, False, True])
        assert_series_equal(mask, expected_mask)
    
    def test_validate_series_details(self):
        """Prueba validación de series con detalles."""
        series = pd.Series([1, -1, None])
        df_result = utils.validate_series(
            series,
            return_mask=False,
            allow_negative=False
        )
        
        self.assertIn('value', df_result.columns)
        self.assertIn('is_valid', df_result.columns)
        self.assertIn('error_message', df_result.columns)

# ============================================================================
# PRUEBAS DE ANÁLISIS Y DETECCIÓN
# ============================================================================

class TestAnalysisDetection(unittest.TestCase):
    """Pruebas para funciones de análisis y detección."""
    
    def test_create_apu_signature(self):
        """Prueba creación de firmas de APU."""
        apu_data = {
            'CODIGO_APU': 'APU001',
            'DESCRIPCION_APU': 'Descripción de prueba',
            'UNIDAD_APU': 'M2',
            'PRECIO': 100.0
        }
        
        signature = utils.create_apu_signature(apu_data)
        self.assertIn('apu001', signature)
        self.assertIn('descripcion de prueba', signature)
        self.assertIn('m2', signature)
    
    def test_create_apu_signature_custom_fields(self):
        """Prueba creación de firma con campos personalizados."""
        apu_data = {'campo1': 'valor1', 'campo2': 123}
        signature = utils.create_apu_signature(
            apu_data, 
            key_fields=['campo1', 'campo2']
        )
        self.assertIn('valor1', signature)
        self.assertIn('123', signature)
    
    def test_detect_outliers_iqr(self):
        """Prueba detección de outliers con método IQR."""
        series = TestDataFactory.create_numeric_series_with_outliers()
        outliers = utils.detect_outliers(series, method='iqr', threshold=1.5)
        
        self.assertIsInstance(outliers, pd.Series)
        self.assertEqual(len(outliers), len(series))
        self.assertTrue(outliers.iloc[-3:].any())  # Los últimos valores son outliers
    
    def test_detect_outliers_zscore(self):
        """Prueba detección de outliers con z-score."""
        series = TestDataFactory.create_numeric_series_with_outliers()
        outliers = utils.detect_outliers(series, method='zscore', threshold=3)
        
        self.assertTrue(outliers.iloc[-2:].any())  # Valores extremos
    
    def test_detect_outliers_modified_zscore(self):
        """Prueba detección de outliers con modified z-score."""
        series = TestDataFactory.create_numeric_series_with_outliers()
        outliers, bounds = utils.detect_outliers(
            series, 
            method='modified_zscore', 
            threshold=3.5,
            return_bounds=True
        )
        
        self.assertIn('median', bounds)
        self.assertIn('mad', bounds)
        self.assertTrue(outliers.iloc[-2:].any())
    
    def test_detect_outliers_empty_series(self):
        """Prueba detección de outliers con serie vacía."""
        empty_series = pd.Series([])
        outliers = utils.detect_outliers(empty_series)
        self.assertTrue(outliers.empty)
    
    def test_detect_outliers_constant_values(self):
        """Prueba detección de outliers con valores constantes."""
        constant_series = pd.Series([100] * 50)
        outliers = utils.detect_outliers(constant_series, method='zscore')
        self.assertFalse(outliers.any())

# ============================================================================
# PRUEBAS DE MANIPULACIÓN DE DATAFRAMES
# ============================================================================

class TestDataFrameManipulation(unittest.TestCase):
    """Pruebas para funciones de manipulación de DataFrames."""
    
    def test_find_and_rename_columns(self):
        """Prueba búsqueda y renombrado de columnas."""
        df = pd.DataFrame({
            'cod_apu': [1, 2],
            'descripcion_item': ['a', 'b'],
            'unidad_medida': ['M', 'KG']
        })
        
        column_map = {
            'CODIGO': ['cod', 'codigo', 'code'],
            'DESCRIPCION': ['desc', 'descripcion'],
            'UNIDAD': ['unidad', 'unit']
        }
        
        result = utils.find_and_rename_columns(df, column_map)
        
        self.assertIn('CODIGO', result.columns)
        self.assertIn('DESCRIPCION', result.columns)
        self.assertIn('UNIDAD', result.columns)
    
    def test_find_and_rename_columns_case_sensitive(self):
        """Prueba renombrado con sensibilidad a mayúsculas."""
        df = pd.DataFrame({'COD_APU': [1], 'Descripcion': ['a']})
        
        column_map = {
            'CODIGO': ['cod_apu'],
            'DESCRIPCION': ['descripcion']
        }
        
        # Sin sensibilidad (por defecto)
        result1 = utils.find_and_rename_columns(df, column_map, case_sensitive=False)
        self.assertIn('CODIGO', result1.columns)
        
        # Con sensibilidad
        result2 = utils.find_and_rename_columns(df, column_map, case_sensitive=True)
        self.assertNotIn('CODIGO', result2.columns)  # No coincide exactamente

# ============================================================================
# PRUEBAS DE SERIALIZACIÓN
# ============================================================================

class TestSerialization(unittest.TestCase):
    """Pruebas para funciones de serialización."""
    
    def test_sanitize_for_json_basic_types(self):
        """Prueba sanitización de tipos básicos."""
        data = {
            'int': np.int32(42),
            'float': np.float64(3.14),
            'bool': np.bool_(True),
            'nan': np.nan,
            'inf': np.inf,
            'list': [1, 2, 3],
            'dict': {'key': 'value'}
        }
        
        result = utils.sanitize_for_json(data)
        
        self.assertIsInstance(result['int'], int)
        self.assertIsInstance(result['float'], float)
        self.assertIsInstance(result['bool'], bool)
        self.assertIsNone(result['nan'])
        self.assertIsNone(result['inf'])
        
        # Verificar que es serializable
        json_str = json.dumps(result)
        self.assertIsNotNone(json_str)
    
    def test_sanitize_for_json_pandas(self):
        """Prueba sanitización de objetos pandas."""
        data = {
            'series': pd.Series([1, 2, 3]),
            'dataframe': pd.DataFrame({'col': [4, 5, 6]}),
            'na_value': pd.NA,
            'nat_value': pd.NaT
        }
        
        result = utils.sanitize_for_json(data)
        
        self.assertIsInstance(result['series'], list)
        self.assertIsInstance(result['dataframe'], list)
        self.assertIsNone(result['na_value'])
        self.assertIsNone(result['nat_value'])
    
    def test_sanitize_for_json_nested(self):
        """Prueba sanitización de estructuras anidadas."""
        data = {
            'level1': {
                'level2': {
                    'level3': pd.Series([1, 2, np.nan])
                }
            }
        }
        
        result = utils.sanitize_for_json(data)
        self.assertIsInstance(result['level1']['level2']['level3'], list)
        self.assertIsNone(result['level1']['level2']['level3'][2])
    
    def test_sanitize_for_json_max_depth(self):
        """Prueba límite de profundidad en sanitización."""
        # Crear estructura muy anidada
        data = {'level': {}}
        current = data['level']
        for i in range(150):
            current['next'] = {}
            current = current['next']
        
        with self.assertRaises(RecursionError):
            utils.sanitize_for_json(data, max_depth=100)

# ============================================================================
# PRUEBAS DE FUNCIONES ADICIONALES
# ============================================================================

class TestAdditionalFunctions(unittest.TestCase):
    """Pruebas para funciones adicionales de utilidad."""
    
    def test_calculate_statistics(self):
        """Prueba cálculo de estadísticas."""
        series = pd.Series([1, 2, 3, 4, 5, None, 7, 8, 9, 10])
        stats = utils.calculate_statistics(series)
        
        self.assertEqual(stats['count'], 9)
        self.assertAlmostEqual(stats['mean'], 5.444, places=2)
        self.assertAlmostEqual(stats['median'], 5.0)
        self.assertEqual(stats['min'], 1.0)
        self.assertEqual(stats['max'], 10.0)
        self.assertEqual(stats['null_count'], 1)
        self.assertAlmostEqual(stats['null_percentage'], 10.0)
    
    def test_calculate_statistics_empty(self):
        """Prueba estadísticas con serie vacía."""
        empty_series = pd.Series([])
        stats = utils.calculate_statistics(empty_series)
        
        self.assertEqual(stats['count'], 0)
        self.assertIsNone(stats['mean'])
        self.assertIsNone(stats['std'])
    
    def test_batch_process_dataframe(self):
        """Prueba procesamiento por lotes de DataFrame."""
        df = TestDataFactory.create_sample_dataframe(2500)
        
        def process_func(batch_df):
            batch_df['new_col'] = batch_df['cantidad'] * 2
            return batch_df
        
        result = utils.batch_process_dataframe(
            df, 
            process_func, 
            batch_size=500
        )
        
        self.assertEqual(len(result), 2500)
        self.assertIn('new_col', result.columns)
        self.assertTrue((result['new_col'] == result['cantidad'] * 2).all())
    
    def test_batch_process_small_dataframe(self):
        """Prueba procesamiento de DataFrame pequeño (sin lotes)."""
        df = TestDataFactory.create_sample_dataframe(10)
        
        def process_func(batch_df):
            batch_df['squared'] = batch_df['cantidad'] ** 2
            return batch_df
        
        result = utils.batch_process_dataframe(
            df, 
            process_func, 
            batch_size=1000
        )
        
        self.assertEqual(len(result), 10)
        self.assertIn('squared', result.columns)

# ============================================================================
# PRUEBAS DE INTEGRACIÓN
# ============================================================================

class TestIntegration(unittest.TestCase):
    """Pruebas de integración entre múltiples funciones."""
    
    def test_complete_apu_processing_pipeline(self):
        """Prueba pipeline completo de procesamiento APU."""
        # Crear datos de prueba
        apu_data = {
            'CODIGO_APU': '  apu-001.  ',
            'DESCRIPCION_APU': 'Excavación Manual en Tierra',
            'UNIDAD_APU': 'metros cubicos',
            'CANTIDAD': '1,234.56',
            'PRECIO': '$2,500.00'
        }
        
        # Procesar código
        clean_code = utils.clean_apu_code(apu_data['CODIGO_APU'])
        self.assertEqual(clean_code, 'APU-001')
        
        # Normalizar descripción
        norm_desc = utils.normalize_text(apu_data['DESCRIPCION_APU'])
        self.assertEqual(norm_desc, 'excavacion manual en tierra')
        
        # Normalizar unidad
        norm_unit = utils.normalize_unit(apu_data['UNIDAD_APU'])
        self.assertEqual(norm_unit, 'M3')
        
        # Parsear números
        cantidad = utils.parse_number(apu_data['CANTIDAD'])
        precio = utils.parse_number(apu_data['PRECIO'])
        self.assertAlmostEqual(cantidad, 1234.56)
        self.assertAlmostEqual(precio, 2500.00)
        
        # Crear firma
        processed_data = {
            'CODIGO_APU': clean_code,
            'DESCRIPCION_APU': norm_desc,
            'UNIDAD_APU': norm_unit
        }
        signature = utils.create_apu_signature(processed_data)
        self.assertIsNotNone(signature)
    
    def test_dataframe_complete_processing(self):
        """Prueba procesamiento completo de DataFrame."""
        # Crear DataFrame de prueba
        df = pd.DataFrame({
            'cod_item': ['APU001', 'APU002', 'APU003'],
            'desc_item': ['Item 1', 'Item 2', 'Item 3'],
            'unidad': ['M2', 'KG', 'HORAS'],
            'cantidad': ['100,50', '200.75', '300'],
            'precio': ['$1,000', '€2,000', '3000.50']
        })
        
        # Renombrar columnas
        column_map = {
            'CODIGO': ['cod'],
            'DESCRIPCION': ['desc'],
            'UNIDAD': ['unidad'],
            'CANTIDAD': ['cantidad'],
            'PRECIO': ['precio']
        }
        
        df = utils.find_and_rename_columns(df, column_map)
        
        # Normalizar texto
        df['DESCRIPCION'] = utils.normalize_text_series(df['DESCRIPCION'])
        
        # Normalizar unidades
        df['UNIDAD'] = df['UNIDAD'].apply(utils.normalize_unit)
        
        # Parsear números
        df['CANTIDAD'] = df['CANTIDAD'].apply(utils.parse_number)
        df['PRECIO'] = df['PRECIO'].apply(utils.parse_number)
        
        # Validar resultados
        self.assertIn('CODIGO', df.columns)
        self.assertEqual(df['UNIDAD'].iloc[2], 'HR')
        self.assertAlmostEqual(df['CANTIDAD'].iloc[0], 100.50)
        
        # Detectar outliers en precios
        outliers = utils.detect_outliers(df['PRECIO'], method='iqr')
        self.assertEqual(len(outliers), len(df))
        
        # Calcular estadísticas
        stats = utils.calculate_statistics(df['PRECIO'])
        self.assertIn('mean', stats)
        self.assertIn('std', stats)

# ============================================================================
# PRUEBAS DE RENDIMIENTO Y ESTRÉS
# ============================================================================

class TestPerformance(unittest.TestCase):
    """Pruebas de rendimiento y casos de estrés."""
    
    def test_normalize_text_large_volume(self):
        """Prueba normalización con gran volumen de texto."""
        large_texts = [f"Texto número {i} con ñ, á, é" for i in range(10000)]
        
        # Debería completarse en tiempo razonable
        import time
        start = time.time()
        
        for text in large_texts[:1000]:  # Procesar subconjunto
            utils.normalize_text(text)
        
        elapsed = time.time() - start
        self.assertLess(elapsed, 5.0)  # Menos de 5 segundos
    
    def test_cache_memory_limit(self):
        """Prueba que el cache LRU respete límites de memoria."""
        # Limpiar cache
        utils.normalize_text.cache_clear()
        utils.clean_apu_code.cache_clear()
        utils.normalize_unit.cache_clear()
        
        # Llenar cache con muchas entradas únicas
        for i in range(2000):  # Más que el límite del cache
            utils.normalize_text(f"unique_text_{i}")
            if i % 100 == 0:
                utils.clean_apu_code(f"APU{i:04d}")
                utils.normalize_unit(f"UNIT{i}")
        
        # Verificar que el cache no exceda su límite
        cache_info = utils.normalize_text.cache_info()
        self.assertLessEqual(cache_info.currsize, 1024)  # Límite configurado
    
    def test_outlier_detection_large_series(self):
        """Prueba detección de outliers en series grandes."""
        np.random.seed(42)
        large_series = pd.Series(np.random.normal(100, 15, 100000))
        
        import time
        start = time.time()
        
        outliers = utils.detect_outliers(large_series, method='iqr')
        
        elapsed = time.time() - start
        self.assertLess(elapsed, 2.0)  # Debe ser eficiente
        self.assertEqual(len(outliers), len(large_series))

# ============================================================================
# PRUEBAS DE CASOS EXTREMOS Y SEGURIDAD
# ============================================================================

class TestEdgeCasesAndSecurity(unittest.TestCase):
    """Pruebas de casos extremos y aspectos de seguridad."""
    
    def test_handle_malformed_input(self):
        """Prueba manejo de entrada malformada."""
        malformed_inputs = [
            '\x00\x01\x02',  # Bytes no imprimibles
            '���',  # Caracteres corruptos
            'A' * 10000,  # String muy largo
            '',  # String vacío
            None,  # None
        ]
        
        for input_val in malformed_inputs:
            with self.subTest(input=input_val):
                # No debe lanzar excepción no controlada
                try:
                    utils.normalize_text(input_val or '')
                    utils.parse_number(input_val)
                    if input_val:
                        utils.clean_apu_code(input_val, validate_format=False)
                except (TypeError, ValueError) as e:
                    # Excepciones esperadas y controladas
                    pass
    
    def test_prevent_regex_dos(self):
        """Prueba prevención de ReDoS (Regular Expression Denial of Service)."""
        # Patrones que podrían causar ReDoS
        potentially_dangerous = [
            'a' * 1000 + 'X',
            '(' * 100 + ')' * 100,
            '\\' * 1000,
        ]
        
        for pattern in potentially_dangerous:
            with self.subTest(pattern=pattern[:20]):
                # No debe tomar tiempo excesivo
                import time
                start = time.time()
                
                utils.normalize_text(pattern)
                utils.clean_apu_code(pattern, validate_format=False)
                
                elapsed = time.time() - start
                self.assertLess(elapsed, 1.0)  # Menos de 1 segundo
    
    def test_handle_circular_references(self):
        """Prueba manejo de referencias circulares en sanitización."""
        # Crear estructura con referencia circular
        data = {'a': {}}
        data['a']['circular'] = data
        
        # No debe causar recursión infinita
        with self.assertRaises(RecursionError):
            # Se espera error controlado por límite de profundidad
            utils.sanitize_for_json(data, max_depth=10)

# ============================================================================
# SUITE DE PRUEBAS PRINCIPAL
# ============================================================================

def create_test_suite():
    """Crea y retorna la suite completa de pruebas."""
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # Agregar todas las clases de prueba
    test_classes = [
        TestTextNormalization,
        TestNumericConversion,
        TestAPUCode,
        TestUnitNormalization,
        TestFileReading,
        TestValidation,
        TestAnalysisDetection,
        TestDataFrameManipulation,
        TestSerialization,
        TestAdditionalFunctions,
        TestIntegration,
        TestPerformance,
        TestEdgeCasesAndSecurity,
    ]
    
    for test_class in test_classes:
        suite.addTests(loader.loadTestsFromTestCase(test_class))
    
    return suite

# ============================================================================
# PUNTO DE ENTRADA PRINCIPAL
# ============================================================================

if __name__ == '__main__':
    # Configurar logging para las pruebas
    logging.basicConfig(
        level=logging.WARNING,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Ejecutar pruebas con verbosidad
    runner = unittest.TextTestRunner(verbosity=2)
    
    # Crear y ejecutar suite
    suite = create_test_suite()
    result = runner.run(suite)
    
    # Imprimir resumen
    print("\n" + "="*70)
    print("RESUMEN DE PRUEBAS")
    print("="*70)
    print(f"Pruebas ejecutadas: {result.testsRun}")
    print(f"Exitosas: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"Fallos: {len(result.failures)}")
    print(f"Errores: {len(result.errors)}")
    print(f"Omitidas: {len(result.skipped)}")
    
    # Calcular cobertura si está disponible
    try:
        import coverage
        cov = coverage.Coverage()
        cov.start()
        suite = create_test_suite()
        runner.run(suite)
        cov.stop()
        print("\n" + "="*70)
        print("COBERTURA DE CÓDIGO")
        print("="*70)
        cov.report(include=['utils.py'])
    except ImportError:
        print("\nInstala 'coverage' para ver el reporte de cobertura:")
        print("pip install coverage")
    
    # Exit code basado en resultados
    sys.exit(0 if result.wasSuccessful() else 1)