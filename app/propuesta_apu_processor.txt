# ============================================================================
# MÉTODOS REFINADOS DEL TRANSFORMER CON ESTRUCTURA ALGEBRAICA
# ============================================================================

def line(self, args: List[Any]) -> Optional[InsumoProcesado]:
    """
    Procesa una línea parseada por Lark usando teoría de mónadas para manejo de efectos.
    
    MEJORAS TOPOLÓGICAS:
    1. Tratamiento categórico de la línea como functor
    2. Uso de mónadas Option/Maybe para manejo seguro de nulos
    3. Validación de invariantes algebraicos
    4. Composición funcional de transformaciones
    """
    # Functor: Mapear estructura cruda a campos semánticos
    fields_monad = self._extract_fields_as_monad(args)
    
    # Validación categórica: Verificar que tenemos un objeto inicial
    if not fields_monad.is_valid():
        logger.debug("Línea: estructura monádica inválida")
        return None
    
    fields = fields_monad.value
    
    # Álgebra: Composición de validaciones
    validation_chain = (
        self._validate_minimal_cardinality(fields)
        .bind(lambda f: self._validate_description_epicenter(f))
        .bind(lambda f: self._validate_structural_integrity(f))
        .bind(lambda f: self._validate_topological_connectivity(f))
    )
    
    if not validation_chain.is_valid():
        logger.debug(f"Línea falló validación algebraica: {validation_chain.error}")
        return None
    
    # Detección del grupo fundamental del formato
    formato = self._detect_format_categorical(fields)
    
    if formato == FormatoLinea.DESCONOCIDO:
        logger.debug(f"Línea: grupo fundamental desconocido para {fields[0][:50]}...")
        return None
    
    # Homomorfismo: Mapear formato a constructor
    constructor = self._get_format_homomorphism(formato)
    
    if constructor is None:
        logger.warning(f"No hay homomorfismo para formato: {formato}")
        return None
    
    # Aplicar morfismo conservando estructura
    try:
        # Inyectar contexto categórico
        categorical_context = {
            **self.apu_context,
            'formato_algebraico': formato.value,
            'campo_base': self._compute_base_field(fields),
            'grupo_simetria': self._detect_symmetry_group(fields)
        }
        
        # Aplicar transformación natural
        result = constructor(fields, categorical_context)
        
        # Verificar que el morfismo preserva la estructura
        if result and not self._validate_morphism_preservation(result, fields):
            logger.warning("Morfismo no preserva estructura algebraica")
            return None
            
        return result
        
    except ValueError as ve:
        logger.debug(f"Error de valor en morfismo {formato.value}: {ve}")
        return None
    except Exception as e:
        logger.error(f"Error categórico en {formato.value}: {type(e).__name__}: {e}")
        if self.config.get("debug_mode", False):
            import traceback
            logger.debug(f"Traceback:\n{traceback.format_exc()}")
        return None


def _extract_fields_as_monad(self, args: List[Any]) -> "OptionMonad":
    """
    Extrae campos usando estructura de mónada Option (Maybe).
    
    TEORÍA CATEGÓRICA:
    - Trata la extracción como un functor F: Raw → Option[Fields]
    - Preserva operación de composición (monoide)
    - Maneja efectos (tokens SEP) como morfismos cero
    """
    from typing import Generic, TypeVar, Callable
    
    # Definición interna de mónada Option
    T = TypeVar('T')
    
    class OptionMonad(Generic[T]):
        """Mónada Option/Maybe para manejo seguro de valores."""
        
        def __init__(self, value: Optional[T] = None, error: str = ""):
            self._value = value
            self._error = error
            
        def is_valid(self) -> bool:
            return self._value is not None
            
        @property
        def value(self) -> T:
            if self._value is None:
                raise ValueError(f"Acceso a valor inválido: {self._error}")
            return self._value
            
        def bind(self, f: Callable[[T], 'OptionMonad']) -> 'OptionMonad':
            """Operación bind de la mónada (>>=)."""
            if not self.is_valid():
                return self
            return f(self.value)
            
        def map(self, f: Callable[[T], T]) -> 'OptionMonad':
            """Operación map del functor."""
            if not self.is_valid():
                return self
            try:
                return OptionMonad(f(self.value))
            except Exception as e:
                return OptionMonad(error=f"Map error: {e}")
    
    if not args:
        return OptionMonad(error="Args vacío")
    
    fields = []
    structural_errors = []
    
    # Análisis de estructura categórica
    for i, arg in enumerate(args):
        # Morfismo de token a valor
        if isinstance(arg, Token):
            if arg.type == self._SEP_TOKEN_TYPE:
                # Morfismo cero: separador → None (preserva estructura)
                continue
            value = self._extract_value(arg)
            if value is not None:
                # Verificar homogeneidad algebraica
                if not self._validate_algebraic_homogeneity(value, i, fields):
                    structural_errors.append(f"Token {i} rompe homogeneidad: {value[:50]}")
                else:
                    fields.append(value)
        elif isinstance(arg, list):
            # Producto categórico: procesar lista recursivamente
            for sub_arg in arg:
                if isinstance(sub_arg, Token) and sub_arg.type == self._SEP_TOKEN_TYPE:
                    continue
                value = self._extract_value(sub_arg)
                if value is not None:
                    fields.append(value)
        else:
            # Morfismo directo
            value = self._extract_value(arg)
            if value is not None:
                fields.append(value)
    
    # Validar objeto terminal
    if structural_errors:
        logger.debug(f"Errores estructurales: {structural_errors}")
    
    if not fields:
        return OptionMonad(error="Todos los campos son morfismos cero")
    
    # Aplicar functor de normalización categórica
    normalized_fields = self._apply_categorical_normalization(fields)
    
    return OptionMonad(normalized_fields)


def _validate_algebraic_homogeneity(self, value: str, position: int, context: List[str]) -> bool:
    """
    Valida homogeneidad algebraica: cada campo debe pertenecer al mismo anillo.
    
    TEORÍA: Un campo debe ser compatible con sus vecinos en el anillo de campos.
    """
    if not value:
        return True
    
    # Determinar tipo algebraico del campo
    field_type = self._classify_field_algebraic_type(value)
    
    # Si es el primer campo, siempre es válido (generador del anillo)
    if position == 0:
        return True
    
    # Verificar compatibilidad con campo anterior
    if context:
        prev_field = context[-1]
        prev_type = self._classify_field_algebraic_type(prev_field)
        
        # Reglas de composición algebraica
        composition_rules = {
            ('ALPHA', 'ALPHA'): True,    # Palabras pueden seguir palabras
            ('ALPHA', 'NUMERIC'): True,   # Números pueden seguir palabras (cantidad)
            ('NUMERIC', 'ALPHA'): True,   # Palabras pueden seguir números (unidad)
            ('NUMERIC', 'NUMERIC'): True, # Números pueden seguir números (precio, total)
            ('ALPHA', 'MIXED'): True,     # Mixto puede seguir palabras
            ('MIXED', 'ALPHA'): True,     # Palabras pueden seguir mixto
            ('SEPARATOR', 'ALPHA'): True, # Palabra después de separador
            ('ALPHA', 'SEPARATOR'): True, # Separador después de palabra
        }
        
        return composition_rules.get((prev_type, field_type), False)
    
    return True


def _classify_field_algebraic_type(self, field: str) -> str:
    """Clasifica un campo en tipos algebraicos básicos."""
    if not field:
        return 'EMPTY'
    
    # Verificar si es principalmente alfabético
    alpha_ratio = sum(1 for c in field if c.isalpha()) / max(len(field), 1)
    digit_ratio = sum(1 for c in field if c.isdigit()) / max(len(field), 1)
    
    if alpha_ratio > 0.7 and digit_ratio < 0.3:
        return 'ALPHA'
    elif digit_ratio > 0.7 and alpha_ratio < 0.3:
        return 'NUMERIC'
    elif alpha_ratio > 0.3 and digit_ratio > 0.3:
        return 'MIXED'
    elif field.strip() in [';', ',', '.', ':', '-']:
        return 'SEPARATOR'
    else:
        return 'OTHER'


def _apply_categorical_normalization(self, fields: List[str]) -> List[str]:
    """
    Aplica normalización categórica para preservar estructura algebraica.
    
    TEORÍA: Reduce campos a forma normal sin perder información categórica.
    """
    normalized = []
    
    for i, field in enumerate(fields):
        # Aplicar functor de limpieza
        cleaned = field.strip()
        
        # Preservar información posicional (índice categórico)
        if i == 0:
            # Campo 0: objeto inicial (descripción)
            # Normalizar pero preservar estructura léxica
            cleaned = ' '.join(cleaned.split())  # Normalizar espacios
        elif i == 1:
            # Campo 1: morfismo a unidad
            cleaned = self.units_validator.normalize_unit(cleaned)
        else:
            # Campos restantes: posibles valores numéricos
            # Preservar formato decimal consistente
            if self._looks_numeric(cleaned):
                cleaned = self._normalize_numeric_representation(cleaned)
        
        # Validar longitud categórica (invariante)
        if len(cleaned) > self._MAX_DESCRIPTION_LENGTH:
            logger.warning(f"Campo {i} truncado categóricamente")
            cleaned = cleaned[:self._MAX_DESCRIPTION_LENGTH]
            
        normalized.append(cleaned)
    
    # Eliminar campos vacíos terminales (morfismos cero al final)
    while normalized and not normalized[-1].strip():
        normalized.pop()
    
    return normalized


def _looks_numeric(self, field: str) -> bool:
    """Determina si un campo parece ser numérico categóricamente."""
    if not field:
        return False
    
    # Eliminar caracteres no numéricos comunes
    cleaned = field.replace(',', '.').replace('$', '').replace('%', '').strip()
    
    # Verificar estructura numérica
    if not cleaned:
        return False
    
    # Patrón: número opcionalmente con decimales
    import re
    pattern = r'^-?\d+(\.\d+)?$'
    return bool(re.match(pattern, cleaned))


def _normalize_numeric_representation(self, field: str) -> str:
    """Normaliza representación numérica a forma canónica."""
    # Usar el separador decimal del perfil
    decimal_sep = self.profile.get('number_format', {}).get('decimal_separator', '.')
    
    # Convertir a representación estándar
    if ',' in field and '.' in field:
        # Caso: 1.234,56 → determinar cuál es separador decimal
        if field.rfind('.') > field.rfind(','):
            # Punto es decimal: 1.234,56 → 1234.56
            field = field.replace('.', '').replace(',', '.')
        else:
            # Coma es decimal: 1,234.56 → 1234.56
            field = field.replace(',', '').replace('.', '')
    elif ',' in field:
        # Coma como separador decimal
        if decimal_sep == '.':
            field = field.replace(',', '.')
    elif '.' in field:
        # Punto como separador decimal
        if decimal_sep == ',':
            field = field.replace('.', ',')
    
    return field


def _validate_minimal_cardinality(self, fields: List[str]) -> "OptionMonad":
    """Valida cardinalidad mínima (teoría de conjuntos)."""
    if len(fields) < self._MIN_FIELDS_FOR_VALID_LINE:
        error_msg = f"Cardinalidad insuficiente: |fields|={len(fields)} < {self._MIN_FIELDS_FOR_VALID_LINE}"
        return OptionMonad(error=error_msg)
    return OptionMonad(fields)


def _validate_description_epicenter(self, fields: List[str]) -> "OptionMonad":
    """Valida que el campo de descripción sea epicéntrico (no vacío)."""
    if not fields or not fields[0] or not fields[0].strip():
        return OptionMonad(error="Descripción es morfismo cero (vacío)")
    return OptionMonad(fields)


def _validate_structural_integrity(self, fields: List[str]) -> "OptionMonad":
    """Valida integridad estructural usando teoría de grafos."""
    # Construir grafo de dependencias entre campos
    dependency_graph = self._build_field_dependency_graph(fields)
    
    # Verificar que el grafo sea conexo
    if not self._is_graph_connected(dependency_graph):
        return OptionMonad(error="Grafo de campos no conexo")
    
    # Verificar que no haya ciclos negativos (dependencias circulares)
    if self._has_negative_cycles(dependency_graph):
        return OptionMonad(error="Ciclos negativos en dependencias")
    
    return OptionMonad(fields)


def _validate_topological_connectivity(self, fields: List[str]) -> "OptionMonad":
    """Valida conectividad topológica entre campos."""
    # Calcular distancia de edición promedio entre campos consecutivos
    edit_distances = []
    for i in range(len(fields) - 1):
        dist = self._compute_levenshtein_distance(fields[i], fields[i + 1])
        edit_distances.append(dist)
    
    # La distancia no debe ser demasiado grande (campos desconectados)
    # ni demasiado pequeña (campos duplicados)
    avg_distance = sum(edit_distances) / len(edit_distances) if edit_distances else 0
    
    if avg_distance > 50:  # Campos muy diferentes
        return OptionMonad(error="Campos topológicamente desconectados")
    
    if avg_distance < 2 and len(fields) > 3:  # Campos muy similares
        return OptionMonad(error="Campos topológicamente redundantes")
    
    return OptionMonad(fields)


def _detect_format_categorical(self, fields: List[str]) -> FormatoLinea:
    """
    Detección categórica de formato usando teoría de tipos.
    
    MEJORAS:
    1. Clasificación basada en tipos algebraicos
    2. Detección de isomorfismos entre formatos
    3. Validación de congruencia estructural
    """
    if not fields or not fields[0]:
        return FormatoLinea.DESCONOCIDO
    
    descripcion = fields[0].strip()
    num_fields = len(fields)
    
    # Tipo algebraico de la línea
    line_type = self._compute_algebraic_type(fields)
    
    # Filtrado categórico de ruido
    if self._is_categorical_noise(descripcion, num_fields, line_type):
        return FormatoLinea.DESCONOCIDO
    
    # Clasificación por teoría de tipos
    tipo_probable = self._classify_by_type_theory(descripcion, fields)
    
    # Verificar isomorfismo con formato MO_COMPLETA
    if (tipo_probable == TipoInsumo.MANO_DE_OBRA and 
        self._is_isomorphic_to_mo_format(fields)):
        logger.debug(f"MO_COMPLETA detectado categóricamente: {descripcion[:30]}...")
        return FormatoLinea.MO_COMPLETA
    
    # Verificar isomorfismo con formato INSUMO_BASICO
    if self._is_isomorphic_to_basic_format(fields):
        logger.debug(f"INSUMO_BASICO detectado categóricamente: {descripcion[:30]}...")
        return FormatoLinea.INSUMO_BASICO
    
    return FormatoLinea.DESCONOCIDO


def _compute_algebraic_type(self, fields: List[str]) -> Dict[str, Any]:
    """Calcula el tipo algebraico de una línea."""
    # Distribución de tipos por campo
    type_distribution = defaultdict(int)
    for field in fields:
        field_type = self._classify_field_algebraic_type(field)
        type_distribution[field_type] += 1
    
    # Características topológicas
    numeric_ratio = sum(1 for f in fields[1:] if self._looks_numeric(f)) / max(len(fields) - 1, 1)
    
    return {
        'type_distribution': dict(type_distribution),
        'numeric_ratio': numeric_ratio,
        'entropy': self._compute_type_entropy(type_distribution),
        'first_field_type': self._classify_field_algebraic_type(fields[0]) if fields else 'EMPTY'
    }


def _compute_type_entropy(self, distribution: Dict[str, int]) -> float:
    """Calcula la entropía de la distribución de tipos."""
    from math import log2
    
    total = sum(distribution.values())
    if total == 0:
        return 0.0
    
    entropy = 0.0
    for count in distribution.values():
        p = count / total
        entropy -= p * log2(p) if p > 0 else 0
    
    return entropy


def _is_categorical_noise(self, descripcion: str, num_fields: int, line_type: Dict) -> bool:
    """Detección categórica de ruido usando teoría de información."""
    # Ruido de baja entropía (muy homogéneo)
    if line_type['entropy'] < 0.5 and num_fields > 3:
        return True
    
    # Ruido de alta redundancia (muchos campos del mismo tipo)
    if max(line_type['type_distribution'].values(), default=0) / num_fields > 0.8:
        return True
    
    # Ruido semántico usando PatternMatcher
    if self.pattern_matcher.is_likely_summary(descripcion, num_fields):
        logger.debug(f"Línea de resumen (categórica): {descripcion[:30]}...")
        return True
    
    if self.pattern_matcher.is_likely_header(descripcion, num_fields):
        logger.debug(f"Línea de encabezado (categórica): {descripcion[:30]}...")
        return True
    
    if self.pattern_matcher.is_likely_category(descripcion, num_fields):
        logger.debug(f"Línea de categoría (categórica): {descripcion[:30]}...")
        return True
    
    return False


def _classify_by_type_theory(self, descripcion: str, fields: List[str]) -> TipoInsumo:
    """Clasificación usando teoría de tipos y lógica intuicionista."""
    # Primero, buscar tipos fuertes (evidencia directa)
    strong_evidence = self._find_strong_type_evidence(descripcion)
    if strong_evidence:
        return strong_evidence
    
    # Luego, inferir por tipo estructural
    structural_type = self._infer_by_structural_type(fields)
    if structural_type:
        return structural_type
    
    # Finalmente, usar clasificación léxica como fallback
    return self._classify_insumo(descripcion)


def _find_strong_type_evidence(self, descripcion: str) -> Optional[TipoInsumo]:
    """Busca evidencia fuerte de tipo en la descripción."""
    desc_upper = descripcion.upper()
    
    # Evidencia fuerte: patrones inequívocos
    strong_patterns = {
        TipoInsumo.MANO_DE_OBRA: [
            r'\bPEON\b', r'\bOFICIAL\b', r'\bOPERARIO\b', r'\bJORNAL\b',
            r'\bAYUDANTE\b', r'\bSUPERVISOR\b', r'\bINGENIERO\b'
        ],
        TipoInsumo.EQUIPO: [
            r'\bEXCAVADORA\b', r'\bRETROEXCAVADORA\b', r'\bVOLQUETA\b',
            r'\bCOMPACTADOR\b', r'\bGRUA\b', r'\bMARTILLO\b'
        ],
        TipoInsumo.TRANSPORTE: [
            r'\bACARREO\b', r'\bFLETE\b', r'\bTRANSPORTE\b',
            r'\bVIAJE\b', r'\bDISTANCIA\b', r'\bKM\b'
        ]
    }
    
    for tipo, patterns in strong_patterns.items():
        for pattern in patterns:
            if re.search(pattern, desc_upper):
                return tipo
    
    return None


def _infer_by_structural_type(self, fields: List[str]) -> Optional[TipoInsumo]:
    """Infere tipo por características estructurales."""
    if len(fields) < 3:
        return None
    
    # Análisis estructural
    numeric_values = self.numeric_extractor.extract_all_numeric_values(fields)
    
    # Heurística 1: Mano de obra tiene jornal y rendimiento
    mo_values = self.numeric_extractor.identify_mo_values(numeric_values)
    if mo_values:
        return TipoInsumo.MANO_DE_OBRA
    
    # Heurística 2: Equipo tiene valores grandes y unidad temporal
    unit = fields[1] if len(fields) > 1 else ""
    if unit.upper() in ['HORA', 'HR', 'DIA', 'DÍA', 'MES'] and numeric_values:
        max_value = max(numeric_values) if numeric_values else 0
        if max_value > 10000:  # Valores grandes sugieren equipo
            return TipoInsumo.EQUIPO
    
    # Heurística 3: Transporte tiene unidad de distancia o viaje
    if unit.upper() in ['KM', 'MILLA', 'VIAJE', 'VJE']:
        return TipoInsumo.TRANSPORTE
    
    return None


def _is_isomorphic_to_mo_format(self, fields: List[str]) -> bool:
    """
    Verifica isomorfismo con formato MO_COMPLETA.
    
    Dos estructuras son isomorfas si existe un biyección que preserve
    las relaciones estructurales.
    """
    if len(fields) < 5:
        return False
    
    # Construir grafo estructural de la línea
    line_graph = self._build_structural_graph(fields)
    
    # Grafo canónico de MO_COMPLETA
    mo_canonical_graph = {
        'nodes': ['DESC', 'UNIT', 'REND', 'JORNAL', 'TOTAL'],
        'edges': [
            ('DESC', 'UNIT'), ('UNIT', 'REND'), 
            ('REND', 'JORNAL'), ('JORNAL', 'TOTAL')
        ],
        'node_types': {
            'DESC': 'ALPHA', 'UNIT': 'ALPHA', 
            'REND': 'NUMERIC', 'JORNAL': 'NUMERIC', 'TOTAL': 'NUMERIC'
        }
    }
    
    # Verificar isomorfismo de grafos
    return self._check_graph_isomorphism(line_graph, mo_canonical_graph)


def _is_isomorphic_to_basic_format(self, fields: List[str]) -> bool:
    """Verifica isomorfismo con formato INSUMO_BASICO."""
    if len(fields) < 4:
        return False
    
    # Extraer valores numéricos
    numeric_values = self.numeric_extractor.extract_all_numeric_values(fields)
    
    # Condición de isomorfismo: al menos 2 valores numéricos
    # y estructura DESC → UNIT → VAL1 → VAL2
    if len(numeric_values) >= 2:
        # Verificar morfismo de tipos
        type_sequence = [self._classify_field_algebraic_type(f) for f in fields[:4]]
        
        # Secuencia canónica: ALPHA, ALPHA, NUMERIC, NUMERIC
        canonical = ['ALPHA', 'ALPHA', 'NUMERIC', 'NUMERIC']
        
        # Verificar homomorfismo (no necesariamente isomorfismo estricto)
        matches = sum(1 for t, c in zip(type_sequence, canonical) if t == c)
        return matches >= 3  # Al menos 3 de 4 coinciden
    
    return False


def _get_format_homomorphism(self, formato: FormatoLinea):
    """Obtiene el homomorfismo (functor) para un formato."""
    builder_map = {
        FormatoLinea.MO_COMPLETA: self._build_mo_completa_categorical,
        FormatoLinea.INSUMO_BASICO: self._build_insumo_basico_categorical,
    }
    return builder_map.get(formato)


def _build_mo_completa_categorical(self, fields: List[str], context: Dict) -> Optional[ManoDeObra]:
    """
    Construye ManoDeObra usando teoría categórica.
    
    TRATA la construcción como un functor F: Fields → ManoDeObra
    que preserva la estructura algebraica.
    """
    try:
        # Extraer componentes canónicos
        descripcion = fields[0]
        unidad = self.units_validator.normalize_unit(fields[1]) if len(fields) > 1 else "JOR"
        
        # Aplicar functor de extracción numérica
        numeric_values = self.numeric_extractor.extract_all_numeric_values(fields)
        
        # Buscar morfismo a valores MO
        mo_values = self.numeric_extractor.identify_mo_values(numeric_values)
        
        if not mo_values:
            # Intentar reconstrucción categórica
            mo_values = self._reconstruct_mo_values_categorical(fields, numeric_values)
            if not mo_values:
                logger.debug("No se pudo reconstruir valores MO categóricamente")
                return None
        
        rendimiento, jornal = mo_values
        
        # Validar congruencia algebraica
        if not self._validate_algebraic_congruence(rendimiento, jornal):
            logger.debug("Valores MO no congruentes algebraicamente")
            return None
        
        # Cálculos categóricos (preservan operaciones)
        cantidad = 1.0 / rendimiento if rendimiento > 0 else 0
        valor_total = cantidad * jornal
        
        if cantidad <= 0 or valor_total <= 0:
            return None
        
        # Construir objeto preservando contexto categórico
        mo_context = {
            **context,
            'algebraic_type': 'MO_COMPLETA',
            'base_field': self._compute_base_field(fields),
            'symmetry_group': 'U(1)',  # Grupo de simetría de MO
            'tensor_rank': 2  # Rendimiento y jornal como tensor de rango 2
        }
        
        return ManoDeObra(
            descripcion_insumo=descripcion,
            unidad_insumo=unidad,
            cantidad=round(cantidad, 6),
            precio_unitario=round(jornal, 2),
            valor_total=round(valor_total, 2),
            rendimiento=round(rendimiento, 6),
            formato_origen="MO_COMPLETA_CATEGORICAL",
            tipo_insumo="MANO_DE_OBRA",
            **mo_context,
        )
        
    except Exception as e:
        logger.error(f"Error en functor MO_COMPLETA: {e}")
        return None


def _build_insumo_basico_categorical(self, fields: List[str], context: Dict) -> Optional[InsumoProcesado]:
    """
    Construye insumo básico usando teoría de tipos dependientes.
    
    TRATA cada campo como un tipo dependiente del anterior.
    """
    try:
        if len(fields) < 3:
            return None
        
        descripcion = fields[0]
        unidad = self.units_validator.normalize_unit(fields[1]) if len(fields) > 1 else "UND"
        
        # Determinar tipo por teoría de tipos
        tipo_insumo = self._classify_by_type_theory(descripcion, fields)
        
        # Manejo especial para tipos algebraicos especiales
        if unidad == "%" or tipo_insumo == TipoInsumo.OTRO:
            return self._build_insumo_especial_categorical(fields, tipo_insumo, unidad, context)
        
        # Extraer valores con tipos dependientes
        valores = self.numeric_extractor.extract_insumo_values(fields)
        
        if len(valores) < 2:
            return None
        
        # Reconstrucción categórica de valores
        cantidad, precio, total = self._reconstruct_values_categorical(valores, fields)
        
        if total <= 0 or cantidad <= 0:
            return None
        
        # Determinar clase por teoría de categorías
        InsumoClass = self._get_insumo_class_by_category_theory(tipo_insumo, fields)
        
        # Contexto categórico
        cat_context = {
            **context,
            'algebraic_type': 'INSUMO_BASICO',
            'dependent_types': self._compute_dependent_types(fields),
            'functor_category': 'Vect_k'  # Categoría de espacios vectoriales
        }
        
        return InsumoClass(
            descripcion_insumo=descripcion,
            unidad_insumo=unidad,
            cantidad=round(cantidad, 6),
            precio_unitario=round(precio, 2),
            valor_total=round(total, 2),
            rendimiento=round(cantidad, 6),
            formato_origen="INSUMO_BASICO_CATEGORICAL",
            tipo_insumo=tipo_insumo.value,
            **cat_context,
        )
        
    except Exception as e:
        logger.error(f"Error en functor INSUMO_BASICO: {e}")
        return None


def _reconstruct_values_categorical(self, valores: List[float], fields: List[str]) -> Tuple[float, float, float]:
    """Reconstruye valores usando teoría de reconstrucción algebraica."""
    if len(valores) == 4:
        cantidad, _, precio, total = valores
    elif len(valores) == 3:
        cantidad, precio, total = valores
    elif len(valores) == 2:
        cantidad, precio = valores
        total = cantidad * precio
    else:
        # Reconstrucción algebraica desde campos
        cantidad, precio, total = self._algebraic_reconstruction(fields)
    
    # Ajuste categórico: preservar relaciones algebraicas
    if cantidad > 0 and total > 0 and precio == 0:
        precio = total / cantidad
    elif precio > 0 and cantidad == 0 and total > 0:
        cantidad = total / precio
    
    return cantidad, precio, total


def _algebraic_reconstruction(self, fields: List[str]) -> Tuple[float, float, float]:
    """Reconstrucción algebraica de valores desde campos."""
    # Buscar patrones algebraicos en los campos
    patterns = [
        # Patrón: cantidad * precio = total
        (r'(\d+\.?\d*)\s*[*x]\s*(\d+\.?\d*)\s*=\s*(\d+\.?\d*)', (1, 2, 3)),
        # Patrón: total / cantidad = precio
        (r'(\d+\.?\d*)\s*/\s*(\d+\.?\d*)\s*=\s*(\d+\.?\d*)', (3, 1, 2)),
    ]
    
    for field in fields:
        for pattern, order in patterns:
            match = re.search(pattern, field)
            if match:
                values = [float(match.group(i)) for i in range(1, 4)]
                # Reordenar según patrón
                return (values[order[0]-1], values[order[1]-1], values[order[2]-1])
    
    # Fallback: usar últimos 3 valores numéricos
    numeric_values = self.numeric_extractor.extract_all_numeric_values(fields, skip_first=False)
    if len(numeric_values) >= 3:
        return tuple(numeric_values[-3:])
    
    return (0.0, 0.0, 0.0)


def _compute_base_field(self, fields: List[str]) -> str:
    """Calcula el campo base (característica) de la línea."""
    # El campo base es el tipo algebraico predominante
    type_counts = defaultdict(int)
    for field in fields:
        field_type = self._classify_field_algebraic_type(field)
        type_counts[field_type] += 1
    
    if not type_counts:
        return "Z"
    
    # Determinar campo por tipo predominante
    predominant = max(type_counts.items(), key=lambda x: x[1])[0]
    
    field_map = {
        'ALPHA': 'Q',      # Racionales (descripciones)
        'NUMERIC': 'R',    # Reales (valores)
        'MIXED': 'C',      # Complejos (mixtos)
        'SEPARATOR': 'Z_p' # Campos finitos (separadores)
    }
    
    return field_map.get(predominant, 'F')


def _detect_symmetry_group(self, fields: List[str]) -> str:
    """Detecta el grupo de simetría de la línea."""
    # Análisis de simetrías en la estructura
    symmetries = []
    
    # Simetría por reflexión (palíndromo de tipos)
    type_sequence = [self._classify_field_algebraic_type(f) for f in fields]
    if type_sequence == type_sequence[::-1]:
        symmetries.append('Z_2')  # Grupo cíclico de orden 2
    
    # Simetría por traslación (patrones repetitivos)
    if len(fields) >= 4:
        pattern_length = self._find_repetition_pattern(type_sequence)
        if pattern_length > 1:
            symmetries.append(f'Z_{pattern_length}')
    
    # Simetría continua (campos numéricos)
    numeric_count = sum(1 for t in type_sequence if t == 'NUMERIC')
    if numeric_count >= 2:
        symmetries.append('U(1)')  # Grupo unitario
    
    return ' × '.join(symmetries) if symmetries else 'Trivial'


def _find_repetition_pattern(self, sequence: List) -> int:
    """Encuentra patrones de repetición en una secuencia."""
    n = len(sequence)
    for pattern_len in range(1, n // 2 + 1):
        if n % pattern_len == 0:
            pattern = sequence[:pattern_len]
            if all(sequence[i:i+pattern_len] == pattern 
                   for i in range(pattern_len, n, pattern_len)):
                return pattern_len
    return 0


def _build_structural_graph(self, fields: List[str]) -> Dict:
    """Construye grafo estructural de la línea."""
    nodes = [f'F{i}' for i in range(len(fields))]
    
    # Tipos de nodos
    node_types = {}
    for i, field in enumerate(fields):
        node_types[f'F{i}'] = self._classify_field_algebraic_type(field)
    
    # Aristas por adyacencia
    edges = []
    for i in range(len(fields) - 1):
        edges.append((f'F{i}', f'F{i+1}'))
    
    # Aristas por relaciones semánticas
    semantic_edges = self._find_semantic_relations(fields)
    edges.extend(semantic_edges)
    
    return {
        'nodes': nodes,
        'edges': edges,
        'node_types': node_types,
        'field_values': fields
    }


def _find_semantic_relations(self, fields: List[str]) -> List[Tuple[str, str]]:
    """Encuentra relaciones semánticas entre campos."""
    relations = []
    
    # Relación descripción → unidad (si la unidad aparece en la descripción)
    if len(fields) > 1:
        desc_lower = fields[0].lower()
        unit = fields[1].lower()
        if unit in desc_lower:
            relations.append(('F0', 'F1'))
    
    # Relaciones numéricas (cantidad → precio → total)
    for i in range(1, len(fields) - 1):
        if (self._looks_numeric(fields[i]) and 
            self._looks_numeric(fields[i + 1])):
            relations.append((f'F{i}', f'F{i+1}'))
    
    return relations


def _check_graph_isomorphism(self, g1: Dict, g2: Dict) -> bool:
    """Verifica isomorfismo aproximado entre grafos."""
    # Verificación simplificada
    if len(g1['nodes']) != len(g2['nodes']):
        return False
    
    # Verificar distribución de tipos
    type_count1 = defaultdict(int)
    for t in g1['node_types'].values():
        type_count1[t] += 1
    
    type_count2 = defaultdict(int)
    for t in g2['node_types'].values():
        type_count2[t] += 1
    
    if type_count1 != type_count2:
        return False
    
    # Verificar estructura de adyacencia
    degree_seq1 = sorted([len([e for e in g1['edges'] if n in e]) 
                         for n in g1['nodes']])
    degree_seq2 = sorted([len([e for e in g2['edges'] if n in e]) 
                         for n in g2['nodes']])
    
    return degree_seq1 == degree_seq2


def _validate_morphism_preservation(self, result: InsumoProcesado, 
                                   original_fields: List[str]) -> bool:
    """Valida que el morfismo preserva la estructura algebraica."""
    # Verificar que valores numéricos no sean negativos
    if (hasattr(result, 'valor_total') and result.valor_total < 0):
        return False
    
    if (hasattr(result, 'cantidad') and result.cantidad < 0):
        return False
    
    if (hasattr(result, 'precio_unitario') and result.precio_unitario < 0):
        return False
    
    # Verificar consistencia algebraica: cantidad * precio ≈ total
    if (hasattr(result, 'cantidad') and hasattr(result, 'precio_unitario') 
        and hasattr(result, 'valor_total')):
        calculated = result.cantidad * result.precio_unitario
        if calculated > 0:
            ratio = result.valor_total / calculated
            if not (0.9 <= ratio <= 1.1):  # 10% de tolerancia
                logger.debug(f"Inconsistencia algebraica: {result.valor_total} ≠ {calculated}")
                return False
    
    # Verificar que la descripción no se perdió
    if (hasattr(result, 'descripcion_insumo') and 
        not result.descripcion_insumo):
        return False
    
    return True


def _reconstruct_mo_values_categorical(self, fields: List[str], 
                                       numeric_values: List[float]) -> Optional[Tuple[float, float]]:
    """
    Reconstrucción categórica de valores MO usando teoría de representación.
    
    Intenta encontrar una representación fiel del par (rendimiento, jornal)
    en el espacio de valores numéricos.
    """
    if len(numeric_values) < 2:
        return None
    
    # Teoría de representación: buscar representantes de las clases
    # de equivalencia para rendimiento y jornal
    
    # Clasificar valores por magnitud
    small_vals = [v for v in numeric_values if v <= self.thresholds.max_rendimiento_tipico]
    large_vals = [v for v in numeric_values if v >= self.thresholds.min_jornal]
    
    # Caso ideal: tenemos candidatos claros
    if small_vals and large_vals:
        rendimiento = min(small_vals)
        jornal = max(large_vals)
        return rendimiento, jornal
    
    # Caso degenerado: inferir por teoría de números
    if len(numeric_values) >= 2:
        sorted_vals = sorted(numeric_values)
        
        # Hipótesis 1: El menor es rendimiento, el mayor es jornal
        if sorted_vals[0] <= 1000 and sorted_vals[-1] >= 1000:
            return sorted_vals[0], sorted_vals[-1]
        
        # Hipótesis 2: Los dos mayores son jornal y algo relacionado
        # Buscar par que tenga relación de división razonable
        for i in range(len(sorted_vals)):
            for j in range(i + 1, len(sorted_vals)):
                ratio = sorted_vals[j] / sorted_vals[i]
                if 10 <= ratio <= 10000:  # Rango razonable jornal/rendimiento
                    # El mayor es jornal, el menor es rendimiento
                    return sorted_vals[i], sorted_vals[j]
    
    return None


def _validate_algebraic_congruence(self, rendimiento: float, jornal: float) -> bool:
    """Valida congruencia algebraica entre rendimiento y jornal."""
    # No pueden ser cero o negativos
    if rendimiento <= 0 or jornal <= 0:
        return False
    
    # La relación debe estar en un rango razonable
    ratio = jornal / rendimiento
    
    # Un jornal típico está entre 50,000 y 10,000,000
    # Un rendimiento típico está entre 0.001 y 100
    # La relación típica está entre 500 y 10,000,000,000
    
    min_ratio = self.thresholds.min_jornal / self.thresholds.max_rendimiento_tipico
    max_ratio = self.thresholds.max_jornal / self.thresholds.min_rendimiento
    
    return min_ratio <= ratio <= max_ratio


def _build_insumo_especial_categorical(self, fields: List[str], 
                                       tipo_insumo: TipoInsumo,
                                       unidad: str,
                                       context: Dict) -> Optional[InsumoProcesado]:
    """Construye insumos especiales (porcentuales, indirectos) categóricamente."""
    descripcion = fields[0]
    
    # Extraer valores preservando estructura
    valores = self.numeric_extractor.extract_all_numeric_values(fields, skip_first=False)
    
    if not valores:
        return None
    
    # Teoría de valores: el valor total es el invariante principal
    total = valores[-1]  # Convención: último valor es total
    
    if total <= 0:
        return None
    
    # Para insumos especiales, la cantidad es 1 (unidad del concepto)
    cantidad = 1.0
    precio = total
    
    # Determinar clase por teoría de categorías
    InsumoClass = self._get_insumo_class_by_category_theory(tipo_insumo, fields)
    
    # Contexto algebraico especial
    special_context = {
        **context,
        'algebraic_type': 'SPECIAL',
        'is_percentage': unidad == '%',
        'value_semantics': 'INVARIANT',
        'functor_category': 'Set'  # Categoría de conjuntos
    }
    
    return InsumoClass(
        descripcion_insumo=descripcion,
        unidad_insumo=unidad,
        cantidad=round(cantidad, 6),
        precio_unitario=round(precio, 2),
        valor_total=round(total, 2),
        rendimiento=0.0,
        formato_origen="INSUMO_ESPECIAL_CATEGORICAL",
        tipo_insumo=tipo_insumo.value,
        **special_context,
    )


def _get_insumo_class_by_category_theory(self, tipo_insumo: TipoInsumo, 
                                         fields: List[str]):
    """
    Determina clase de insumo usando teoría de categorías.
    
    Considera no solo el tipo, sino también la estructura de los campos.
    """
    # Mapeo base por tipo
    class_mapping = {
        TipoInsumo.MANO_DE_OBRA: ManoDeObra,
        TipoInsumo.EQUIPO: Equipo,
        TipoInsumo.TRANSPORTE: Transporte,
        TipoInsumo.SUMINISTRO: Suministro,
        TipoInsumo.OTRO: Otro,
    }
    
    base_class = class_mapping.get(tipo_insumo, Suministro)
    
    # Ajustar por características estructurales
    if tipo_insumo == TipoInsumo.SUMINISTRO:
        # Verificar si es realmente equipo por valores grandes
        numeric_values = self.numeric_extractor.extract_all_numeric_values(fields)
        if numeric_values and max(numeric_values) > 100000:
            return Equipo
    
    return base_class


def _compute_dependent_types(self, fields: List[str]) -> Dict[str, str]:
    """Calcula tipos dependientes para la línea."""
    dependent_types = {}
    
    for i, field in enumerate(fields):
        field_type = self._classify_field_algebraic_type(field)
        
        # Tipo dependiente del anterior
        if i > 0:
            prev_type = self._classify_field_algebraic_type(fields[i-1])
            dependent_types[f'F{i}'] = f'{field_type} | {prev_type}'
        else:
            dependent_types[f'F{i}'] = f'{field_type}'
    
    return dependent_types


def _build_field_dependency_graph(self, fields: List[str]) -> Dict[int, List[int]]:
    """Construye grafo de dependencias entre campos."""
    graph = defaultdict(list)
    
    for i in range(len(fields)):
        # Dependencias posicionales (campos adyacentes)
        if i > 0:
            graph[i].append(i-1)
        if i < len(fields) - 1:
            graph[i].append(i+1)
        
        # Dependencias semánticas
        for j in range(len(fields)):
            if i != j and self._fields_are_semantically_related(fields[i], fields[j]):
                graph[i].append(j)
    
    return dict(graph)


def _fields_are_semantically_related(self, field1: str, field2: str) -> bool:
    """Determina si dos campos están semánticamente relacionados."""
    # Coincidencia léxica
    if field1 and field2 and (field1 in field2 or field2 in field1):
        return True
    
    # Relación numérica
    if self._looks_numeric(field1) and self._looks_numeric(field2):
        try:
            val1 = float(self._normalize_numeric_representation(field1))
            val2 = float(self._normalize_numeric_representation(field2))
            
            # Relación multiplicativa simple
            if val1 > 0 and val2 > 0:
                ratio = max(val1, val2) / min(val1, val2)
                return 0.9 <= ratio <= 1.1 or 2 <= ratio <= 10
        except:
            pass
    
    return False


def _is_graph_connected(self, graph: Dict[int, List[int]]) -> bool:
    """Verifica si un grafo es conexo."""
    if not graph:
        return True
    
    # BFS desde el primer nodo
    visited = set()
    stack = [next(iter(graph))]
    
    while stack:
        node = stack.pop()
        if node not in visited:
            visited.add(node)
            stack.extend(graph.get(node, []))
    
    return len(visited) == len(graph)


def _has_negative_cycles(self, graph: Dict[int, List[int]]) -> bool:
    """Verifica si hay ciclos negativos (dependencias circulares problemáticas)."""
    # Para un grafo no ponderado, buscamos ciclos simples
    visited = set()
    rec_stack = set()
    
    def dfs(node):
        visited.add(node)
        rec_stack.add(node)
        
        for neighbor in graph.get(node, []):
            if neighbor not in visited:
                if dfs(neighbor):
                    return True
            elif neighbor in rec_stack:
                # Ciclo detectado
                return True
        
        rec_stack.remove(node)
        return False
    
    for node in graph:
        if node not in visited:
            if dfs(node):
                return True
    
    return False


def _compute_levenshtein_distance(self, s1: str, s2: str) -> int:
    """Calcula distancia de Levenshtein entre dos cadenas."""
    if len(s1) < len(s2):
        return self._compute_levenshtein_distance(s2, s1)
    
    if len(s2) == 0:
        return len(s1)
    
    previous_row = range(len(s2) + 1)
    for i, c1 in enumerate(s1):
        current_row = [i + 1]
        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row
    
    return previous_row[-1]


# ============================================================================
# MÉTODOS REFINADOS DEL PROCESADOR PRINCIPAL
# ============================================================================

def _process_apu_lines_categorical(
    self,
    lines: List[str],
    apu_context: Dict[str, Any],
    line_cache: Optional[Dict[str, Any]] = None,
) -> List["InsumoProcesado"]:
    """
    Procesa líneas de APU usando teoría categórica.
    
    MEJORAS:
    1. Tratamiento de líneas como objetos en una categoría
    2. Uso de funtores para transformaciones
    3. Validación de morfismos entre estados
    4. Preservación de invariantes algebraicos
    """
    if not lines:
        return []
    
    if self.parser is None:
        logger.error("Parser no inicializado categóricamente")
        return []
    
    results = []
    stats = ParsingStats()
    apu_code = apu_context.get("codigo_apu", "UNKNOWN")
    
    # Cache categórico: mapeo línea → objeto parseado
    categorical_cache = self._build_categorical_cache(line_cache)
    
    # Functor de transformación para este APU
    transformer = APUTransformer(
        apu_context, self.config, self.profile, self.keyword_cache
    )
    
    logger.debug(
        f"Procesando categóricamente {len(lines)} líneas para APU: {apu_code} "
        f"(cache categórico: {len(categorical_cache)} objetos)"
    )
    
    for line_num, line in enumerate(lines, start=1):
        # Validación categórica de línea
        if not self._is_valid_line_categorical(line):
            continue
        
        stats.total_lines += 1
        line_clean = line.strip()
        
        # Detección de morfismos especiales (capítulos)
        if transformer.pattern_matcher.is_likely_chapter_header(line_clean):
            self.current_chapter = line_clean
            logger.debug(f"Capítulo categórico: {self.current_chapter}")
            continue
        
        # Inyectar contexto categórico
        apu_context["capitulo"] = self.current_chapter
        
        # Buscar en cache categórico
        cache_key = self._compute_categorical_cache_key(line_clean)
        cached_obj = categorical_cache.get(cache_key)
        
        if cached_obj and self._is_valid_cached_object(cached_obj):
            # Usar objeto cacheado (morfismo existente)
            tree = cached_obj.get("tree")
            stats.cache_hits += 1
            logger.debug(f"  ⚡ Línea {line_num}: Objeto cacheado categórico")
        else:
            # Construir nuevo objeto (nuevo morfismo)
            tree = self._parse_line_categorical(line_clean, line_num, stats)
            if tree is None:
                continue
        
        # Aplicar functor de transformación
        insumo = self._transform_with_categorical_functor(
            tree, transformer, line_clean, line_num, stats
        )
        
        if insumo is not None:
            # Validar que el insumo es un objeto terminal válido
            if self._validate_terminal_object(insumo):
                insumo.line_number = line_num
                results.append(insumo)
                
                # Actualizar cache categórico
                if cache_key not in categorical_cache:
                    categorical_cache[cache_key] = {
                        "tree": tree,
                        "insumo_type": type(insumo).__name__,
                        "algebraic_signature": self._compute_algebraic_signature(insumo)
                    }
            else:
                stats.empty_results += 1
                logger.debug(f"  ⚠️ Línea {line_num}: Objeto no terminal")
        else:
            stats.failed_lines.append({
                "line_number": line_num,
                "content": line_clean[:100],
                "apu_code": apu_code,
                "reason": "functor_returned_none",
            })
    
    # Estadísticas categóricas
    self._log_categorical_stats(apu_code, stats)
    self._merge_stats_categorical(stats)
    
    return results


def _is_valid_line_categorical(self, line: Any) -> bool:
    """Validación categórica de línea."""
    if line is None:
        return False
    if not isinstance(line, str):
        logger.debug(f"Línea no es morfismo a string: {type(line).__name__}")
        return False
    
    line_str = str(line).strip()
    
    # Validación de objeto inicial
    if not line_str:
        return False
    
    # Validación de dimensión (longitud)
    if len(line_str) < 3:
        return False
    
    # Validación de estructura (debe tener algún separador)
    if ';' not in line_str and len(line_str.split()) < 2:
        return False
    
    return True


def _build_categorical_cache(self, line_cache: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    """Construye cache categórico con validación de objetos."""
    categorical_cache = {}
    
    # Agregar cache global
    if self.parse_cache and isinstance(self.parse_cache, dict):
        for key, tree in self.parse_cache.items():
            if self._is_valid_tree(tree):
                categorical_cache[key] = {"tree": tree, "source": "global"}
    
    # Agregar cache específico
    if line_cache and isinstance(line_cache, dict):
        for key, tree in line_cache.items():
            if self._is_valid_tree(tree):
                categorical_cache[key] = {"tree": tree, "source": "local"}
    
    # Limitar tamaño categórico
    MAX_CATEGORICAL_CACHE = 50000
    if len(categorical_cache) > MAX_CATEGORICAL_CACHE:
        logger.warning(f"Cache categórico excede límite, truncando")
        keys = list(categorical_cache.keys())[-MAX_CATEGORICAL_CACHE:]
        categorical_cache = {k: categorical_cache[k] for k in keys}
    
    return categorical_cache


def _compute_categorical_cache_key(self, line: str) -> str:
    """Computa clave de cache categórica (invariante bajo transformaciones)."""
    # Normalización categórica
    normalized = " ".join(line.split())
    
    # Reducir a forma normal algebraica
    # 1. Normalizar números
    import re
    normalized = re.sub(r'\d+', '#', normalized)
    
    # 2. Normalizar unidades
    unit_pattern = r'\b(UND|M|M2|M3|KG|HR|DIA|JOR)\b'
    normalized = re.sub(unit_pattern, '@', normalized, flags=re.IGNORECASE)
    
    # 3. Normalizar separadores
    normalized = normalized.replace(';', '|')
    
    return normalized[:500]  # Longitud limitada


def _is_valid_cached_object(self, cached_obj: Any) -> bool:
    """Valida que un objeto cacheado sea categóricamente válido."""
    if not isinstance(cached_obj, dict):
        return False
    
    if "tree" not in cached_obj:
        return False
    
    return self._is_valid_tree(cached_obj["tree"])


def _parse_line_categorical(
    self, line: str, line_num: int, stats: ParsingStats
) -> Optional[Any]:
    """
    Parseo categórico con manejo de excepciones como morfismos especiales.
    """
    from lark.exceptions import (
        UnexpectedCharacters, UnexpectedEOF, UnexpectedInput, UnexpectedToken
    )
    
    try:
        # Validación pre-parseo categórica
        if not self._validate_pre_parse_categorical(line):
            stats.lark_parse_errors += 1
            return None
        
        return self.parser.parse(line)
        
    except UnexpectedCharacters as uc:
        stats.lark_unexpected_chars += 1
        # Morfismo de error: caracter inesperado
        logger.debug(f"  ✗ Línea {line_num}: Morfismo UnexpectedCharacters")
        return None
        
    except UnexpectedToken as ut:
        stats.lark_parse_errors += 1
        logger.debug(f"  ✗ Línea {line_num}: Morfismo UnexpectedToken")
        return None
        
    except UnexpectedEOF as ueof:
        stats.lark_parse_errors += 1
        logger.debug(f"  ✗ Línea {line_num}: Morfismo UnexpectedEOF")
        return None
        
    except UnexpectedInput as ui:
        stats.lark_unexpected_input += 1
        logger.debug(f"  ✗ Línea {line_num}: Morfismo UnexpectedInput")
        return None
        
    except Exception as e:
        stats.lark_parse_errors += 1
        logger.error(f"  🚨 Línea {line_num}: Morfismo inesperado: {type(e).__name__}")
        return None


def _validate_pre_parse_categorical(self, line: str) -> bool:
    """Validación categórica pre-parseo."""
    # Debe tener estructura mínima
    if ';' not in line:
        # Pero podría tener otros separadores
        if not any(sep in line for sep in [',', '|', '\t']):
            return False
    
    # No debe ser demasiado larga
    if len(line) > 5000:
        return False
    
    # Debe tener contenido mixto (no solo números o solo letras)
    has_alpha = any(c.isalpha() for c in line)
    has_digit = any(c.isdigit() for c in line)
    
    if not (has_alpha and has_digit):
        # Permitir excepciones (como "100%" o "MATERIALES")
        if not (has_digit and '%' in line) and not line.isalpha():
            return False
    
    return True


def _transform_with_categorical_functor(
    self,
    tree: Any,
    transformer: APUTransformer,
    line: str,
    line_num: int,
    stats: ParsingStats,
) -> Optional[InsumoProcesado]:
    """
    Transforma usando teoría de funtores.
    
    El transformer es un functor F: ParseTree → Option[InsumoProcesado]
    """
    try:
        # Aplicar functor
        result = transformer.transform(tree)
        
        # Manejar resultado como objeto en categoría Option
        if isinstance(result, list):
            # Producto categórico: tomar primer objeto no nulo
            for item in result:
                if item is not None:
                    stats.successful_parses += 1
                    return self._apply_categorical_refinements(item, line)
            stats.empty_results += 1
            return None
        
        if result is not None:
            stats.successful_parses += 1
            return self._apply_categorical_refinements(result, line)
        else:
            stats.empty_results += 1
            return None
            
    except Exception as transform_error:
        stats.transformer_errors += 1
        logger.error(f"  ✗ Línea {line_num}: Error en functor: {type(transform_error).__name__}")
        return None


def _apply_categorical_refinements(self, insumo: InsumoProcesado, 
                                   original_line: str) -> InsumoProcesado:
    """Aplica refinamientos categóricos al insumo."""
    # Añadir firma algebraica
    if not hasattr(insumo, 'algebraic_signature'):
        insumo.algebraic_signature = self._compute_algebraic_signature(insumo)
    
    # Añadir invariantes categóricos
    if not hasattr(insumo, 'categorical_invariants'):
        insumo.categorical_invariants = {
            'object_type': type(insumo).__name__,
            'line_hash': hash(original_line) % 1000000,
            'morphism_class': self._classify_morphism(insumo, original_line)
        }
    
    return insumo


def _compute_algebraic_signature(self, insumo: InsumoProcesado) -> str:
    """Computa firma algebraica del insumo."""
    import hashlib
    
    components = []
    
    # Descripción normalizada
    if hasattr(insumo, 'descripcion_insumo'):
        desc = insumo.descripcion_insumo.upper()
        components.append(re.sub(r'[^A-Z]', '', desc[:50]))
    
    # Valores numéricos
    numeric_attrs = ['cantidad', 'precio_unitario', 'valor_total', 'rendimiento']
    for attr in numeric_attrs:
        if hasattr(insumo, attr):
            val = getattr(insumo, attr)
            components.append(f"{attr[:3]}:{val:.2f}")
    
    # Tipo
    if hasattr(insumo, 'tipo_insumo'):
        components.append(insumo.tipo_insumo[:3])
    
    signature_str = '|'.join(components)
    return hashlib.md5(signature_str.encode()).hexdigest()[:16]


def _classify_morphism(self, insumo: InsumoProcesado, line: str) -> str:
    """Clasifica el morfismo que produjo este insumo."""
    # Basado en cómo se relaciona con la línea original
    if not hasattr(insumo, 'descripcion_insumo'):
        return 'UNKNOWN'
    
    desc = insumo.descripcion_insumo.lower()
    line_lower = line.lower()
    
    # Morfismo de inclusión (descripción está en línea)
    if desc in line_lower:
        return 'INCLUSION'
    
    # Morfismo de extracción (línea contiene más información)
    if line_lower in desc:
        return 'EXTRACTION'
    
    # Morfismo de transformación (cambio significativo)
    return 'TRANSFORMATION'


def _validate_terminal_object(self, insumo: InsumoProcesado) -> bool:
    """Valida que el insumo es un objeto terminal válido en la categoría."""
    # Campos requeridos
    required = ['descripcion_insumo', 'tipo_insumo']
    for attr in required:
        if not hasattr(insumo, attr):
            return False
        val = getattr(insumo, attr)
        if val is None or (isinstance(val, str) and not val.strip()):
            return False
    
    # Coherencia de valores
    if hasattr(insumo, 'valor_total'):
        if insumo.valor_total < 0:
            return False
        
        # Verificar relación algebraica básica
        if (hasattr(insumo, 'cantidad') and hasattr(insumo, 'precio_unitario')):
            if insumo.cantidad > 0 and insumo.precio_unitario > 0:
                calculated = insumo.cantidad * insumo.precio_unitario
                if calculated > 0:
                    diff = abs(insumo.valor_total - calculated) / calculated
                    if diff > 0.2:  # 20% de tolerancia
                        return False
    
    return True


def _log_categorical_stats(self, apu_code: str, stats: ParsingStats):
    """Registra estadísticas categóricas."""
    if stats.total_lines == 0:
        return
    
    success_rate = (stats.successful_parses / stats.total_lines * 100) if stats.total_lines > 0 else 0
    cache_rate = (stats.cache_hits / stats.total_lines * 100) if stats.total_lines > 0 else 0
    
    logger.info("-" * 70)
    logger.info(f"📊 APU CATEGÓRICO: {apu_code}")
    logger.info(f"   Objetos procesados:  {stats.total_lines}")
    logger.info(f"   ✓ Morfismos exitosos: {stats.successful_parses} ({success_rate:.1f}%)")
    logger.info(f"   ⚡ Cache categórico:   {stats.cache_hits} ({cache_rate:.1f}%)")
    
    if stats.lark_parse_errors > 0:
        logger.info(f"   ✗ Morfismos Lark inválidos: {stats.lark_parse_errors}")
    if stats.transformer_errors > 0:
        logger.info(f"   ✗ Functores fallidos: {stats.transformer_errors}")
    
    logger.info("-" * 70)


def _merge_stats_categorical(self, apu_stats: ParsingStats):
    """Fusión categórica de estadísticas."""
    # Esta es una versión mejorada de _merge_stats
    for attr in ['total_lines', 'successful_parses', 'lark_parse_errors',
                 'transformer_errors', 'empty_results', 'cache_hits']:
        if hasattr(self.parsing_stats, attr) and hasattr(apu_stats, attr):
            current = getattr(self.parsing_stats, attr)
            new = getattr(apu_stats, attr)
            setattr(self.parsing_stats, attr, current + new)
    
    # Fusionar líneas fallidas
    self.parsing_stats.failed_lines.extend(apu_stats.failed_lines)