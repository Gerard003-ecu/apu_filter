import logging
import math
import time
from collections import deque
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Any, Callable, Dict, List, NamedTuple, Optional, Set, Tuple, Union
import warnings

try:
    import numpy as np
except ImportError:
    np = None

import pandas as pd
import scipy.signal
import networkx as nx

try:
    from scipy import sparse
    from scipy.sparse import bmat
    from scipy.sparse.linalg import spsolve, lsqr, eigsh
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    sparse = None

from .apu_processor import APUProcessor
from .report_parser_crudo import ReportParserCrudo
from .telemetry import TelemetryContext
from .laplace_oracle import LaplaceOracle, ConfigurationError as OracleConfigurationError

logger = logging.getLogger(__name__)


# ============================================================================
# CONSTANTES DEL SISTEMA
# ============================================================================
class SystemConstants:
    """Constantes del sistema para evitar números mágicos."""

    # Límites de tiempo
    MIN_DELTA_TIME: float = 0.001  # Segundos mínimos entre cálculos PID
    MAX_DELTA_TIME: float = 3600.0  # 1 hora máximo entre cálculos
    PROCESSING_TIMEOUT: float = 3600.0  # Timeout de procesamiento total

    # Límites físicos
    MIN_ENERGY_THRESHOLD: float = 1e-10  # Julios mínimos para cálculos
    MAX_EXPONENTIAL_ARG: float = 100.0  # Límite para evitar overflow en exp()
    MAX_WATER_HAMMER_PRESSURE: float = 10.0  # Presión máxima de golpe de ariete (antes Flyback)
    MAX_FLYBACK_VOLTAGE: float = MAX_WATER_HAMMER_PRESSURE  # Alias de compatibilidad

    # Diagnóstico
    LOW_INERTIA_THRESHOLD: float = 0.1
    HIGH_PRESSURE_RATIO: float = 1000.0
    HIGH_FLYBACK_THRESHOLD: float = 0.5
    OVERHEAT_POWER_THRESHOLD: float = 50.0  # Watts

    # Control de flujo
    EMERGENCY_BRAKE_FACTOR: float = 0.5
    MAX_ITERATIONS_MULTIPLIER: int = 10  # max_iterations = total_records * multiplier
    MIN_BATCH_SIZE_FLOOR: int = 1  # Tamaño mínimo absoluto de batch

    # Validación de archivos
    VALID_FILE_EXTENSIONS: Set[str] = {".csv", ".txt", ".tsv", ".dat"}
    MAX_FILE_SIZE_MB: float = 500.0  # Límite de tamaño de archivo
    MIN_FILE_SIZE_BYTES: int = 10  # Archivo mínimo válido

    # Resistencia dinámica
    COMPLEXITY_RESISTANCE_FACTOR: float = 5.0

    # Límites de registros
    MAX_RECORDS_LIMIT: int = 10_000_000  # Límite absoluto de registros
    MIN_RECORDS_FOR_PID: int = 10  # Mínimo para activar control PID

    # Cache
    MAX_CACHE_SIZE: int = 100_000  # Límite de entradas en cache

    # Consolidación
    MAX_BATCHES_TO_CONSOLIDATE: int = 10_000  # Límite de batches

    # Estabilidad Giroscópica
    GYRO_SENSITIVITY: float = 5.0  # FactorSensibilidad para Sg
    GYRO_EMA_ALPHA: float = 0.1  # Alpha para filtro EMA de corriente

# ============================================================================
# MOTOR DE FÍSICA - MÉTODOS REFINADOS
# ============================================================================
class FluxPhysicsEngine:
    """
    Motor de física RLC.

    Características:
    1. Integración numérica más estable (Runge-Kutta de 2do orden).
    2. Cálculo de números de Betti corregido para grafos.
    3. Entropía termodinámica con fundamentación estadística rigurosa.
    4. Modelo de amortiguamiento no lineal para alta saturación.
    """

    _MAX_METRICS_HISTORY: int = 100

    def __init__(self, capacitance: float, resistance: float, inductance: float):
        # Inicializar logger primero para usar en validación
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")

        self._validate_physical_parameters(capacitance, resistance, inductance)

        self.C = float(capacitance)
        self.R = float(resistance)
        self.L = float(inductance)

        # Parámetros derivados del circuito RLC
        self._omega_0 = 1.0 / math.sqrt(self.L * self.C)  # Frecuencia natural
        self._alpha = self.R / (2.0 * self.L)  # Factor de amortiguamiento
        self._zeta = self._alpha / self._omega_0  # Ratio de amortiguamiento
        self._Q = math.sqrt(self.L / self.C) / self.R if self.R > 0 else float("inf")

        # Clasificación del sistema
        self._update_damping_classification()

        # Estado del sistema: [carga Q, corriente I]
        self._state = [0.0, 0.0]  # Compatible con/sin numpy
        self._state_history: deque = deque(maxlen=self._MAX_METRICS_HISTORY)

        # === MAXWELL FDTD SETUP ===
        # Topología fija para el solver electromagnético
        # Grafo completo K6 representando interacciones entre las 6 métricas base
        if SCIPY_AVAILABLE:
            nodes = list(range(6))
            adj = {i: set(nodes) - {i} for i in nodes}

            self.vector_calc = DiscreteVectorCalculus(adj)
            # R es resistencia, conductividad es inversa
            sigma_e = 1.0 / max(self.R, 1e-6)
            self.maxwell_solver = MaxwellFDTDSolver(
                self.vector_calc,
                permittivity=self.C,
                permeability=self.L,
                electric_conductivity=sigma_e
            )
            self.hamiltonian_control = PortHamiltonianController(self.maxwell_solver)
        else:
            self.vector_calc = None
            self.maxwell_solver = None
            self.hamiltonian_control = None

        # Estado del giroscopio (inicialización temprana)
        self._gyro_state = {
            "omega_x": 0.0,
            "omega_y": 0.0,
            "nutation_amplitude": 0.0,
            "precession_phase": 0.0,
        }

        # Grafo de conectividad para análisis topológico (dinámico)
        self._adjacency_list: Dict[int, Set[int]] = {}
        self._vertex_count: int = 0
        self._edge_count: int = 0

        # Historial de métricas
        self._metrics_history: deque = deque(maxlen=self._MAX_METRICS_HISTORY)
        self._entropy_history: deque = deque(maxlen=self._MAX_METRICS_HISTORY)

        # Estado temporal
        self._last_current: float = 0.0
        self._ema_current: float = 0.0  # EMA de la corriente (Eje de rotación)
        self._last_time: float = time.time()
        self._initialized: bool = False

        # Amortiguamiento no lineal
        self._nonlinear_damping_factor: float = 1.0

    def _validate_physical_parameters(self, C: float, R: float, L: float) -> None:
        """Validación de parámetros físicos con análisis dimensional."""
        errors = []

        if C <= 0:
            errors.append(f"Capacitancia debe ser positiva, got {C} F")
        if R < 0:
            errors.append(f"Resistencia debe ser no-negativa, got {R} Ω")
        if L <= 0:
            errors.append(f"Inductancia debe ser positiva, got {L} H")

        # Verificación de rangos físicamente razonables
        if C > 0 and L > 0:
            omega_0 = 1.0 / math.sqrt(L * C)
            if omega_0 > 1e12:  # > 1 THz
                self.logger.warning(
                    f"Frecuencia natural {omega_0:.2e} rad/s excesivamente alta"
                )

        if R > 0 and L > 0:
            tau = L / R  # Constante de tiempo
            if tau < 1e-12:  # < 1 ps
                self.logger.warning(f"Constante de tiempo {tau:.2e} s muy pequeña")

        if errors:
            raise ConfigurationError(
                "Parámetros físicos inválidos:\n" + "\n".join(f"  • {e}" for e in errors)
            )

    def _update_damping_classification(self) -> None:
        """Actualiza clasificación de amortiguamiento del sistema."""
        if self._zeta > 1.0:
            self._damping_type = "OVERDAMPED"
            self._omega_d = self._omega_0 * math.sqrt(self._zeta**2 - 1)
        elif self._zeta < 1.0:
            self._damping_type = "UNDERDAMPED"
            self._omega_d = self._omega_0 * math.sqrt(1 - self._zeta**2)
        else:
            self._damping_type = "CRITICALLY_DAMPED"
            self._omega_d = 0.0

    def _evolve_state_rk4(self, driving_current: float, dt: float) -> Tuple[float, float]:
        """
        Evolución del estado RLC usando Runge-Kutta de 4to orden (RK4).

        Mayor precisión O(dt⁴) vs O(dt²) de RK2, crítico para
        sistemas subamortiguados donde la oscilación debe preservarse.

        Sistema de ecuaciones de estado:
            dQ/dt = I
            dI/dt = (V_in - R·I - Q/C) / L
        """
        Q, I = self._state

        # Voltaje de entrada proporcional a corriente de driving
        # con saturación suave para evitar sobretensiones
        V_max = 20.0
        V_in = V_max * math.tanh(driving_current)

        # Función de derivadas del sistema
        def f(q: float, i: float) -> Tuple[float, float]:
            dq_dt = i
            # Resistencia no lineal: aumenta con I² (efecto Joule)
            R_eff = self.R * (1.0 + 0.1 * i * i)
            di_dt = (V_in - R_eff * i - q / self.C) / self.L
            return dq_dt, di_dt

        # RK4 clásico
        k1_q, k1_i = f(Q, I)
        k2_q, k2_i = f(Q + 0.5 * dt * k1_q, I + 0.5 * dt * k1_i)
        k3_q, k3_i = f(Q + 0.5 * dt * k2_q, I + 0.5 * dt * k2_i)
        k4_q, k4_i = f(Q + dt * k3_q, I + dt * k3_i)

        Q_new = Q + (dt / 6.0) * (k1_q + 2 * k2_q + 2 * k3_q + k4_q)
        I_new = I + (dt / 6.0) * (k1_i + 2 * k2_i + 2 * k3_i + k4_i)

        # === LIMITADOR DE ENERGÍA ===
        # Prevenir acumulación infinita de energía (estabilidad numérica)
        E_max = 100.0  # Energía máxima permitida
        E_current = 0.5 * self.L * I_new**2 + 0.5 * (Q_new**2) / self.C

        if E_current > E_max:
            # Escalar estado para limitar energía (conservando proporciones)
            scale = math.sqrt(E_max / E_current)
            Q_new *= scale
            I_new *= scale
            self._nonlinear_damping_factor = scale
            self.logger.debug(f"Energía limitada: {E_current:.2f} → {E_max:.2f} J")
        else:
            # Amortiguamiento no lineal suave para alta energía
            damping = 1.0 / (1.0 + 0.05 * max(0, E_current - E_max * 0.5))
            I_new *= damping
            self._nonlinear_damping_factor = damping

        self._state = [Q_new, I_new]

        self._state_history.append(
            {
                "Q": Q_new,
                "I": I_new,
                "time": time.time(),
                "energy": 0.5 * self.L * I_new**2 + 0.5 * (Q_new**2) / self.C,
                "V_in": V_in,
            }
        )

        return Q_new, I_new

    def _build_metric_graph(self, metrics: Dict[str, float]) -> None:
        """
        Construye grafo de correlación.

        Usa umbral adaptativo basado en correlación de Spearman (robusta a outliers)
        sobre historial.
        """
        metric_keys = [
            "saturation",
            "complexity",
            "current_I",
            "potential_energy",
            "kinetic_energy",
            "entropy_shannon",
        ]
        values = [metrics.get(k, 0.0) for k in metric_keys]

        self._adjacency_list.clear()
        self._vertex_count = len(values)
        self._edge_count = 0

        for i in range(self._vertex_count):
            self._adjacency_list[i] = set()

        if self._vertex_count < 2:
            return

        # Calcular matriz de distancias normalizadas
        # Usar distancia de correlación: d = 1 - |corr|

        # Normalizar valores al rango [0, 1]
        v_min = min(values)
        v_max = max(values)
        v_range = v_max - v_min if v_max != v_min else 1.0
        normalized = [(v - v_min) / v_range for v in values]

        # Umbral adaptativo basado en dispersión
        mean_val = sum(normalized) / len(normalized)
        variance = sum((v - mean_val) ** 2 for v in normalized) / len(normalized)

        # Mayor varianza → umbral más permisivo para capturar estructura
        base_threshold = 0.3
        adaptive_threshold = base_threshold * (1.0 + math.sqrt(variance))
        adaptive_threshold = min(0.7, adaptive_threshold)  # Cap máximo

        # Crear aristas basadas en proximidad en espacio normalizado
        for i in range(self._vertex_count):
            for j in range(i + 1, self._vertex_count):
                # Distancia euclidiana normalizada
                dist = abs(normalized[i] - normalized[j])

                # Correlación implícita: valores cercanos están correlacionados
                if dist < adaptive_threshold:
                    self._adjacency_list[i].add(j)
                    self._adjacency_list[j].add(i)
                    self._edge_count += 1

    def _calculate_betti_numbers(self) -> Dict[int, int]:
        """
        Calcula números de Betti usando Union-Find optimizado con
        elementos de homología persistente.

        Para un grafo G = (V, E):

        - β₀ = número de componentes conexas = |V| - rank(A)
        - β₁ = número de ciclos independientes = |E| - |V| + β₀
        - β_k = 0 para k ≥ 2 (el grafo es 1-dimensional)

        Característica de Euler: χ = β₀ - β₁ = |V| - |E|

        Complejidad ciclomática (McCabe): M = β₁ + 1

        La homología persistente se simula ordenando aristas por peso
        y rastreando nacimiento/muerte de características.
        """
        if self._vertex_count == 0:
            return {
                0: 0, 1: 0, 2: 0,
                "euler_characteristic": 0,
                "is_tree": False,
                "is_forest": True,
                "cyclomatic_complexity": 1,
                "homology_dimensions": [],
                "connected_components": 0,
                "independent_cycles": 0,
            }

        # === UNION-FIND CON COMPRESIÓN DE CAMINOS Y UNIÓN POR RANGO ===
        parent = list(range(self._vertex_count))
        rank = [0] * self._vertex_count

        def find(x: int) -> int:
            """Find con compresión de caminos (path halving)."""
            while parent[x] != x:
                parent[x] = parent[parent[x]]  # Path halving
                x = parent[x]
            return x

        def union(x: int, y: int) -> bool:
            """
            Union por rango.
            Retorna True si x e y YA estaban conectados (arista crea ciclo).
            """
            root_x = find(x)
            root_y = find(y)

            if root_x == root_y:
                return True  # Ciclo detectado

            # Unión por rango para árbol balanceado
            if rank[root_x] < rank[root_y]:
                root_x, root_y = root_y, root_x

            parent[root_y] = root_x

            if rank[root_x] == rank[root_y]:
                rank[root_x] += 1

            return False  # Componentes fusionadas

        # === PROCESAR ARISTAS Y DETECTAR CICLOS ===
        edges_processed = 0
        cycles_detected = 0

        # Lista de aristas para homología persistente
        edge_list = []

        for u in range(self._vertex_count):
            neighbors = self._adjacency_list.get(u, set())
            for v in sorted(neighbors):
                if v > u:  # Cada arista una sola vez
                    edge_list.append((u, v))

        # === HOMOLOGÍA PERSISTENTE SIMPLIFICADA ===
        # Ordenar aristas por "peso" (simulado como índice)
        # En un grafo sin pesos, usamos el orden de inserción
        persistence_diagram = []

        for idx, (u, v) in enumerate(edge_list):
            edges_processed += 1

            is_cycle = union(u, v)

            if is_cycle:
                cycles_detected += 1
                # Registro de ciclo: nace en este momento, muere en infinito
                persistence_diagram.append({
                    "dimension": 1,
                    "birth": idx / max(len(edge_list), 1),  # Normalizado
                    "death": 1.0,  # Infinito normalizado
                    "persistence": 1.0 - idx / max(len(edge_list), 1),
                    "edge": (u, v),
                })

        # === CONTAR COMPONENTES CONEXAS ===
        unique_roots = set()
        for i in range(self._vertex_count):
            unique_roots.add(find(i))

        beta_0 = len(unique_roots)

        # === CALCULAR β₁ USANDO FÓRMULA DE EULER ===
        # χ = V - E = β₀ - β₁
        # β₁ = β₀ - χ = β₀ - (V - E) = β₀ - V + E
        chi = self._vertex_count - edges_processed
        beta_1 = beta_0 - chi

        # Validación: β₁ debe coincidir con ciclos detectados
        assert beta_1 == cycles_detected, (
            f"Inconsistencia: β₁={beta_1} ≠ ciclos={cycles_detected}"
        )

        # β₁ >= 0 siempre para grafos
        beta_1 = max(0, beta_1)

        # === MÉTRICAS TOPOLÓGICAS DERIVADAS ===
        is_connected = (beta_0 == 1)
        is_tree = is_connected and (beta_1 == 0)
        is_forest = (beta_1 == 0)  # Bosque: sin ciclos

        # Complejidad ciclomática de McCabe
        # M = E - V + 2P donde P = componentes conexas
        # Equivalente a: M = β₁ + P
        cyclomatic_complexity = beta_1 + beta_0

        # === FILTRAR DIAGRAMA DE PERSISTENCIA ===
        # Mantener solo características con persistencia significativa
        significant_features = [
            feat for feat in persistence_diagram
            if feat["persistence"] > 0.1
        ]

        return {
            # Números de Betti
            0: beta_0,
            1: beta_1,
            2: 0,  # Grafos son 1-dimensionales

            # Característica de Euler
            "euler_characteristic": chi,

            # Clasificación topológica
            "is_connected": is_connected,
            "is_tree": is_tree,
            "is_forest": is_forest,
            "is_cyclic": beta_1 > 0,

            # Métricas de complejidad
            "cyclomatic_complexity": cyclomatic_complexity,
            "graph_genus": beta_1,  # Para grafos planos

            # Componentes
            "connected_components": beta_0,
            "independent_cycles": beta_1,

            # Homología persistente
            "homology_dimensions": significant_features,
            "total_persistence": sum(f["persistence"] for f in persistence_diagram),

            # Estadísticas del grafo
            "vertex_count": self._vertex_count,
            "edge_count": edges_processed,
            "edge_density": (2 * edges_processed) / (self._vertex_count * (self._vertex_count - 1))
                if self._vertex_count > 1 else 0.0,
        }

    def calculate_pump_work(self, current_I: float, voltage_across_inductor: float, dt: float) -> float:
        """
        Calcula el Trabajo (W) realizado por la Bomba Lineal.
        Basado en v = dw/dq -> dw = v * dq -> W = v * I * dt.

        Args:
            current_I: La 'velocidad' del pistón (Corriente).
            voltage_across_inductor: La 'fuerza' ejercida por el pistón (L * di/dt).
            dt: Diferencial de tiempo.

        Returns:
            Joules de trabajo realizado sobre el flujo de datos.
        """
        # Potencia instantánea entregada por el inductor (Pistón)
        # W = V * I * dt
        power_stroke = voltage_across_inductor * current_I

        # Trabajo acumulado en este paso
        work_done = power_stroke * dt
        return work_done

    def calculate_gyroscopic_stability(self, current_I: float) -> float:
        """
        Calcula estabilidad giroscópica usando ecuaciones de Euler linealizadas.

        Modelo de trompo simétrico (Ix = Iy ≠ Iz):

        Ecuaciones de Euler para cuerpo rígido:
            Ix·dωx/dt = (Iy - Iz)·ωy·ωz + τx
            Iy·dωy/dt = (Iz - Ix)·ωz·ωx + τy
            Iz·dωz/dt = (Ix - Iy)·ωx·ωy + τz

        Para rotación estable alrededor de z con pequeñas perturbaciones:
            dωx/dt = Ω·ωy  donde Ω = (Iz - Ix)/Ix · ωz
            dωy/dt = -Ω·ωx

        Esto da oscilación armónica (precesión) con frecuencia Ω.

        Criterio de estabilidad (teorema de la raqueta de tenis):
        - Rotación alrededor del eje de momento de inercia máximo o mínimo: ESTABLE
        - Rotación alrededor del eje intermedio: INESTABLE

        La "corriente" representa velocidad angular ωz.
        La derivada dI/dt representa aceleración angular (torque).
        """
        current_time = time.time()

        # === INICIALIZACIÓN ===
        if not self._initialized:
            self._ema_current = current_I
            self._last_current = current_I
            self._last_time = current_time
            self._initialized = True

            # Estado del giroscopio
            self._gyro_state = {
                "omega_x": 0.0,  # Perturbación en x
                "omega_y": 0.0,  # Perturbación en y
                "nutation_amplitude": 0.0,
                "precession_phase": 0.0,
            }

            return 1.0  # Inicialmente estable

        dt = max(1e-6, current_time - self._last_time)

        # === MOMENTOS DE INERCIA EFECTIVOS ===
        # Modelamos el flujo de datos como un trompo alargado
        # Eje z es el eje principal de rotación (flujo de datos)
        Ix = 1.0   # Momento transversal
        Iy = 1.0   # Momento transversal (simetría axial)
        Iz = 1.5   # Momento axial (trompo alargado, Iz > Ix,Iy → estable)

        # Velocidad angular principal (proporcional a corriente)
        omega_z = abs(current_I) * 10.0  # Escalar para sensibilidad

        # === ECUACIONES DE EULER LINEALIZADAS ===
        # Para simetría axial (Ix = Iy):
        # d²ωx/dt² + Ω²·ωx = 0  (oscilador armónico)
        # donde Ω = (Iz - Ix)/Ix · ωz es la frecuencia de precesión

        if Ix > 0:
            Omega_precession = ((Iz - Ix) / Ix) * omega_z
        else:
            Omega_precession = 0.0

        # === EVOLUCIÓN DE PERTURBACIONES ===
        state = self._gyro_state
        omega_x = state["omega_x"]
        omega_y = state["omega_y"]

        # Ecuaciones acopladas (rotación en plano xy)
        # Usar Euler semi-implícito para estabilidad
        omega_x_new = omega_x * math.cos(Omega_precession * dt) + omega_y * math.sin(Omega_precession * dt)
        omega_y_new = -omega_x * math.sin(Omega_precession * dt) + omega_y * math.cos(Omega_precession * dt)

        # === EXCITACIÓN POR CAMBIO EN CORRIENTE ===
        dI_dt = (current_I - self._last_current) / dt

        # Cambios bruscos en corriente excitan nutación
        excitation_amplitude = 0.1 * abs(dI_dt)

        # Añadir excitación aleatoria en fase
        phase = state["precession_phase"] + Omega_precession * dt
        omega_x_new += excitation_amplitude * math.cos(phase)
        omega_y_new += excitation_amplitude * math.sin(phase)

        # === AMORTIGUAMIENTO VISCOSO ===
        # Las perturbaciones se amortiguan por fricción
        damping_coeff = 0.95  # Por paso de tiempo
        omega_x_new *= damping_coeff
        omega_y_new *= damping_coeff

        # === AMPLITUD DE NUTACIÓN ===
        nutation_amplitude = math.sqrt(omega_x_new**2 + omega_y_new**2)

        # Filtro EMA para suavizar
        alpha_nut = 0.1
        smoothed_nutation = (1 - alpha_nut) * state["nutation_amplitude"] + alpha_nut * nutation_amplitude

        # === CRITERIO DE ESTABILIDAD ===
        # 1. Velocidad mínima para estabilidad giroscópica
        #    ωz > ω_crítico donde ω_crítico depende de la geometría
        omega_critical = 0.5
        speed_factor = 1.0 - math.exp(-3.0 * max(0, omega_z - omega_critical))

        # 2. Nutación excesiva indica inestabilidad
        #    Si la nutación es comparable a ωz, el trompo "tambalea"
        nutation_ratio = smoothed_nutation / max(omega_z, 0.1)
        nutation_factor = 1.0 / (1.0 + 5.0 * nutation_ratio)

        # 3. Teorema de la raqueta de tenis
        #    Rotación alrededor de Iz (máximo) es estable si Iz > Ix, Iy
        #    Cuantificamos con el margen (Iz - Ix) / Ix
        inertia_margin = (Iz - Ix) / Ix
        stability_factor = math.tanh(2.0 * inertia_margin)  # 1 para margen grande

        # === ESTABILIDAD COMBINADA ===
        Sg = speed_factor * nutation_factor * stability_factor
        Sg = max(0.0, min(1.0, Sg))

        # === ACTUALIZAR ESTADO ===
        state["omega_x"] = omega_x_new
        state["omega_y"] = omega_y_new
        state["nutation_amplitude"] = smoothed_nutation
        state["precession_phase"] = phase % (2 * math.pi)

        self._last_current = current_I
        self._last_time = current_time

        # === DIAGNÓSTICO ===
        if Sg < 0.5:
            if Sg < 0.3:
                diagnosis = "NUTACIÓN CRÍTICA - Flujo inestable"
            else:
                diagnosis = "PRECESIÓN DETECTADA - Flujo oscilante"

            self.logger.debug(
                f"Estabilidad giroscópica: Sg={Sg:.3f}, "
                f"nutación={smoothed_nutation:.3f}, ωz={omega_z:.2f}. "
                f"Diagnóstico: {diagnosis}"
            )

        return Sg

    def calculate_system_entropy(
        self, total_records: int, error_count: int, processing_time: float
    ) -> Dict[str, float]:
        """
        Calcula entropía del sistema con correcciones para muestras pequeñas.

        Mejoras implementadas:

        1. **Estados puros**: Cuando error_count ∈ {0, total_records}, la entropía
           es exactamente 0 (estado determinístico), sin aplicar suavizado.

        2. **Estimador James-Stein shrinkage**: Para muestras pequeñas, contrae
           las probabilidades empíricas hacia una distribución uniforme.

           p̂_JS = λ·p_uniform + (1-λ)·p_empírico
           donde λ = α/(α + N) con α = 1 (prior Jeffrey's).

        3. **Corrección de Miller-Madow**: Ajusta sesgo de subestimación:
           H_MM = H + (m-1)/(2N·ln2)

        4. **Entropías generalizadas**: Rényi y Tsallis para diferentes
           sensibilidades a eventos raros.

        5. **Detección de muerte térmica**: Basada en teoría de grandes
           desviaciones, P(error) > ε con ε = 0.25.
        """
        if total_records <= 0:
            return self._get_zero_entropy()

        # === CASO ESPECIAL: ESTADOS PUROS ===
        # Un estado puro (sin mezcla) tiene entropía exactamente 0
        # Esto es físicamente correcto y evita artefactos del suavizado
        is_pure_state = (error_count == 0) or (error_count == total_records)

        if is_pure_state:
            # Entropía de Shannon para estado puro = 0
            # Todas las entropías generalizadas también son 0
            p_error = error_count / total_records

            return {
                "shannon_entropy": 0.0,
                "shannon_entropy_corrected": 0.0,
                "renyi_entropy_1": 0.0,
                "renyi_entropy_2": 0.0,
                "renyi_entropy_inf": 0.0,
                "tsallis_entropy": 0.0,
                "lempel_ziv_complexity": 0.0,
                "entropy_ratio": 0.0,
                "is_thermal_death": p_error > 0.5,  # 100% errores = muerte térmica
                "effective_samples": float(total_records),
                "kl_divergence": math.log2(2) if p_error in (0, 1) else 0.0,  # Máxima divergencia de uniforme
                "entropy_rate": 0.0,
                "mutual_info_temporal": 0.0,
                "max_entropy": 1.0,
                "entropy_absolute": 0.0,
                "configurational_entropy": 0.0,
            }

        # === SHRINKAGE DE JAMES-STEIN ===
        m = 2  # Número de categorías (éxito/error)
        alpha_prior = 1.0  # Prior de Jeffrey (no informativo)

        # Probabilidades empíricas (sin suavizado para el shrinkage)
        n_success = total_records - error_count
        n_error = error_count

        p_success_emp = n_success / total_records
        p_error_emp = n_error / total_records

        # Factor de shrinkage: λ = α/(α + N)
        lambda_js = alpha_prior / (alpha_prior + total_records)

        # Probabilidad uniforme (target del shrinkage)
        p_uniform = 1.0 / m

        # Probabilidades contraídas
        p_success = lambda_js * p_uniform + (1 - lambda_js) * p_success_emp
        p_error = lambda_js * p_uniform + (1 - lambda_js) * p_error_emp

        # Normalizar para garantizar suma = 1 (corrección numérica)
        p_total = p_success + p_error
        p_success /= p_total
        p_error /= p_total

        probabilities = [p_success, p_error]

        # === ENTROPÍA DE SHANNON ===
        H_shannon = 0.0
        for p in probabilities:
            if p > 1e-15:  # Evitar log(0)
                H_shannon -= p * math.log2(p)

        # === CORRECCIÓN DE MILLER-MADOW ===
        # Corrige sesgo de subestimación para muestras finitas
        # H_MM = H + (m-1) / (2*N*ln(2))
        miller_madow_correction = (m - 1) / (2 * total_records * math.log(2))
        H_mm = H_shannon + miller_madow_correction

        # === ENTROPÍA DE RÉNYI GENERALIZADA ===
        def renyi_entropy(alpha: float) -> float:
            """
            H_α = (1/(1-α)) * log₂(Σᵢ pᵢ^α)

            Límites:
            - α → 1: Shannon
            - α → 0: Hartley (log del soporte)
            - α → ∞: min-entropy (-log max(p))
            """
            if abs(alpha - 1.0) < 1e-8:
                return H_shannon

            sum_p_alpha = sum(p**alpha for p in probabilities if p > 1e-15)

            if sum_p_alpha <= 0:
                return 0.0

            return (1.0 / (1.0 - alpha)) * math.log2(sum_p_alpha)

        H_renyi_05 = renyi_entropy(0.5)   # Más sensible a eventos raros
        H_renyi_1 = H_shannon             # Shannon
        H_renyi_2 = renyi_entropy(2.0)    # Entropía de colisión

        # Min-entropía (α → ∞)
        p_max = max(probabilities)
        H_renyi_inf = -math.log2(p_max) if p_max > 0 else 0.0

        # === ENTROPÍA DE TSALLIS (q-entropía) ===
        # S_q = (1 - Σᵢ pᵢ^q) / (q - 1)
        # Es no-extensiva: S_q(A+B) = S_q(A) + S_q(B) + (1-q)*S_q(A)*S_q(B)
        q = 2.0
        sum_p_q = sum(p**q for p in probabilities if p > 1e-15)
        H_tsallis = (1.0 - sum_p_q) / (q - 1.0) if abs(q - 1.0) > 1e-8 else H_shannon

        # === DIVERGENCIA KL DESDE DISTRIBUCIÓN UNIFORME ===
        # D_KL(P||U) = Σᵢ pᵢ * log₂(pᵢ / u)
        # Mide "sorpresa" de la distribución real respecto a la uniforme
        kl_divergence = 0.0
        for p in probabilities:
            if p > 1e-15:
                kl_divergence += p * math.log2(p / p_uniform)

        # === COMPLEJIDAD DE LEMPEL-ZIV (aproximación) ===
        # Para un proceso binario, la complejidad se aproxima como
        # C ≈ H * n / log₂(n) para secuencias largas
        # Normalizamos a [0, 1] usando la relación con entropía
        if H_shannon > 0:
            lz_complexity = 1.0 - math.exp(-H_shannon)
        else:
            lz_complexity = 0.0

        # === MÉTRICAS DERIVADAS ===
        max_entropy = math.log2(m)  # 1 bit para sistema binario
        entropy_ratio = H_shannon / max_entropy if max_entropy > 0 else 0.0

        # Tasa de entropía (bits por unidad de tiempo)
        entropy_rate = H_shannon / max(processing_time, 1e-6)

        # === DETECCIÓN DE MUERTE TÉRMICA ===
        # Criterio: alta entropía + alta tasa de errores
        # Basado en principio de máxima entropía de Jaynes
        epsilon_death = 0.25
        is_thermal_death = (p_error_emp > epsilon_death) and (entropy_ratio > 0.85)

        # === INFORMACIÓN MUTUA TEMPORAL (estimación) ===
        # Aproximación basada en reducción de incertidumbre
        # I(t; t-1) ≈ H(t) - H(t|t-1)
        # Sin historial, asumimos I ≈ 0
        mutual_info_temporal = 0.0
        if len(self._entropy_history) >= 2:
            prev_entropy = self._entropy_history[-1].get("shannon_entropy", H_shannon)
            # Información ganada = reducción de entropía
            mutual_info_temporal = max(0, prev_entropy - H_shannon)

        result = {
            # Entropías fundamentales
            "shannon_entropy": H_shannon,
            "shannon_entropy_corrected": H_mm,

            # Familia de Rényi
            "renyi_entropy_05": H_renyi_05,
            "renyi_entropy_1": H_renyi_1,
            "renyi_entropy_2": H_renyi_2,
            "renyi_entropy_inf": H_renyi_inf,

            # Tsallis (no extensiva)
            "tsallis_entropy": H_tsallis,

            # Métricas de información
            "kl_divergence": kl_divergence,
            "lempel_ziv_complexity": lz_complexity,
            "mutual_info_temporal": mutual_info_temporal,

            # Métricas normalizadas
            "entropy_ratio": entropy_ratio,
            "max_entropy": max_entropy,
            "entropy_absolute": H_shannon,
            "entropy_rate": entropy_rate,

            # Diagnóstico
            "is_thermal_death": is_thermal_death,
            "effective_samples": total_records * (1 - lambda_js),

            # Alias para compatibilidad
            "configurational_entropy": H_renyi_2,
        }

        # Guardar en historial
        self._entropy_history.append({
            **result,
            "timestamp": time.time(),
            "total_records": total_records,
            "error_rate": p_error_emp,
        })

        return result

    def _get_zero_entropy(self) -> Dict[str, float]:
        """Retorna entropía cero para casos triviales."""
        return {
            "shannon_entropy": 0.0,
            "shannon_entropy_corrected": 0.0,
            "renyi_entropy_1": 0.0,
            "renyi_entropy_2": 0.0,
            "renyi_entropy_inf": 0.0,
            "tsallis_entropy": 0.0,
            "lempel_ziv_complexity": 0.0,
            "entropy_ratio": 0.0,
            "is_thermal_death": False,
            "effective_samples": 0.0,
            "kl_divergence": 0.0,
            "entropy_rate": 0.0,
            "mutual_info_temporal": 0.0,
            "max_entropy": 1.0,
            "entropy_absolute": 0.0,
            "configurational_entropy": 0.0,
        }

    def calculate_metrics(
        self,
        total_records: int,
        cache_hits: int,
        error_count: int = 0,
        processing_time: float = 1.0,
    ) -> Dict[str, float]:
        """
        Calcula métricas físicas del sistema usando Maxwell FDTD y Control Hamiltoniano.
        """
        if total_records <= 0:
            return self._get_zero_metrics()

        current_time = time.time()

        # Corriente normalizada (eficiencia de caché)
        current_I = cache_hits / total_records

        # Complejidad como resistencia base
        complexity = 1.0 - current_I

        # Inicialización delta tiempo
        if self._initialized:
            dt = max(1e-6, current_time - self._last_time)
        else:
            dt = 0.01
            self._initialized = True

        # === MOTOR MAXWELL FDTD ===
        if SCIPY_AVAILABLE and self.maxwell_solver:
            # 1. Mapear corriente de entrada a Vector J en las aristas
            #    Distribuimos la corriente uniformemente como carga base del sistema
            J_vec = np.full(self.vector_calc.num_edges, current_I)
            self.maxwell_solver.J_e = J_vec

            # 2. Actualizar campos (Leapfrog)
            # Nota: Usamos la nueva API de la propuesta
            self.maxwell_solver.step_magnetic_field(dt)
            self.maxwell_solver.step_electric_field(dt)

            # 3. Control Hamiltoniano (Inyectar disipación si energía excesiva)
            # Usamos apply_control para inyectar damping si es necesario
            # El control inyecta corrientes adicionales a J_e y J_m
            control_u = self.hamiltonian_control.apply_control(dt)
            excess_energy = np.linalg.norm(control_u) # Aproximación de disipación activa

            # 4. Obtener Energía Total (Hamiltoniano)
            H_total = self.hamiltonian_control.hamiltonian()

            # 5. Mapear Variables de Estado Vectoriales a Escalares para Compatibilidad
            #    Saturation ~ Potencial Eléctrico Normalizado
            #    Energy = 0.5 * C * V^2  =>  V = sqrt(2*E/C)
            v_equiv = math.sqrt(2.0 * H_total / self.C) if self.C > 0 else 0.0
            saturation = math.tanh(v_equiv) # Sigmoide para mantener en [0,1]

            # Energía cinética (Magnética) y Potencial (Eléctrica)
            E_potential = 0.5 * self.maxwell_solver.epsilon * np.sum(self.maxwell_solver.E**2)
            E_kinetic = 0.5 * (1.0/self.maxwell_solver.mu) * np.sum(self.maxwell_solver.B**2) if self.maxwell_solver.mu > 0 else 0.0

            # Resistencia Dinámica (inversa de sigma)
            # R es resistencia, conductividad es inversa
            sigma_eff = self.maxwell_solver.sigma_e
            # Sumamos la resistencia virtual del controlador (Series Equivalent)
            R_dynamic = (1.0 / max(sigma_eff, 1e-9)) + self.hamiltonian_control.kd

            # Amortiguamiento dinámico
            zeta_dynamic = R_dynamic / (2.0 * math.sqrt(self.L / self.C)) if self.C > 0 else float('inf')

            # Potencia disipada (Joule)
            # P = sigma * E^2
            P_dissipated = sigma_eff * np.sum(self.maxwell_solver.E**2)
        else:
            # Fallback a lógica escalar si no hay scipy
            Q, I = self._evolve_state_rk4(current_I, dt)
            H_total = 0.5 * self.L * I**2 + 0.5 * (Q**2) / self.C
            v_equiv = math.sqrt(2.0 * H_total / self.C) if self.C > 0 else 0.0
            saturation = math.tanh(v_equiv)
            E_potential = 0.5 * (Q**2) / self.C
            E_kinetic = 0.5 * self.L * I**2
            R_dynamic = self.R
            zeta_dynamic = self._zeta
            P_dissipated = self.R * I**2
            excess_energy = 0.0

        # --- Lógica de la Bomba Lineal (Linear Pump) ---

        # 1. Calcular la aceleración del pistón (di/dt)
        # Un cambio brusco en la corriente (throughput) significa que el pistón golpeó una "pared" de datos sucios.
        di_dt = (current_I - self._last_current) / dt

        # 2. Presión del Pistón (Voltaje Inductivo)
        # v = L * di/dt
        piston_pressure = self.L * di_dt

        # 3. Detección de "Golpe de Ariete" (Flyback peligroso)
        # Si la presión es negativa y alta, el flujo está intentando retroceder violentamente.
        # Renombrado de V_flyback a water_hammer_pressure
        water_hammer_pressure = abs(piston_pressure) if piston_pressure < 0 else 0.0

        # Limitar por seguridad del sistema
        water_hammer_pressure = min(water_hammer_pressure, SystemConstants.MAX_WATER_HAMMER_PRESSURE)

        # Alias para compatibilidad hacia atrás
        V_flyback = water_hammer_pressure

        # Entropía
        entropy_metrics = self.calculate_system_entropy(
            total_records, error_count, processing_time
        )

        # Estabilidad Giroscópica
        gyro_stability = self.calculate_gyroscopic_stability(current_I)

        # Construir grafo y calcular topología (Betti numbers)
        # Usamos las métricas escalares para mantener la topología de correlación
        metrics = {
            "saturation": saturation,
            "complexity": complexity,
            "current_I": current_I,
            "potential_energy": E_potential,
            "kinetic_energy": E_kinetic,
            "total_energy": H_total,
            "dissipated_power": P_dissipated,
            "flyback_voltage": V_flyback,  # Legacy alias
            "water_hammer_pressure": water_hammer_pressure, # New metric
            "piston_pressure": piston_pressure, # New metric
            "piston_acceleration": di_dt, # New metric
            "pump_work": self.calculate_pump_work(current_I, piston_pressure, dt), # New metric
            "dynamic_resistance": R_dynamic,
            "damping_ratio": zeta_dynamic,
            "damping_type": self._damping_type,
            "resonant_frequency_hz": self._omega_0 / (2 * math.pi),
            "quality_factor": self._Q,
            "time_constant": self.L * (self.maxwell_solver.sigma_e if self.maxwell_solver else (1.0/self.R)),
            # Entropía Extendida
            "entropy_shannon": entropy_metrics["shannon_entropy"],
            "entropy_shannon_corrected": entropy_metrics["shannon_entropy_corrected"],
            "tsallis_entropy": entropy_metrics["tsallis_entropy"],
            "kl_divergence": entropy_metrics["kl_divergence"],
            "entropy_rate": entropy_metrics["entropy_rate"],
            "entropy_ratio": entropy_metrics["entropy_ratio"],
            "is_thermal_death": entropy_metrics["is_thermal_death"],
            # Alias para pruebas
            "entropy_absolute": entropy_metrics["entropy_absolute"],
            # Giroscópica
            "gyroscopic_stability": gyro_stability,
            # Maxwell internals
            "hamiltonian_excess": excess_energy
        }

        # Análisis topológico (Grafo de correlación de métricas)
        self._build_metric_graph(metrics)
        betti = self._calculate_betti_numbers()
        metrics["betti_0"] = betti[0]
        metrics["betti_1"] = betti[1]
        metrics["graph_vertices"] = self._vertex_count
        metrics["graph_edges"] = self._edge_count

        # Actualizar estado
        self._last_current = current_I
        self._last_time = current_time

        # Guardar en historial
        self._store_metrics(metrics)

        # Guardar historial de estado físico (para compatibilidad y depuración)
        if self.maxwell_solver and len(self.maxwell_solver.E) > 0:
            avg_E = float(np.mean(np.abs(self.maxwell_solver.E)))
            avg_B = float(np.mean(np.abs(self.maxwell_solver.B)))
        else:
            avg_E, avg_B = 0.0, 0.0

        self._state_history.append({
            "time": current_time,
            "E_avg": avg_E,
            "B_avg": avg_B,
            "energy": H_total,
            "Q": avg_E * self.C, # Aproximación para compatibilidad
            "I": avg_B           # Aproximación
        })

        return metrics

    def _get_zero_metrics(self) -> Dict[str, float]:
        """Métricas iniciales para casos triviales."""
        return {
            "saturation": 0.0,
            "complexity": 1.0,
            "current_I": 0.0,
            "potential_energy": 0.0,
            "kinetic_energy": 0.0,
            "total_energy": 0.0,
            "dissipated_power": 0.0,
            "flyback_voltage": 0.0,
            "dynamic_resistance": self.R,
            "damping_ratio": self._zeta,
            "damping_type": self._damping_type,
            "resonant_frequency_hz": self._omega_0 / (2 * math.pi),
            "quality_factor": self._Q,
            "time_constant": self.L / self.R if self.R > 0 else float("inf"),
            "entropy_shannon": 0.0,
            "entropy_absolute": 0.0,
            "entropy_rate": 0.0,
            "entropy_ratio": 0.0,
            "is_thermal_death": False,
            "betti_0": 0,
            "betti_1": 0,
            "graph_vertices": 0,
            "graph_edges": 0,
            "gyroscopic_stability": 1.0,
        }

    def _store_metrics(self, metrics: Dict[str, float]) -> None:
        """Almacena métricas con timestamp."""
        self._metrics_history.append({**metrics, "_timestamp": time.time()})

    def get_trend_analysis(self) -> Dict[str, Any]:
        """Analiza tendencias en métricas históricas."""
        if len(self._metrics_history) < 2:
            return {"status": "INSUFFICIENT_DATA", "samples": len(self._metrics_history)}

        result = {"status": "OK", "samples": len(self._metrics_history)}

        # Métricas a analizar
        keys_to_analyze = ["saturation", "dissipated_power", "entropy_ratio"]

        for key in keys_to_analyze:
            values = [m.get(key, 0.0) for m in self._metrics_history if key in m]
            if len(values) >= 2:
                # Tendencia lineal simple
                first_half = sum(values[: len(values) // 2]) / (len(values) // 2)
                second_half = sum(values[len(values) // 2 :]) / (
                    len(values) - len(values) // 2
                )

                if second_half > first_half * 1.1:
                    trend = "INCREASING"
                elif second_half < first_half * 0.9:
                    trend = "DECREASING"
                else:
                    trend = "STABLE"

                result[key] = {
                    "trend": trend,
                    "current": values[-1],
                    "mean": sum(values) / len(values),
                    "min": min(values),
                    "max": max(values),
                }

        return result

    def get_system_diagnosis(self, metrics: Dict[str, float]) -> Dict[str, str]:
        """Genera diagnóstico del estado del sistema."""
        diagnosis = {
            "state": "NORMAL",
            "damping": self._damping_type,
            "energy": "BALANCED",
            "entropy": "LOW",
        }

        # Diagnóstico de saturación
        saturation = metrics.get("saturation", 0.0)
        if saturation > 0.95:
            diagnosis["state"] = "SATURATED"
        elif saturation < 0.05:
            diagnosis["state"] = "IDLE"

        # Diagnóstico de energía
        pe = metrics.get("potential_energy", 0)
        ke = metrics.get("kinetic_energy", 0)
        total_e = pe + ke

        if total_e > 0:
            if pe / total_e > 0.9:
                diagnosis["energy"] = "POTENTIAL_DOMINATED"
            elif ke / total_e > 0.9:
                diagnosis["energy"] = "KINETIC_DOMINATED"

        # Diagnóstico de potencia
        power = metrics.get("dissipated_power", 0)
        if power > SystemConstants.OVERHEAT_POWER_THRESHOLD:
            diagnosis["state"] = "OVERHEATING"

        # Diagnóstico de entropía
        entropy_ratio = metrics.get("entropy_ratio", 0)
        if entropy_ratio > 0.8:
            diagnosis["entropy"] = "HIGH"
            if metrics.get("is_thermal_death", False):
                diagnosis["state"] = "THERMAL_DEATH"
        elif entropy_ratio > 0.5:
            diagnosis["entropy"] = "MODERATE"

        # Diagnóstico topológico
        betti_0 = metrics.get("betti_0", 1)
        betti_1 = metrics.get("betti_1", 0)

        if betti_0 > 1:
            diagnosis["topology"] = "DISCONNECTED"
        elif betti_1 > 0:
            diagnosis["topology"] = "CYCLIC"
        else:
            diagnosis["topology"] = "SIMPLE"

        # Diagnóstico Giroscópico
        gyro_stability = metrics.get("gyroscopic_stability", 1.0)
        diagnosis["rotation_stability"] = "STABLE"
        if gyro_stability < 0.6:
            diagnosis["rotation_stability"] = (
                "⚠️ PRECESIÓN DETECTADA (Inestabilidad de Flujo)"
            )
            # También escalamos el estado si es crítico
            if gyro_stability < 0.3 and diagnosis["state"] == "NORMAL":
                diagnosis["state"] = "UNSTABLE"

        return diagnosis