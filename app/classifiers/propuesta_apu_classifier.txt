import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Set
from scipy.spatial import Voronoi, Delaunay
import logging

logger = logging.getLogger(__name__)


class APUClassifier:
    """Clasificador robusto de APUs basado en reglas configurables."""

    def __init__(self, config_path: Optional[str] = None):
        self.rules: List[ClassificationRule] = []
        self.default_type = "INDEFINIDO"
        self.zero_cost_type = "SIN_COSTO"
        self._rule_cache: Dict[str, callable] = {}

        self._load_config(config_path)
        self._validate_rules()
        self._compile_rules()

    def _compile_rules(self) -> None:
        """Precompila las reglas para evaluaci√≥n vectorizada eficiente."""
        for rule in self.rules:
            try:
                # Convertir condici√≥n a funci√≥n lambda vectorizada
                condition = rule.condition
                
                # Reemplazar porcentajes para usar formato de array numpy
                condition = condition.replace("porcentaje_materiales", "x")
                condition = condition.replace("porcentaje_mo_eq", "y")
                
                # Escalar de porcentaje (0-100) a fracci√≥n (0-1)
                condition = condition.replace("60.0", "0.6")
                condition = condition.replace("40.0", "0.4")
                condition = condition.replace("50.0", "0.5")
                
                # Crear funci√≥n vectorizada con numpy
                self._rule_cache[rule.rule_type] = self._create_vectorized_function(condition)
            except Exception as e:
                logger.warning(f"No se pudo compilar regla {rule.rule_type}: {e}")

    def _create_vectorized_function(self, condition: str) -> callable:
        """Crea funci√≥n vectorizada a partir de condici√≥n."""
        # Mapeo de operadores a funciones numpy
        condition = condition.replace("and", "&").replace("or", "|").replace("not", "~")
        
        def rule_func(x: np.ndarray, y: np.ndarray) -> np.ndarray:
            """Eval√∫a condici√≥n vectorizada."""
            try:
                # Crear contexto seguro
                context = {
                    'x': x * 100,  # Convertir a porcentaje para evaluaci√≥n
                    'y': y * 100,
                    'np': np
                }
                # Evaluar usando numpy directamente
                return eval(condition, {"__builtins__": {}}, context)
            except Exception as e:
                logger.error(f"Error evaluando condici√≥n {condition}: {e}")
                return np.zeros_like(x, dtype=bool)
        
        return np.vectorize(rule_func, otypes=[bool])

    def _validate_rules(self) -> None:
        """
        Valida coherencia topol√≥gica del conjunto de reglas usando triangulaci√≥n de Delaunay.
        
        Raises:
            ValueError: Si no existen reglas o hay huecos significativos.
        """
        if not self.rules:
            raise ValueError("No hay reglas de clasificaci√≥n definidas")

        # Verificar cobertura con triangulaci√≥n
        coverage_gaps = self._analyze_coverage_voronoi()
        if coverage_gaps:
            gap_area = len(coverage_gaps) / 100.0  # Normalizar por grid
            if gap_area > 0.1:  # M√°s del 10% sin cobertura
                raise ValueError(
                    f"Reglas no cubren {gap_area:.1%} del espacio. "
                    f"Puntos sin cobertura: {len(coverage_gaps)}"
                )
            logger.warning(
                f"‚ö†Ô∏è {len(coverage_gaps)} regiones sin cobertura ({gap_area:.1%})"
            )

    def _analyze_coverage_voronoi(self, grid_size: int = 50) -> List[Tuple[float, float]]:
        """
        Analiza cobertura usando diagramas de Voronoi para detectar huecos.
        
        Args:
            grid_size: Resoluci√≥n de muestreo.
            
        Returns:
            Puntos sin cobertura en la regi√≥n cr√≠tica [0,1]x[0,1].
        """
        # Crear malla de puntos
        x = np.linspace(0, 1, grid_size)
        y = np.linspace(0, 1, grid_size)
        X, Y = np.meshgrid(x, y)
        points = np.column_stack((X.ravel(), Y.ravel()))
        
        # Evaluar todas las reglas
        uncovered = []
        for point in points:
            covered = False
            for rule in self.rules:
                if rule.evaluate(point[0], point[1]):
                    covered = True
                    break
            if not covered:
                uncovered.append((float(point[0]), float(point[1])))
        
        return uncovered

    def classify_single(
        self,
        pct_materiales: float,
        pct_mo_eq: float,
        total_cost: float = 1.0,
    ) -> str:
        """
        Clasifica un √∫nico APU con validaci√≥n mejorada.
        
        Args:
            pct_materiales: Fracci√≥n de materiales [0, 1].
            pct_mo_eq: Fracci√≥n de MO+equipo [0, 1].
            total_cost: Costo total (0 indica APU sin costo).
            
        Returns:
            Tipo de APU seg√∫n reglas.
        """
        # Validar entradas
        if not (0 <= pct_materiales <= 1):
            raise ValueError(f"pct_materiales debe estar en [0,1], recibido {pct_materiales}")
        if not (0 <= pct_mo_eq <= 1):
            raise ValueError(f"pct_mo_eq debe estar en [0,1], recibido {pct_mo_eq}")
        
        # Caso especial: sin costo
        if total_cost <= 0 or np.isnan(total_cost):
            return self.zero_cost_type
        
        # Validar conservaci√≥n de masa (pct_materiales + pct_mo_eq ‚âà 1)
        total_pct = pct_materiales + pct_mo_eq
        if not (0.99 <= total_pct <= 1.01):
            logger.warning(
                f"Suma de porcentajes no es 100%: materiales={pct_materiales:.1%}, "
                f"MO={pct_mo_eq:.1%}, total={total_pct:.1%}"
            )
        
        # Clasificar con reglas compiladas
        for rule in self.rules:
            if rule.rule_type in self._rule_cache:
                try:
                    # Usar funci√≥n compilada
                    func = self._rule_cache[rule.rule_type]
                    if func(np.array([pct_materiales]), np.array([pct_mo_eq]))[0]:
                        return rule.rule_type
                except Exception as e:
                    logger.error(f"Error en regla compilada {rule.rule_type}: {e}")
        
        return self.default_type

    def classify_dataframe(
        self,
        df: pd.DataFrame,
        col_total: str = "VALOR_CONSTRUCCION_UN",
        col_materiales: str = "VALOR_SUMINISTRO_UN",
        col_mo_eq: str = "VALOR_INSTALACION_UN",
        output_col: str = "TIPO_APU",
    ) -> pd.DataFrame:
        """
        Clasifica DataFrame completo con optimizaciones de memoria.
        
        Args:
            df: DataFrame con costos.
            col_total: Columna de costo total.
            col_materiales: Columna de materiales.
            col_mo_eq: Columna de MO+equipo.
            output_col: Columna de salida.
            
        Returns:
            DataFrame con clasificaci√≥n a√±adida.
        """
        df = df.copy()
        
        # Validar columnas
        required = [col_total, col_materiales, col_mo_eq]
        missing = [c for c in required if c not in df.columns]
        if missing:
            raise ValueError(f"Columnas faltantes: {missing}")
        
        # Convertir a arrays numpy para eficiencia
        with pd.option_context('mode.chained_assignment', None):
            # Usar operaciones vectorizadas
            totales = pd.to_numeric(df[col_total], errors='coerce').values
            materiales = pd.to_numeric(df[col_materiales], errors='coerce').values
            mo_eq = pd.to_numeric(df[col_mo_eq], errors='coerce').values
            
            # Calcular porcentajes
            with np.errstate(divide='ignore', invalid='ignore'):
                pct_mat = np.where(totales > 0, materiales / totales, 0)
                pct_mo = np.where(totales > 0, mo_eq / totales, 0)
            
            # Clasificaci√≥n vectorizada optimizada
            tipos = self._classify_vectorized_optimized(totales, pct_mat, pct_mo)
            df[output_col] = tipos
        
        # An√°lisis de calidad
        self._analyze_classification_quality(df, output_col)
        
        return df

    def _classify_vectorized_optimized(
        self,
        totales: np.ndarray,
        pct_mat: np.ndarray,
        pct_mo: np.ndarray,
    ) -> np.ndarray:
        """
        Clasificaci√≥n vectorizada optimizada con operaciones por lotes.
        
        Args:
            totales: Array de costos totales.
            pct_mat: Porcentajes de materiales [0, 1].
            pct_mo: Porcentajes de MO [0, 1].
            
        Returns:
            Array de tipos clasificados.
        """
        n = len(totales)
        tipos = np.full(n, self.default_type, dtype=object)
        
        # M√°scara: APUs sin costo
        mask_sin_costo = (totales <= 0) | np.isnan(totales)
        tipos[mask_sin_costo] = self.zero_cost_type
        
        # M√°scara de v√°lidos
        mask_validos = ~mask_sin_costo
        if not mask_validos.any():
            return tipos
        
        # Extraer puntos v√°lidos
        valid_indices = np.where(mask_validos)[0]
        mat_valid = pct_mat[mask_validos]
        mo_valid = pct_mo[mask_validos]
        
        # Evaluar todas las reglas compiladas simult√°neamente
        rule_masks = {}
        for rule in self.rules:
            if rule.rule_type in self._rule_cache:
                try:
                    func = self._rule_cache[rule.rule_type]
                    rule_mask = func(mat_valid, mo_valid)
                    rule_masks[rule.rule_type] = rule_mask
                except Exception as e:
                    logger.error(f"Error evaluando regla {rule.rule_type}: {e}")
        
        # Aplicar prioridades
        assigned = np.zeros(len(valid_indices), dtype=bool)
        for rule in sorted(self.rules, key=lambda r: r.priority):
            if rule.rule_type in rule_masks:
                # Aplicar solo a puntos no asignados
                available_mask = ~assigned & rule_masks[rule.rule_type]
                if available_mask.any():
                    # Asignar tipo a los √≠ndices originales
                    tipos[valid_indices[available_mask]] = rule.rule_type
                    assigned[available_mask] = True
        
        return tipos

    def _analyze_classification_quality(self, df: pd.DataFrame, tipo_col: str) -> None:
        """
        Analiza calidad de clasificaci√≥n con m√©tricas estad√≠sticas.
        
        Args:
            df: DataFrame clasificado.
            tipo_col: Columna con tipos de APU.
        """
        if tipo_col not in df.columns:
            return
        
        total = len(df)
        if total == 0:
            return
        
        stats = df[tipo_col].value_counts()
        
        # Calcular m√©tricas de calidad
        undefined_mask = df[tipo_col] == self.default_type
        undefined_pct = undefined_mask.sum() / total * 100
        
        zero_cost_mask = df[tipo_col] == self.zero_cost_type
        zero_cost_pct = zero_cost_mask.sum() / total * 100
        
        # Log detallado
        logger.info("=" * 60)
        logger.info("üìä AN√ÅLISIS DE CALIDAD DE CLASIFICACI√ìN")
        logger.info("=" * 60)
        
        for tipo, count in stats.items():
            pct = count / total * 100
            # Histograma ASCII mejorado
            bar_length = int(pct / 2)  # Escala 0-50
            bar = "‚ñà" * bar_length + "‚ñë" * (50 - bar_length)
            
            # Informaci√≥n adicional por tipo
            if tipo == self.default_type:
                info = "‚ö†Ô∏è SIN CLASIFICACI√ìN"
            elif tipo == self.zero_cost_type:
                info = "üí∞ SIN COSTO"
            else:
                # Distribuci√≥n de costos para este tipo
                if 'VALOR_CONSTRUCCION_UN' in df.columns:
                    tipo_mask = df[tipo_col] == tipo
                    avg_cost = df.loc[tipo_mask, 'VALOR_CONSTRUCCION_UN'].mean()
                    info = f"üí∞ Prom: ${avg_cost:,.0f}"
                else:
                    info = ""
            
            logger.info(f"{tipo:20} {count:6} ({pct:5.1f}%) {bar} {info}")
        
        logger.info("-" * 60)
        logger.info(f"Total registros: {total:,}")
        logger.info(f"Indefinidos: {undefined_mask.sum():,} ({undefined_pct:.1f}%)")
        logger.info(f"Sin costo: {zero_cost_mask.sum():,} ({zero_cost_pct:.1f}%)")
        
        # Alertas de calidad
        if undefined_pct > 5:
            logger.warning(f"‚ö†Ô∏è Alto porcentaje de APUs sin clasificar: {undefined_pct:.1f}%")
        if zero_cost_pct > 10:
            logger.warning(f"‚ö†Ô∏è Alto porcentaje de APUs sin costo: {zero_cost_pct:.1f}%")
        
        # An√°lisis de distribuci√≥n espacial
        self._analyze_spatial_distribution(df, tipo_col)

    def _analyze_spatial_distribution(self, df: pd.DataFrame, tipo_col: str) -> None:
        """
        Analiza distribuci√≥n de tipos en el espacio 2D.
        
        Args:
            df: DataFrame con tipos.
            tipo_col: Columna con tipos.
        """
        # Verificar columnas necesarias
        required = ['PORCENTAJE_MATERIALES', 'PORCENTAJE_MO_EQ']
        if not all(col in df.columns for col in required):
            return
        
        # Calcular centroides por tipo
        centroids = {}
        for tipo in df[tipo_col].unique():
            mask = df[tipo_col] == tipo
            if mask.any():
                x_centroid = df.loc[mask, 'PORCENTAJE_MATERIALES'].mean()
                y_centroid = df.loc[mask, 'PORCENTAJE_MO_EQ'].mean()
                centroids[tipo] = (x_centroid, y_centroid)
        
        # Log de centroides
        if centroids:
            logger.info("\nüìç CENTROIDES POR TIPO (Espacio [0,1]x[0,1]):")
            for tipo, (x, y) in centroids.items():
                logger.info(f"  {tipo:20}: Materiales={x:.2f}, MO={y:.2f}")


class StructuralClassifier(APUClassifier):
    """
    Clasificador que considera la topolog√≠a de soporte del APU.
    """
    
    def classify_by_structure(
        self,
        insumos_del_apu: List[Dict],
        min_support_threshold: float = 0.1
    ) -> Tuple[str, Dict[str, float]]:
        """
        Clasifica el APU bas√°ndose en la naturaleza de su cimentaci√≥n (Nivel 3).
        
        Args:
            insumos_del_apu: Lista de diccionarios con insumos.
            min_support_threshold: Umbral m√≠nimo para considerar dominancia.
            
        Returns:
            Tuple (tipo, m√©tricas de soporte)
        """
        if not insumos_del_apu:
            return "ESTRUCTURA_VACIA", {}
        
        # Calcular distribuci√≥n de tipos
        tipo_counts: Dict[str, int] = {}
        tipo_valores: Dict[str, float] = {}
        
        for insumo in insumos_del_apu:
            tipo = insumo.get('TIPO_INSUMO', 'DESCONOCIDO')
            valor = insumo.get('VALOR_TOTAL', 0.0)
            
            tipo_counts[tipo] = tipo_counts.get(tipo, 0) + 1
            tipo_valores[tipo] = tipo_valores.get(tipo, 0.0) + valor
        
        # Calcular m√©tricas de soporte
        total_insumos = len(insumos_del_apu)
        total_valor = sum(tipo_valores.values())
        
        if total_valor == 0:
            return "SIN_VALOR", tipo_valores
        
        # Calcular porcentajes
        pct_counts = {tipo: count/total_insumos for tipo, count in tipo_counts.items()}
        pct_valores = {tipo: valor/total_valor for tipo, valor in tipo_valores.items()}
        
        # An√°lisis de dominancia
        mo_valor = tipo_valores.get('MANO_DE_OBRA', 0.0)
        mat_valor = tipo_valores.get('SUMINISTRO', 0.0)
        eq_valor = tipo_valores.get('EQUIPO', 0.0)
        
        mo_pct = mo_valor / total_valor
        mat_pct = mat_valor / total_valor
        eq_pct = eq_valor / total_valor
        
        # Reglas de clasificaci√≥n topol√≥gica
        if mo_pct + eq_pct > min_support_threshold and mat_pct < min_support_threshold:
            return "SERVICIO_PURO", pct_valores
        elif mat_pct > min_support_threshold and mo_pct + eq_pct < min_support_threshold:
            return "SUMINISTRO_PURO", pct_valores
        elif mo_pct > 0.6:
            return "INTENSIVO_MANO_OBRA", pct_valores
        elif mat_pct > 0.6:
            return "INTENSIVO_MATERIALES", pct_valores
        elif eq_pct > 0.4:
            return "INTENSIVO_EQUIPO", pct_valores
        
        # An√°lisis de diversidad
        diversity_index = len(tipo_counts) / total_insumos
        
        if diversity_index > 0.7:
            return "ESTRUCTURA_COMPLEJA", pct_valores
        elif diversity_index < 0.3:
            dominant_type = max(tipo_counts.items(), key=lambda x: x[1])[0]
            return f"MONO_ESTRUCTURA_{dominant_type}", pct_valores
        
        return "ESTRUCTURA_MIXTA", pct_valores
        