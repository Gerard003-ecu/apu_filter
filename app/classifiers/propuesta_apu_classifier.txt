### m√©todos refinados "apu_classifier"

import re
from typing import Tuple


@dataclass
class ClassificationRule:
    """Estructura para reglas de clasificaci√≥n con validaci√≥n integrada."""

    rule_type: str
    priority: int
    condition: str
    description: str

    _ALLOWED_VARS: set = None
    _CONDITION_PATTERN: re.Pattern = None

    def __post_init__(self):
        """Normaliza y valida la condici√≥n al instanciar."""
        # Inicializar constantes de clase si no existen
        if ClassificationRule._ALLOWED_VARS is None:
            ClassificationRule._ALLOWED_VARS = frozenset({
                'porcentaje_materiales', 'porcentaje_mo_eq'
            })
            ClassificationRule._CONDITION_PATTERN = re.compile(
                r'^[\d\s\.\(\)><=!]+$|porcentaje_materiales|porcentaje_mo_eq|and|or|not'
            )

        self.condition = self._normalize_condition(self.condition)
        self._validate_syntax()

    def _normalize_condition(self, condition: str) -> str:
        """
        Normaliza operadores l√≥gicos SQL-style a sintaxis Python.
        
        Transforma AND/OR/NOT (case-insensitive) a and/or/not.
        """
        condition = re.sub(r'\bAND\b', 'and', condition, flags=re.IGNORECASE)
        condition = re.sub(r'\bOR\b', 'or', condition, flags=re.IGNORECASE)
        condition = re.sub(r'\bNOT\b', 'not', condition, flags=re.IGNORECASE)
        return condition.strip()

    def _validate_syntax(self) -> None:
        """
        Valida que la condici√≥n sea sint√°cticamente segura y evaluable.
        
        Raises:
            ValueError: Si la condici√≥n contiene elementos no permitidos.
        """
        test_expr = self.condition
        
        # Remover elementos v√°lidos para detectar residuos peligrosos
        for var in self._ALLOWED_VARS:
            test_expr = test_expr.replace(var, ' ')
        
        # Remover literales num√©ricos (int y float)
        test_expr = re.sub(r'\b\d+\.?\d*\b', ' ', test_expr)
        
        # Remover operadores y palabras clave permitidas
        allowed_tokens = ['>=', '<=', '==', '!=', '>', '<', 'and', 'or', 'not', '(', ')']
        for token in allowed_tokens:
            test_expr = test_expr.replace(token, ' ')
        
        remaining = test_expr.strip()
        if remaining:
            raise ValueError(
                f"Condici√≥n contiene elementos no permitidos: '{remaining}' "
                f"en expresi√≥n '{self.condition}'"
            )
        
        # Verificar sintaxis Python v√°lida
        try:
            compile(self.condition, '<condition>', 'eval')
        except SyntaxError as e:
            raise ValueError(f"Sintaxis inv√°lida en condici√≥n: {e}")

    def evaluate(self, pct_materiales: float, pct_mo_eq: float) -> bool:
        """
        Eval√∫a la condici√≥n con los porcentajes proporcionados.

        Args:
            pct_materiales: Fracci√≥n de materiales [0, 1].
            pct_mo_eq: Fracci√≥n de MO+equipo [0, 1].

        Returns:
            True si la condici√≥n se satisface.
        """
        try:
            # Escalar a porcentaje [0, 100] para consistencia con condiciones
            safe_context = {
                "__builtins__": {},
                "porcentaje_materiales": pct_materiales * 100.0,
                "porcentaje_mo_eq": pct_mo_eq * 100.0,
            }
            return bool(eval(self.condition, safe_context))
        except Exception as e:
            logger.error(
                f"Error evaluando regla '{self.rule_type}' | "
                f"mat={pct_materiales:.2%}, mo={pct_mo_eq:.2%}: {e}"
            )
            return False

    def get_coverage_bounds(self) -> Tuple[Tuple[float, float], Tuple[float, float]]:
        """
        Extrae l√≠mites heur√≠sticos de cobertura en el espacio [0,1]¬≤.
        
        √ötil para an√°lisis topol√≥gico de la partici√≥n del espacio.

        Returns:
            ((mat_min, mat_max), (mo_min, mo_max)) normalizados a [0, 1].
        """
        mat_min, mat_max = 0.0, 1.0
        mo_min, mo_max = 0.0, 1.0

        bound_patterns = [
            (r'porcentaje_materiales\s*>=\s*(\d+\.?\d*)', 'mat', 'min'),
            (r'porcentaje_materiales\s*>\s*(\d+\.?\d*)', 'mat', 'min'),
            (r'porcentaje_materiales\s*<=\s*(\d+\.?\d*)', 'mat', 'max'),
            (r'porcentaje_materiales\s*<\s*(\d+\.?\d*)', 'mat', 'max'),
            (r'porcentaje_mo_eq\s*>=\s*(\d+\.?\d*)', 'mo', 'min'),
            (r'porcentaje_mo_eq\s*>\s*(\d+\.?\d*)', 'mo', 'min'),
            (r'porcentaje_mo_eq\s*<=\s*(\d+\.?\d*)', 'mo', 'max'),
            (r'porcentaje_mo_eq\s*<\s*(\d+\.?\d*)', 'mo', 'max'),
        ]

        for pattern, var_type, bound_type in bound_patterns:
            match = re.search(pattern, self.condition)
            if match:
                value = float(match.group(1)) / 100.0
                if var_type == 'mat':
                    if bound_type == 'min':
                        mat_min = max(mat_min, value)
                    else:
                        mat_max = min(mat_max, value)
                else:
                    if bound_type == 'min':
                        mo_min = max(mo_min, value)
                    else:
                        mo_max = min(mo_max, value)

        return ((mat_min, mat_max), (mo_min, mo_max))


### segundo m√©todo refinado

class APUClassifier:
    """Clasificador robusto de APUs basado en reglas configurables."""

    def __init__(self, config_path: Optional[str] = None):
        self.rules: List[ClassificationRule] = []
        self.default_type = "INDEFINIDO"
        self.zero_cost_type = "SIN_COSTO"
        
        self._load_config(config_path)
        self._validate_rules()

    def _load_config(self, config_path: Optional[str]) -> None:
        """
        Carga reglas desde archivo JSON con validaci√≥n robusta.
        
        Args:
            config_path: Ruta al archivo de configuraci√≥n.
        """
        if not config_path or not Path(config_path).exists():
            logger.warning("‚ö†Ô∏è Configuraci√≥n no encontrada, usando reglas por defecto")
            self._load_default_rules()
            return

        try:
            with open(config_path, "r", encoding="utf-8") as f:
                config = json.load(f)

            rules_config = config.get("apu_classification_rules", {})
            loaded_count = 0

            for idx, rule_dict in enumerate(rules_config.get("rules", [])):
                try:
                    if "type" not in rule_dict or "condition" not in rule_dict:
                        raise KeyError("Faltan campos obligatorios 'type' o 'condition'")
                    
                    rule = ClassificationRule(
                        rule_type=rule_dict["type"],
                        priority=rule_dict.get("priority", 99),
                        condition=rule_dict["condition"],
                        description=rule_dict.get("description", ""),
                    )
                    self.rules.append(rule)
                    loaded_count += 1
                except (KeyError, ValueError) as e:
                    logger.warning(f"‚ö†Ô∏è Regla √≠ndice {idx} inv√°lida, omitida: {e}")

            if not self.rules:
                logger.warning("‚ö†Ô∏è Sin reglas v√°lidas en config, usando por defecto")
                self._load_default_rules()
                return

            self.rules.sort(key=lambda r: r.priority)
            self.default_type = rules_config.get("default_type", "INDEFINIDO")
            self.zero_cost_type = rules_config.get("zero_cost_type", "SIN_COSTO")

            logger.info(f"‚úÖ {loaded_count} reglas de clasificaci√≥n cargadas")

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON malformado: {e}")
            self._load_default_rules()
        except Exception as e:
            logger.error(f"‚ùå Error cargando configuraci√≥n: {e}")
            self._load_default_rules()

    def _load_default_rules(self) -> None:
        """
        Reglas por defecto dise√±adas para cubrir el espacio [0,1]¬≤ completamente.
        
        La partici√≥n sigue un orden de prioridad que garantiza clasificaci√≥n
        determinista sin ambig√ºedades topol√≥gicas.
        """
        self.rules = [
            ClassificationRule(
                rule_type="INSTALACION",
                priority=1,
                condition="porcentaje_mo_eq >= 60.0",
                description="Predomina MO/equipo (‚â•60%)",
            ),
            ClassificationRule(
                rule_type="SUMINISTRO",
                priority=2,
                condition="porcentaje_materiales >= 60.0",
                description="Predomina materiales (‚â•60%)",
            ),
            ClassificationRule(
                rule_type="CONSTRUCCION_MIXTO",
                priority=3,
                condition=(
                    "(porcentaje_materiales >= 40.0 and porcentaje_materiales < 60.0) or "
                    "(porcentaje_mo_eq >= 40.0 and porcentaje_mo_eq < 60.0)"
                ),
                description="Composici√≥n mixta (40-60%)",
            ),
            ClassificationRule(
                rule_type="OBRA_COMPLETA",
                priority=4,
                condition="porcentaje_materiales >= 0 and porcentaje_mo_eq >= 0",
                description="Cobertura residual universal",
            ),
        ]
        self.default_type = "INDEFINIDO"
        self.zero_cost_type = "SIN_COSTO"

    def _validate_rules(self) -> None:
        """
        Valida coherencia topol√≥gica del conjunto de reglas.
        
        Raises:
            ValueError: Si no existen reglas.
        """
        if not self.rules:
            raise ValueError("No hay reglas de clasificaci√≥n definidas")

        # Detectar tipos duplicados
        types = [r.rule_type for r in self.rules]
        duplicates = {t for t in types if types.count(t) > 1}
        if duplicates:
            logger.warning(f"‚ö†Ô∏è Tipos duplicados: {duplicates}")

        # An√°lisis de cobertura del espacio
        uncovered = self._sample_uncovered_regions(grid_size=20)
        if uncovered:
            logger.warning(
                f"‚ö†Ô∏è Detectadas {len(uncovered)} regiones sin cobertura. "
                f"Fallback: '{self.default_type}'"
            )

    def _sample_uncovered_regions(
        self, grid_size: int = 20
    ) -> List[Tuple[float, float]]:
        """
        Muestrea el espacio [0,1]¬≤ para detectar huecos en la cobertura.
        
        Args:
            grid_size: Resoluci√≥n de la grilla de muestreo.
            
        Returns:
            Lista de puntos (pct_mat, pct_mo) no cubiertos.
        """
        uncovered = []
        step = 1.0 / max(grid_size - 1, 1)

        for i in range(grid_size):
            for j in range(grid_size):
                pct_mat, pct_mo = i * step, j * step
                
                if not any(r.evaluate(pct_mat, pct_mo) for r in self.rules):
                    uncovered.append((pct_mat, pct_mo))

        return uncovered

    def classify_single(
        self,
        pct_materiales: float,
        pct_mo_eq: float,
        total_cost: float = 1.0,
    ) -> str:
        """
        Clasifica un √∫nico APU.

        Args:
            pct_materiales: Fracci√≥n de materiales [0, 1].
            pct_mo_eq: Fracci√≥n de MO+equipo [0, 1].
            total_cost: Costo total (0 indica APU sin costo).

        Returns:
            Tipo de APU seg√∫n reglas.
        """
        # Caso especial: sin costo
        if total_cost <= 0 or (isinstance(total_cost, float) and np.isnan(total_cost)):
            return self.zero_cost_type

        # Normalizar entradas al dominio v√°lido
        pct_materiales = float(np.clip(pct_materiales, 0.0, 1.0))
        pct_mo_eq = float(np.clip(pct_mo_eq, 0.0, 1.0))

        for rule in self.rules:
            if rule.evaluate(pct_materiales, pct_mo_eq):
                return rule.rule_type

        return self.default_type

    def classify_dataframe(
        self,
        df: pd.DataFrame,
        col_total: str = "VALOR_CONSTRUCCION_UN",
        col_materiales: str = "VALOR_SUMINISTRO_UN",
        col_mo_eq: str = "VALOR_INSTALACION_UN",
        output_col: str = "TIPO_APU",
    ) -> pd.DataFrame:
        """
        Clasifica DataFrame completo con operaciones vectorizadas.

        Args:
            df: DataFrame con costos.
            col_total: Columna de costo total.
            col_materiales: Columna de materiales.
            col_mo_eq: Columna de MO+equipo.
            output_col: Columna de salida.

        Returns:
            DataFrame con clasificaci√≥n a√±adida.
        """
        df = df.copy()
        required = [col_total, col_materiales, col_mo_eq]
        missing = [c for c in required if c not in df.columns]

        if missing:
            logger.error(f"‚ùå Columnas faltantes: {missing}")
            df[output_col] = self.default_type
            return df

        # Extraer arrays num√©ricos
        totales = pd.to_numeric(df[col_total], errors='coerce').fillna(0).values
        materiales = pd.to_numeric(df[col_materiales], errors='coerce').fillna(0).values
        mo_eq = pd.to_numeric(df[col_mo_eq], errors='coerce').fillna(0).values

        # Clasificaci√≥n vectorizada
        df[output_col] = self._classify_vectorized(totales, materiales, mo_eq)
        
        self._log_classification_stats(df[output_col])
        return df

    def _classify_vectorized(
        self,
        totales: np.ndarray,
        materiales: np.ndarray,
        mo_eq: np.ndarray,
    ) -> np.ndarray:
        """
        Clasificaci√≥n vectorizada O(n) usando m√°scaras NumPy.

        Args:
            totales: Array de costos totales.
            materiales: Array de costos de materiales.
            mo_eq: Array de costos MO+equipo.

        Returns:
            Array de tipos clasificados.
        """
        n = len(totales)
        tipos = np.full(n, self.default_type, dtype=object)

        # M√°scara: APUs sin costo
        mask_sin_costo = (totales <= 0) | np.isnan(totales)
        tipos[mask_sin_costo] = self.zero_cost_type

        # Calcular porcentajes solo para v√°lidos
        mask_validos = ~mask_sin_costo
        if not mask_validos.any():
            return tipos

        totales_safe = np.where(mask_validos, totales, 1.0)
        pct_mat = np.clip(materiales / totales_safe, 0.0, 1.0)
        pct_mo = np.clip(mo_eq / totales_safe, 0.0, 1.0)

        # Aplicar reglas secuencialmente con m√°scara de pendientes
        pendientes = mask_validos.copy()

        for rule in self.rules:
            if not pendientes.any():
                break

            cumple = self._eval_rule_vectorized(rule, pct_mat, pct_mo, pendientes)
            tipos[cumple] = rule.rule_type
            pendientes &= ~cumple

        return tipos

    def _eval_rule_vectorized(
        self,
        rule: ClassificationRule,
        pct_mat: np.ndarray,
        pct_mo: np.ndarray,
        mask_activos: np.ndarray,
    ) -> np.ndarray:
        """
        Eval√∫a regla de forma vectorizada sobre arrays.

        Args:
            rule: Regla a evaluar.
            pct_mat: Porcentajes de materiales [0, 1].
            pct_mo: Porcentajes de MO [0, 1].
            mask_activos: M√°scara de elementos a considerar.

        Returns:
            M√°scara booleana de elementos que cumplen la regla.
        """
        try:
            context = {
                "__builtins__": {},
                "porcentaje_materiales": pct_mat * 100.0,
                "porcentaje_mo_eq": pct_mo * 100.0,
            }
            result = eval(rule.condition, context)
            
            # Manejar resultado escalar vs array
            if np.isscalar(result):
                result = np.full(len(pct_mat), result, dtype=bool)
            
            return np.asarray(result, dtype=bool) & mask_activos
            
        except Exception as e:
            logger.error(f"Error vectorizado en '{rule.rule_type}': {e}")
            return np.zeros(len(pct_mat), dtype=bool)

    def _log_classification_stats(self, series: pd.Series) -> None:
        """Registra estad√≠sticas con visualizaci√≥n mejorada."""
        total = len(series)
        if total == 0:
            logger.warning("‚ö†Ô∏è DataFrame vac√≠o")
            return

        stats = series.value_counts()
        
        logger.info("‚ïê" * 55)
        logger.info("üìä ESTAD√çSTICAS DE CLASIFICACI√ìN")
        logger.info("‚ïê" * 55)

        for tipo, count in stats.items():
            pct = (count / total) * 100
            bar = "‚ñà" * int(pct / 5) + "‚ñë" * (20 - int(pct / 5))
            logger.info(f"  {tipo:<18} ‚îÇ {count:>6} ‚îÇ {pct:>5.1f}% ‚îÇ {bar}")

        logger.info("‚îÄ" * 55)
        logger.info(f"  {'TOTAL':<18} ‚îÇ {total:>6}")
        logger.info("‚ïê" * 55)

        # Alertas
        for alert_type, label in [
            (self.default_type, "sin clasificar"),
            (self.zero_cost_type, "sin costo"),
        ]:
            count = stats.get(alert_type, 0)
            if count > 0:
                logger.warning(
                    f"‚ö†Ô∏è {count} APUs ({count/total*100:.1f}%) {label} "
                    f"[{alert_type}]"
                )

    def get_coverage_report(self) -> pd.DataFrame:
        """
        Genera reporte de cobertura topol√≥gica de las reglas.

        Returns:
            DataFrame con bounds estimados y √°rea de cada regla.
        """
        data = []
        for rule in self.rules:
            (mat_min, mat_max), (mo_min, mo_max) = rule.get_coverage_bounds()
            area = (mat_max - mat_min) * (mo_max - mo_min)
            
            data.append({
                "tipo": rule.rule_type,
                "prioridad": rule.priority,
                "mat_range": f"[{mat_min:.0%}, {mat_max:.0%}]",
                "mo_range": f"[{mo_min:.0%}, {mo_max:.0%}]",
                "area_estimada": f"{area:.1%}",
                "condicion": rule.condition,
            })

        return pd.DataFrame(data)


### m√©todos refinados de las pruebas

Suite de Pruebas Refinada para APUClassifier

"""
Tests exhaustivos para el clasificador APU refactorizado.

Cubre:
- Normalizaci√≥n de operadores l√≥gicos
- Validaci√≥n sint√°ctica de condiciones
- Clasificaci√≥n individual y vectorizada
- An√°lisis de cobertura topol√≥gica
- Edge cases y robustez num√©rica
"""

import json
import os
import tempfile
from typing import List, Tuple

import numpy as np
import pandas as pd
import pytest

from app.classifiers.apu_classifier import APUClassifier, ClassificationRule

CONFIG_PATH = "config/config_rules.json"


# =============================================================================
# FIXTURES
# =============================================================================


@pytest.fixture
def default_classifier() -> APUClassifier:
    """Clasificador con reglas por defecto."""
    return APUClassifier()


@pytest.fixture
def config_classifier() -> APUClassifier:
    """Clasificador con configuraci√≥n real si existe."""
    if os.path.exists(CONFIG_PATH):
        return APUClassifier(CONFIG_PATH)
    pytest.skip(f"Archivo de configuraci√≥n no encontrado: {CONFIG_PATH}")


@pytest.fixture
def temp_config_path():
    """Genera archivo de configuraci√≥n temporal y lo limpia despu√©s."""
    paths = []
    
    def _create_config(config_dict: dict) -> str:
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".json", delete=False, encoding="utf-8"
        ) as f:
            json.dump(config_dict, f)
            paths.append(f.name)
            return f.name
    
    yield _create_config
    
    for path in paths:
        if os.path.exists(path):
            os.unlink(path)


@pytest.fixture
def sample_dataframe() -> pd.DataFrame:
    """DataFrame de prueba con diversos escenarios."""
    return pd.DataFrame({
        "VALOR_CONSTRUCCION_UN": [100, 200, 150, 300, 0, 50, 1000, np.nan],
        "VALOR_SUMINISTRO_UN": [70, 120, 45, 180, 0, 35, 100, 50],
        "VALOR_INSTALACION_UN": [30, 80, 105, 120, 0, 15, 900, 50],
    })


# =============================================================================
# TESTS: ClassificationRule - Normalizaci√≥n de Operadores
# =============================================================================


class TestClassificationRuleNormalization:
    """Tests para normalizaci√≥n de operadores l√≥gicos SQL ‚Üí Python."""

    @pytest.mark.parametrize("input_condition,expected_normalized", [
        # May√∫sculas
        ("porcentaje_materiales >= 50 AND porcentaje_mo_eq >= 30",
         "porcentaje_materiales >= 50 and porcentaje_mo_eq >= 30"),
        # Min√∫sculas (sin cambio)
        ("porcentaje_materiales >= 50 and porcentaje_mo_eq >= 30",
         "porcentaje_materiales >= 50 and porcentaje_mo_eq >= 30"),
        # Mixto
        ("porcentaje_materiales >= 50 And porcentaje_mo_eq >= 30",
         "porcentaje_materiales >= 50 and porcentaje_mo_eq >= 30"),
        # OR
        ("porcentaje_materiales >= 60 OR porcentaje_mo_eq >= 60",
         "porcentaje_materiales >= 60 or porcentaje_mo_eq >= 60"),
        # NOT
        ("NOT porcentaje_materiales >= 50",
         "not porcentaje_materiales >= 50"),
        # Combinaci√≥n compleja
        ("(porcentaje_materiales >= 40 AND porcentaje_materiales <= 60) OR "
         "(porcentaje_mo_eq >= 40 AND porcentaje_mo_eq <= 60)",
         "(porcentaje_materiales >= 40 and porcentaje_materiales <= 60) or "
         "(porcentaje_mo_eq >= 40 and porcentaje_mo_eq <= 60)"),
    ])
    def test_operator_normalization(self, input_condition: str, expected_normalized: str):
        """Verifica normalizaci√≥n AND/OR/NOT ‚Üí and/or/not."""
        rule = ClassificationRule(
            rule_type="TEST",
            priority=1,
            condition=input_condition,
            description="Test normalization",
        )
        assert rule.condition == expected_normalized

    def test_preserves_variable_names(self):
        """Verifica que no modifique 'and'/'or' dentro de nombres de variables."""
        # Edge case: nombres hipot√©ticos que contienen 'and'/'or'
        condition = "porcentaje_materiales >= 50"
        rule = ClassificationRule(
            rule_type="TEST",
            priority=1,
            condition=condition,
            description="Test",
        )
        assert "porcentaje_materiales" in rule.condition


# =============================================================================
# TESTS: ClassificationRule - Validaci√≥n Sint√°ctica
# =============================================================================


class TestClassificationRuleValidation:
    """Tests para validaci√≥n de seguridad y sintaxis."""

    @pytest.mark.parametrize("valid_condition", [
        "porcentaje_materiales >= 50",
        "porcentaje_mo_eq > 30",
        "porcentaje_materiales >= 40 and porcentaje_materiales <= 60",
        "(porcentaje_materiales >= 50) or (porcentaje_mo_eq >= 50)",
        "not porcentaje_materiales >= 80",
        "porcentaje_materiales == 50.5",
        "porcentaje_mo_eq != 0",
        "porcentaje_materiales >= 0 and porcentaje_mo_eq >= 0",
    ])
    def test_valid_conditions_accepted(self, valid_condition: str):
        """Condiciones v√°lidas deben ser aceptadas."""
        rule = ClassificationRule(
            rule_type="TEST",
            priority=1,
            condition=valid_condition,
            description="Valid",
        )
        assert rule.condition is not None

    @pytest.mark.parametrize("invalid_condition,error_fragment", [
        # Inyecci√≥n de c√≥digo
        ("__import__('os').system('ls')", "no permitidos"),
        ("exec('print(1)')", "no permitidos"),
        ("eval('1+1')", "no permitidos"),
        # Variables no permitidas
        ("unknown_var >= 50", "no permitidos"),
        ("porcentaje_materiales >= x", "no permitidos"),
        # Funciones no permitidas
        ("len(porcentaje_materiales) > 0", "no permitidos"),
        ("abs(porcentaje_materiales) >= 50", "no permitidos"),
        # Sintaxis inv√°lida
        ("porcentaje_materiales >= ", "Sintaxis inv√°lida"),
        ("porcentaje_materiales >= 50 &&", "no permitidos"),
        ("porcentaje_materiales >= 50 ||", "no permitidos"),
    ])
    def test_invalid_conditions_rejected(self, invalid_condition: str, error_fragment: str):
        """Condiciones inv√°lidas o peligrosas deben ser rechazadas."""
        with pytest.raises(ValueError) as exc_info:
            ClassificationRule(
                rule_type="TEST",
                priority=1,
                condition=invalid_condition,
                description="Invalid",
            )
        assert error_fragment in str(exc_info.value)

    def test_empty_condition_rejected(self):
        """Condici√≥n vac√≠a debe ser rechazada."""
        with pytest.raises(ValueError):
            ClassificationRule(
                rule_type="TEST",
                priority=1,
                condition="   ",
                description="Empty",
            )


# =============================================================================
# TESTS: ClassificationRule - Evaluaci√≥n
# =============================================================================


class TestClassificationRuleEvaluation:
    """Tests para evaluaci√≥n de reglas."""

    @pytest.mark.parametrize("pct_mat,pct_mo,condition,expected", [
        # Pruebas b√°sicas de comparaci√≥n
        (0.60, 0.20, "porcentaje_materiales >= 60", True),
        (0.59, 0.20, "porcentaje_materiales >= 60", False),
        (0.20, 0.70, "porcentaje_mo_eq >= 60", True),
        # Operadores combinados
        (0.50, 0.50, "porcentaje_materiales >= 40 and porcentaje_materiales <= 60", True),
        (0.30, 0.30, "porcentaje_materiales >= 40 and porcentaje_materiales <= 60", False),
        # OR
        (0.70, 0.10, "porcentaje_materiales >= 60 or porcentaje_mo_eq >= 60", True),
        (0.10, 0.70, "porcentaje_materiales >= 60 or porcentaje_mo_eq >= 60", True),
        (0.30, 0.30, "porcentaje_materiales >= 60 or porcentaje_mo_eq >= 60", False),
        # NOT
        (0.30, 0.30, "not porcentaje_materiales >= 60", True),
        (0.70, 0.30, "not porcentaje_materiales >= 60", False),
        # Edge: exactamente en el l√≠mite
        (0.60, 0.40, "porcentaje_materiales >= 60.0", True),
        (0.40, 0.60, "porcentaje_mo_eq >= 60.0", True),
    ])
    def test_evaluate_conditions(
        self, pct_mat: float, pct_mo: float, condition: str, expected: bool
    ):
        """Verifica evaluaci√≥n correcta de diversas condiciones."""
        rule = ClassificationRule(
            rule_type="TEST",
            priority=1,
            condition=condition,
            description="Test",
        )
        assert rule.evaluate(pct_mat, pct_mo) == expected

    def test_evaluate_handles_boundary_values(self):
        """Verifica manejo de valores l√≠mite [0, 1]."""
        rule = ClassificationRule(
            rule_type="TEST",
            priority=1,
            condition="porcentaje_materiales >= 0 and porcentaje_mo_eq >= 0",
            description="Universal",
        )
        
        assert rule.evaluate(0.0, 0.0) is True
        assert rule.evaluate(1.0, 1.0) is True
        assert rule.evaluate(0.5, 0.5) is True


# =============================================================================
# TESTS: ClassificationRule - Cobertura Topol√≥gica
# =============================================================================


class TestClassificationRuleCoverageBounds:
    """Tests para extracci√≥n de l√≠mites de cobertura."""

    @pytest.mark.parametrize("condition,expected_mat,expected_mo", [
        ("porcentaje_materiales >= 60", (0.60, 1.0), (0.0, 1.0)),
        ("porcentaje_mo_eq >= 70", (0.0, 1.0), (0.70, 1.0)),
        ("porcentaje_materiales >= 40 and porcentaje_materiales <= 60",
         (0.40, 0.60), (0.0, 1.0)),
        ("porcentaje_mo_eq > 50 and porcentaje_mo_eq < 80",
         (0.0, 1.0), (0.50, 0.80)),
    ])
    def test_get_coverage_bounds(
        self,
        condition: str,
        expected_mat: Tuple[float, float],
        expected_mo: Tuple[float, float],
    ):
        """Verifica extracci√≥n heur√≠stica de bounds."""
        rule = ClassificationRule(
            rule_type="TEST",
            priority=1,
            condition=condition,
            description="Test",
        )
        (mat_min, mat_max), (mo_min, mo_max) = rule.get_coverage_bounds()
        
        assert abs(mat_min - expected_mat[0]) < 0.01
        assert abs(mat_max - expected_mat[1]) < 0.01
        assert abs(mo_min - expected_mo[0]) < 0.01
        assert abs(mo_max - expected_mo[1]) < 0.01


# =============================================================================
# TESTS: APUClassifier - Carga de Configuraci√≥n
# =============================================================================


class TestAPUClassifierConfigLoading:
    """Tests para carga de configuraci√≥n."""

    def test_loads_default_rules_without_config(self):
        """Sin config, debe cargar reglas por defecto."""
        classifier = APUClassifier()
        
        assert len(classifier.rules) > 0
        assert classifier.default_type == "INDEFINIDO"
        assert classifier.zero_cost_type == "SIN_COSTO"

    def test_loads_config_from_json(self, temp_config_path):
        """Carga correcta desde archivo JSON."""
        config = {
            "apu_classification_rules": {
                "rules": [
                    {
                        "type": "CUSTOM_TYPE",
                        "priority": 1,
                        "condition": "porcentaje_materiales >= 50",
                        "description": "Custom rule",
                    }
                ],
                "default_type": "CUSTOM_DEFAULT",
                "zero_cost_type": "CUSTOM_ZERO",
            }
        }
        config_path = temp_config_path(config)
        
        classifier = APUClassifier(config_path)
        
        assert len(classifier.rules) == 1
        assert classifier.rules[0].rule_type == "CUSTOM_TYPE"
        assert classifier.default_type == "CUSTOM_DEFAULT"
        assert classifier.zero_cost_type == "CUSTOM_ZERO"

    def test_handles_invalid_json_gracefully(self, temp_config_path):
        """JSON malformado debe fallback a defaults."""
        # Crear archivo con JSON inv√°lido manualmente
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".json", delete=False
        ) as f:
            f.write("{invalid json content")
            bad_path = f.name
        
        try:
            classifier = APUClassifier(bad_path)
            assert len(classifier.rules) > 0  # Debe tener defaults
        finally:
            os.unlink(bad_path)

    def test_skips_invalid_rules_in_config(self, temp_config_path):
        """Reglas inv√°lidas deben ser omitidas, no crashear."""
        config = {
            "apu_classification_rules": {
                "rules": [
                    {
                        "type": "VALID_RULE",
                        "priority": 1,
                        "condition": "porcentaje_materiales >= 50",
                    },
                    {
                        "type": "INVALID_RULE",
                        "priority": 2,
                        "condition": "__import__('os')",  # Inv√°lida
                    },
                    {
                        # Falta 'type' - inv√°lida
                        "priority": 3,
                        "condition": "porcentaje_mo_eq >= 50",
                    },
                ],
            }
        }
        config_path = temp_config_path(config)
        
        classifier = APUClassifier(config_path)
        
        # Solo la primera regla v√°lida debe cargarse
        assert len(classifier.rules) == 1
        assert classifier.rules[0].rule_type == "VALID_RULE"

    def test_sorts_rules_by_priority(self, temp_config_path):
        """Reglas deben ordenarse por prioridad ascendente."""
        config = {
            "apu_classification_rules": {
                "rules": [
                    {"type": "LOW", "priority": 10, "condition": "porcentaje_materiales >= 0"},
                    {"type": "HIGH", "priority": 1, "condition": "porcentaje_materiales >= 90"},
                    {"type": "MED", "priority": 5, "condition": "porcentaje_materiales >= 50"},
                ],
            }
        }
        config_path = temp_config_path(config)
        
        classifier = APUClassifier(config_path)
        
        priorities = [r.priority for r in classifier.rules]
        assert priorities == sorted(priorities)
        assert classifier.rules[0].rule_type == "HIGH"


# =============================================================================
# TESTS: APUClassifier - Clasificaci√≥n Individual
# =============================================================================


class TestAPUClassifierSingleClassification:
    """Tests para classify_single."""

    def test_zero_cost_returns_sin_costo(self, default_classifier):
        """Costo cero debe retornar SIN_COSTO."""
        result = default_classifier.classify_single(0.5, 0.5, total_cost=0.0)
        assert result == "SIN_COSTO"

    def test_negative_cost_returns_sin_costo(self, default_classifier):
        """Costo negativo debe retornar SIN_COSTO."""
        result = default_classifier.classify_single(0.5, 0.5, total_cost=-100.0)
        assert result == "SIN_COSTO"

    def test_nan_cost_returns_sin_costo(self, default_classifier):
        """Costo NaN debe retornar SIN_COSTO."""
        result = default_classifier.classify_single(0.5, 0.5, total_cost=np.nan)
        assert result == "SIN_COSTO"

    @pytest.mark.parametrize("pct_mat,pct_mo,expected", [
        (0.70, 0.30, "SUMINISTRO"),       # Materiales >= 60%
        (0.30, 0.70, "INSTALACION"),       # MO >= 60%
        (0.50, 0.50, "CONSTRUCCION_MIXTO"), # Balance
        (0.45, 0.45, "CONSTRUCCION_MIXTO"), # Rango 40-60
    ])
    def test_default_rules_classification(
        self, default_classifier, pct_mat: float, pct_mo: float, expected: str
    ):
        """Verifica clasificaci√≥n con reglas por defecto."""
        result = default_classifier.classify_single(pct_mat, pct_mo, total_cost=100.0)
        assert result == expected

    def test_clips_out_of_range_percentages(self, default_classifier):
        """Porcentajes fuera de [0,1] deben ser clipped."""
        # pct > 1 debe tratarse como 1
        result = default_classifier.classify_single(1.5, 0.0, total_cost=100.0)
        assert result in ["SUMINISTRO", "OBRA_COMPLETA"]  # Materiales al 100%
        
        # pct < 0 debe tratarse como 0
        result = default_classifier.classify_single(-0.5, 0.8, total_cost=100.0)
        assert result == "INSTALACION"  # MO al 80%

    def test_with_real_config_scenarios(self, config_classifier):
        """Test con escenarios usando configuraci√≥n real."""
        test_cases = [
            (0.70, 0.10, "SUMINISTRO", "Predominio material puro", 100.0),
            (0.65, 0.25, "SUMINISTRO_PREFABRICADO", "Material con MO moderada", 100.0),
            (0.30, 0.65, "INSTALACION", "Predominio MO/equipo", 100.0),
            (0.50, 0.45, "CONSTRUCCION_MIXTO", "Balance 50/50", 100.0),
            (0.55, 0.40, "CONSTRUCCION_MIXTO", "L√≠mite superior mixto", 100.0),
            (0.45, 0.35, "CONSTRUCCION_MIXTO", "Caso intermedio", 100.0),
            (0.00, 0.00, "SIN_COSTO", "Sin costo", 0.0),
            (0.90, 0.05, "SUMINISTRO", "Material muy alto", 100.0),
        ]

        for pct_mat, pct_mo_eq, expected, desc, total_cost in test_cases:
            result = config_classifier.classify_single(pct_mat, pct_mo_eq, total_cost)
            assert result == expected, (
                f"Fallo en '{desc}': esperado {expected}, obtenido {result}"
            )


# =============================================================================
# TESTS: APUClassifier - Clasificaci√≥n DataFrame
# =============================================================================


class TestAPUClassifierDataFrameClassification:
    """Tests para classify_dataframe."""

    def test_adds_output_column(self, default_classifier, sample_dataframe):
        """Debe a√±adir columna de clasificaci√≥n."""
        result = default_classifier.classify_dataframe(sample_dataframe)
        
        assert "TIPO_APU" in result.columns
        assert len(result) == len(sample_dataframe)

    def test_no_null_classifications(self, default_classifier, sample_dataframe):
        """No debe haber clasificaciones nulas."""
        result = default_classifier.classify_dataframe(sample_dataframe)
        
        assert result["TIPO_APU"].isna().sum() == 0

    def test_zero_cost_row_classified(self, default_classifier, sample_dataframe):
        """Filas con costo cero deben ser SIN_COSTO."""
        result = default_classifier.classify_dataframe(sample_dataframe)
        
        zero_cost_mask = sample_dataframe["VALOR_CONSTRUCCION_UN"] == 0
        zero_cost_classifications = result.loc[zero_cost_mask, "TIPO_APU"]
        
        assert all(t == "SIN_COSTO" for t in zero_cost_classifications)

    def test_nan_cost_row_classified(self, default_classifier, sample_dataframe):
        """Filas con costo NaN deben ser SIN_COSTO."""
        result = default_classifier.classify_dataframe(sample_dataframe)
        
        nan_cost_mask = sample_dataframe["VALOR_CONSTRUCCION_UN"].isna()
        nan_classifications = result.loc[nan_cost_mask, "TIPO_APU"]
        
        assert all(t == "SIN_COSTO" for t in nan_classifications)

    def test_custom_column_names(self, default_classifier):
        """Debe funcionar con nombres de columna personalizados."""
        df = pd.DataFrame({
            "total": [100, 200],
            "mat": [60, 40],
            "mo": [40, 60],
        })
        
        result = default_classifier.classify_dataframe(
            df,
            col_total="total",
            col_materiales="mat",
            col_mo_eq="mo",
            output_col="clasificacion",
        )
        
        assert "clasificacion" in result.columns
        assert result["clasificacion"].isna().sum() == 0

    def test_missing_columns_handled(self, default_classifier):
        """Columnas faltantes deben manejarse gracefully."""
        df = pd.DataFrame({
            "VALOR_CONSTRUCCION_UN": [100, 200],
            # Faltan las otras columnas
        })
        
        result = default_classifier.classify_dataframe(df)
        
        assert "TIPO_APU" in result.columns
        # Todas deben ser default por falta de datos
        assert all(t == default_classifier.default_type for t in result["TIPO_APU"])

    def test_does_not_modify_original(self, default_classifier, sample_dataframe):
        """No debe modificar el DataFrame original."""
        original_cols = set(sample_dataframe.columns)
        
        _ = default_classifier.classify_dataframe(sample_dataframe)
        
        assert set(sample_dataframe.columns) == original_cols

    def test_handles_string_numeric_columns(self, default_classifier):
        """Debe manejar columnas num√©ricas como strings."""
        df = pd.DataFrame({
            "VALOR_CONSTRUCCION_UN": ["100", "200", "abc", None],
            "VALOR_SUMINISTRO_UN": ["60", "80", "50", "25"],
            "VALOR_INSTALACION_UN": ["40", "120", "50", "25"],
        })
        
        result = default_classifier.classify_dataframe(df)
        
        assert result["TIPO_APU"].isna().sum() == 0


# =============================================================================
# TESTS: APUClassifier - Vectorizaci√≥n
# =============================================================================


class TestAPUClassifierVectorization:
    """Tests para verificar que la vectorizaci√≥n produce resultados correctos."""

    def test_vectorized_matches_single(self, default_classifier):
        """Clasificaci√≥n vectorizada debe coincidir con individual."""
        test_cases = [
            (100, 70, 30),   # SUMINISTRO
            (100, 30, 70),   # INSTALACION
            (100, 50, 50),   # MIXTO
            (0, 0, 0),       # SIN_COSTO
            (100, 100, 0),   # SUMINISTRO
        ]
        
        df = pd.DataFrame(test_cases, columns=[
            "VALOR_CONSTRUCCION_UN",
            "VALOR_SUMINISTRO_UN", 
            "VALOR_INSTALACION_UN",
        ])
        
        df_result = default_classifier.classify_dataframe(df)
        
        for idx, (total, mat, mo) in enumerate(test_cases):
            pct_mat = mat / total if total > 0 else 0
            pct_mo = mo / total if total > 0 else 0
            
            single_result = default_classifier.classify_single(pct_mat, pct_mo, total)
            vector_result = df_result.iloc[idx]["TIPO_APU"]
            
            assert single_result == vector_result, (
                f"Mismatch en fila {idx}: single={single_result}, vector={vector_result}"
            )

    def test_large_dataframe_performance(self, default_classifier):
        """Debe manejar DataFrames grandes eficientemente."""
        np.random.seed(42)
        n = 10_000
        
        df = pd.DataFrame({
            "VALOR_CONSTRUCCION_UN": np.random.uniform(0, 1000, n),
            "VALOR_SUMINISTRO_UN": np.random.uniform(0, 500, n),
            "VALOR_INSTALACION_UN": np.random.uniform(0, 500, n),
        })
        
        # Esto debe completarse en tiempo razonable (< 5 segundos)
        import time
        start = time.time()
        result = default_classifier.classify_dataframe(df)
        elapsed = time.time() - start
        
        assert len(result) == n
        assert elapsed < 5.0, f"Clasificaci√≥n muy lenta: {elapsed:.2f}s"


# =============================================================================
# TESTS: APUClassifier - Cobertura Topol√≥gica
# =============================================================================


class TestAPUClassifierTopologicalCoverage:
    """Tests para an√°lisis de cobertura del espacio [0,1]¬≤."""

    def test_default_rules_cover_space(self, default_classifier):
        """Reglas por defecto deben cubrir todo el espacio v√°lido."""
        uncovered = default_classifier._sample_uncovered_regions(grid_size=10)
        
        # No debe haber regiones sin cobertura
        assert len(uncovered) == 0, f"Regiones sin cobertura: {uncovered}"

    def test_coverage_report_structure(self, default_classifier):
        """Reporte de cobertura debe tener estructura correcta."""
        report = default_classifier.get_coverage_report()
        
        assert isinstance(report, pd.DataFrame)
        expected_cols = {"tipo", "prioridad", "mat_range", "mo_range", 
                        "area_estimada", "condicion"}
        assert expected_cols.issubset(set(report.columns))
        assert len(report) == len(default_classifier.rules)

    def test_detects_gaps_in_coverage(self, temp_config_path):
        """Debe detectar huecos en la cobertura."""
        # Configuraci√≥n con gap intencional
        config = {
            "apu_classification_rules": {
                "rules": [
                    {
                        "type": "HIGH_MAT",
                        "priority": 1,
                        "condition": "porcentaje_materiales >= 80",
                    },
                    {
                        "type": "HIGH_MO",
                        "priority": 2,
                        "condition": "porcentaje_mo_eq >= 80",
                    },
                    # Gap: no hay regla para (mat < 80) AND (mo < 80)
                ],
            }
        }
        config_path = temp_config_path(config)
        classifier = APUClassifier(config_path)
        
        uncovered = classifier._sample_uncovered_regions(grid_size=10)
        
        # Debe detectar regiones sin cobertura
        assert len(uncovered) > 0


# =============================================================================
# TESTS: APUClassifier - Validaci√≥n de Reglas
# =============================================================================


class TestAPUClassifierRuleValidation:
    """Tests para validaci√≥n de coherencia de reglas."""

    def test_raises_on_no_rules(self, temp_config_path):
        """Debe fallar si no hay reglas definidas."""
        config = {"apu_classification_rules": {"rules": []}}
        config_path = temp_config_path(config)
        
        # Todas las reglas son inv√°lidas, y no quedan defaults
        # Esto deber√≠a usar defaults, verificar comportamiento
        classifier = APUClassifier(config_path)
        
        # Si no hay reglas v√°lidas, debe cargar defaults
        assert len(classifier.rules) > 0

    def test_warns_on_duplicate_types(self, temp_config_path, caplog):
        """Debe advertir sobre tipos duplicados."""
        import logging
        
        config = {
            "apu_classification_rules": {
                "rules": [
                    {"type": "DUPLICATE", "priority": 1, 
                     "condition": "porcentaje_materiales >= 50"},
                    {"type": "DUPLICATE", "priority": 2, 
                     "condition": "porcentaje_mo_eq >= 50"},
                ],
            }
        }
        config_path = temp_config_path(config)
        
        with caplog.at_level(logging.WARNING):
            APUClassifier(config_path)
        
        assert "duplicados" in caplog.text.lower() or "duplicates" in caplog.text.lower()


# =============================================================================
# TESTS: Edge Cases y Robustez
# =============================================================================


class TestAPUClassifierEdgeCases:
    """Tests para casos l√≠mite y robustez."""

    def test_empty_dataframe(self, default_classifier):
        """DataFrame vac√≠o debe manejarse correctamente."""
        df = pd.DataFrame({
            "VALOR_CONSTRUCCION_UN": [],
            "VALOR_SUMINISTRO_UN": [],
            "VALOR_INSTALACION_UN": [],
        })
        
        result = default_classifier.classify_dataframe(df)
        
        assert len(result) == 0
        assert "TIPO_APU" in result.columns

    def test_single_row_dataframe(self, default_classifier):
        """DataFrame de una fila debe funcionar."""
        df = pd.DataFrame({
            "VALOR_CONSTRUCCION_UN": [100],
            "VALOR_SUMINISTRO_UN": [70],
            "VALOR_INSTALACION_UN": [30],
        })
        
        result = default_classifier.classify_dataframe(df)
        
        assert len(result) == 1
        assert result.iloc[0]["TIPO_APU"] == "SUMINISTRO"

    def test_infinity_values(self, default_classifier):
        """Valores infinitos deben manejarse."""
        df = pd.DataFrame({
            "VALOR_CONSTRUCCION_UN": [np.inf, -np.inf, 100],
            "VALOR_SUMINISTRO_UN": [50, 50, 70],
            "VALOR_INSTALACION_UN": [50, 50, 30],
        })
        
        result = default_classifier.classify_dataframe(df)
        
        # No debe crashear
        assert len(result) == 3

    def test_very_small_percentages(self, default_classifier):
        """Porcentajes muy peque√±os deben manejarse."""
        result = default_classifier.classify_single(0.001, 0.001, total_cost=100.0)
        
        # Debe tener alguna clasificaci√≥n v√°lida
        assert result in ["OBRA_COMPLETA", "INDEFINIDO", "CONSTRUCCION_MIXTO"]

    def test_exact_boundary_values(self, default_classifier):
        """Valores exactamente en l√≠mites deben clasificarse consistentemente."""
        # Exactamente 60%
        result_60 = default_classifier.classify_single(0.60, 0.40, total_cost=100.0)
        
        # Justo debajo de 60%
        result_59 = default_classifier.classify_single(0.59, 0.41, total_cost=100.0)
        
        # 60% debe ser SUMINISTRO, 59% debe ser MIXTO o diferente
        assert result_60 == "SUMINISTRO"


# =============================================================================
# TESTS: Compatibilidad con Tests Originales
# =============================================================================


class TestBackwardsCompatibility:
    """Tests que replican la suite original para garantizar compatibilidad."""

    def test_classifier_with_various_scenarios(self):
        """Test del clasificador con m√∫ltiples escenarios (original)."""
        if os.path.exists(CONFIG_PATH):
            classifier = APUClassifier(CONFIG_PATH)
        else:
            pytest.skip(f"Archivo de configuraci√≥n no encontrado: {CONFIG_PATH}")

        test_cases = [
            (0.70, 0.10, "SUMINISTRO", "Predominio material puro", 100.0),
            (0.65, 0.25, "SUMINISTRO_PREFABRICADO", "Material con MO moderada", 100.0),
            (0.30, 0.65, "INSTALACION", "Predominio MO/equipo", 100.0),
            (0.50, 0.45, "CONSTRUCCION_MIXTO", "Balance 50/50", 100.0),
            (0.55, 0.40, "CONSTRUCCION_MIXTO", "L√≠mite superior mixto", 100.0),
            (0.45, 0.35, "CONSTRUCCION_MIXTO", "Caso intermedio (Mixto)", 100.0),
            (0.00, 0.00, "SIN_COSTO", "Sin costo", 0.0),
            (0.90, 0.05, "SUMINISTRO", "Material muy alto, MO baja", 100.0),
        ]

        for pct_mat, pct_mo_eq, expected, desc, total_cost in test_cases:
            result = classifier.classify_single(pct_mat, pct_mo_eq, total_cost=total_cost)
            assert result == expected, (
                f"Fallo en {desc}: esperado {expected}, obtenido {result}"
            )

    def test_dataframe_classification(self):
        """Test de clasificaci√≥n de DataFrame completo (original)."""
        if os.path.exists(CONFIG_PATH):
            classifier = APUClassifier(CONFIG_PATH)
        else:
            classifier = APUClassifier()

        df = pd.DataFrame({
            "VALOR_CONSTRUCCION_UN": [100, 200, 150, 300, 0],
            "VALOR_SUMINISTRO_UN": [70, 120, 45, 180, 0],
            "VALOR_INSTALACION_UN": [30, 80, 105, 120, 0],
        })

        df_classified = classifier.classify_dataframe(df)

        assert "TIPO_APU" in df_classified.columns
        assert df_classified["TIPO_APU"].isna().sum() == 0
        assert df_classified.iloc[4]["TIPO_APU"] == "SIN_COSTO"

    def test_config_loading(self):
        """Test de carga de configuraci√≥n desde JSON (original)."""
        config = {
            "apu_classification_rules": {
                "rules": [
                    {
                        "type": "TEST_TYPE",
                        "priority": 1,
                        "condition": "porcentaje_materiales >= 50.0",
                        "description": "Test rule",
                    }
                ],
                "default_type": "TEST_DEFAULT",
            }
        }

        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".json", delete=False
        ) as f:
            json.dump(config, f)
            config_path = f.name

        try:
            classifier = APUClassifier(config_path)
            assert len(classifier.rules) == 1
            assert classifier.rules[0].rule_type == "TEST_TYPE"
            assert classifier.default_type == "TEST_DEFAULT"
        finally:
            if os.path.exists(config_path):
                os.unlink(config_path)


# =============================================================================
# MAIN
# =============================================================================


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short", "-x"])