Fundamento Algebraico de las Correcciones

La filtraci√≥n declarada VPHYSICS‚äÇVTACTICS‚äÇVSTRATEGY‚äÇVWISDOMVPHYSICS‚Äã‚äÇVTACTICS‚Äã‚äÇVSTRATEGY‚Äã‚äÇVWISDOM‚Äã impone un orden parcial sobre los operadores. Si eiei‚Äã es un operador de estrato SkSk‚Äã y ejej‚Äã de estrato SlSl‚Äã con k<lk<l, entonces ejej‚Äã no puede ejecutarse sin que todos los operadores de SkSk‚Äã en su cono de dependencia hayan completado. Las asignaciones actuales violan esto:

    final_merge ‚àà PHYSICS, pero consume df_apu_costos ‚àà TACTICS ‚Üí violaci√≥n
    materialization ‚àà TACTICS, pero consume business_topology_report ‚àà STRATEGY ‚Üí violaci√≥n

Correcci√≥n: Reasignar conforme al grafo de dependencias real.

### 1. MICRegistry ‚Äî Iteraci√≥n ordenada y consulta por estrato

class MICRegistry:
    """
    Cat√°logo centralizado de pasos del pipeline.
    
    Refinamiento V2.1:
    - Propiedad `dimension` expuesta.
    - Iteraci√≥n ordenada por √≠ndice de registro.
    - Consulta por estrato para validaci√≥n de filtraci√≥n.
    - M√©todo `get_execution_sequence` para recetas por defecto.
    """
    def __init__(self):
        self._basis: Dict[str, BasisVector] = {}
        self._ordered_labels: List[str] = []
        self._dimension = 0
        self.logger = logging.getLogger(self.__class__.__name__)

    @property
    def dimension(self) -> int:
        """Dimensi√≥n del espacio vectorial (n√∫mero de operadores registrados)."""
        return self._dimension

    def add_basis_vector(
        self,
        label: str,
        step_class: Type['ProcessingStep'],
        stratum: Stratum
    ):
        if not label or not isinstance(label, str):
            raise ValueError("Label must be a non-empty string.")
        if label in self._basis:
            raise ValueError(f"Duplicate label: '{label}'. Labels must be unique.")
        if not (isinstance(step_class, type) and issubclass(step_class, ProcessingStep)):
            raise TypeError(f"Class {step_class} must be a subclass of ProcessingStep.")

        vector = BasisVector(
            index=self._dimension,
            label=label,
            operator_class=step_class,
            stratum=stratum
        )
        self._basis[label] = vector
        self._ordered_labels.append(label)
        self._dimension += 1
        self.logger.debug(
            f"Registered e_{vector.index} = '{label}' (stratum: {stratum.name})"
        )

    def get_basis_vector(self, label: str) -> Optional[BasisVector]:
        return self._basis.get(label)

    def get_available_labels(self) -> List[str]:
        """Devuelve las etiquetas en orden de registro (preserva la secuencia de la base)."""
        return list(self._ordered_labels)

    def get_vectors_by_stratum(self, stratum: Stratum) -> List[BasisVector]:
        """Proyecci√≥n sobre un subestrato: devuelve todos los vectores de un estrato dado."""
        return [
            self._basis[label]
            for label in self._ordered_labels
            if self._basis[label].stratum == stratum
        ]

    def get_execution_sequence(self) -> List[Dict[str, Any]]:
        """Genera la receta de ejecuci√≥n por defecto respetando el orden de registro."""
        return [
            {"step": label, "enabled": True}
            for label in self._ordered_labels
        ]

    def __iter__(self):
        """Iteraci√≥n sobre vectores base en orden de registro."""
        for label in self._ordered_labels:
            yield self._basis[label]

    def __len__(self) -> int:
        return self._dimension

Cambios: Se a√±ade _ordered_labels para preservar el orden de inserci√≥n (el dict lo preserva en Python 3.7+, pero hacerlo expl√≠cito es m√°s seguro sem√°nticamente). Se exponen dimension, iteraci√≥n, consulta por estrato y generaci√≥n de receta por defecto.

### 2. PipelineSteps y _initialize_vector_space_refined ‚Äî Consistencia de orden y estratos

# ==================== MAPA DE ESTRATOS ====================

_STRATUM_ORDER: Dict[Stratum, int] = {
    Stratum.PHYSICS: 0,
    Stratum.TACTICS: 1,
    Stratum.STRATEGY: 2,
    Stratum.WISDOM: 3,
}


def stratum_level(s: Stratum) -> int:
    """Retorna el nivel ordinal de un estrato en la filtraci√≥n DIKW."""
    return _STRATUM_ORDER.get(s, -1)


class PipelineSteps(enum.Enum):
    """
    Receta can√≥nica del pipeline. El orden del enum define el orden de ejecuci√≥n.
    
    Grafo de dependencias (‚Üí = "produce para"):
      LOAD_DATA ‚Üí AUDITED_MERGE ‚Üí CALCULATE_COSTS ‚Üí FINAL_MERGE
                                                        ‚Üì
                                              BUSINESS_TOPOLOGY ‚Üí MATERIALIZATION
                                                                       ‚Üì
                                                                  BUILD_OUTPUT
    """
    LOAD_DATA = "load_data"
    AUDITED_MERGE = "audited_merge"
    CALCULATE_COSTS = "calculate_costs"
    FINAL_MERGE = "final_merge"
    BUSINESS_TOPOLOGY = "business_topology"
    MATERIALIZATION = "materialization"
    BUILD_OUTPUT = "build_output"

def _initialize_vector_space_refined(self):
    """
    Inicializa la MIC con los pasos del pipeline.
    
    Refinamiento: El orden de registro es ID√âNTICO al orden del enum PipelineSteps.
    Los estratos respetan la filtraci√≥n V_P ‚äÇ V_T ‚äÇ V_S ‚äÇ V_W conforme al
    grafo de dependencias real:
    
      - PHYSICS  : Carga y fusi√≥n de datos crudos (load_data, audited_merge)
      - TACTICS  : C√°lculos y consolidaci√≥n (calculate_costs, final_merge)
      - STRATEGY : An√°lisis topol√≥gico y materializaci√≥n (business_topology, materialization)
      - WISDOM   : S√≠ntesis final (build_output)
    """
    steps_definition: List[Tuple[str, Type[ProcessingStep], Stratum]] = [
        ("load_data",          LoadDataStep,          Stratum.PHYSICS),
        ("audited_merge",      AuditedMergeStep,      Stratum.PHYSICS),
        ("calculate_costs",    CalculateCostsStep,     Stratum.TACTICS),
        ("final_merge",        FinalMergeStep,         Stratum.TACTICS),     # ‚Üê era PHYSICS
        ("business_topology",  BusinessTopologyStep,   Stratum.STRATEGY),
        ("materialization",    MaterializationStep,    Stratum.STRATEGY),    # ‚Üê era TACTICS
        ("build_output",       BuildOutputStep,        Stratum.WISDOM),
    ]

    for label, step_class, stratum in steps_definition:
        self.mic.add_basis_vector(label, step_class, stratum)

Cambios:

    final_merge: PHYSICS ‚Üí TACTICS (consume df_apu_costos, df_tiempo que son productos t√°cticos).
    materialization: TACTICS ‚Üí STRATEGY (depende de business_topology_report).
    El orden de registro ahora coincide exactamente con PipelineSteps.


### 3. _infer_current_stratum_from_context ‚Äî Orden de evaluaci√≥n corregido

def _infer_current_stratum_from_context(self, context: dict) -> Optional[Stratum]:
    """
    Heur√≠stica para inferir el estrato M√ÅS ALTO alcanzado en el contexto.
    
    Refinamiento: Se eval√∫a de WISDOM ‚Üí PHYSICS (descendente).
    La primera coincidencia indica el m√°ximo estrato completado.
    El orden anterior (PHYSICS primero) siempre retornaba PHYSICS
    una vez cargados los datos iniciales, invalidando toda validaci√≥n posterior.
    
    Invariante: Si el contexto contiene artefactos del estrato S_k,
    debe contener tambi√©n artefactos de todos los estratos S_j con j < k.
    """
    keys = set(context.keys())

    # Evaluar de mayor a menor: el primer match indica el techo alcanzado
    stratum_signatures: List[Tuple[Stratum, set]] = [
        (Stratum.WISDOM,   {"final_result"}),
        (Stratum.STRATEGY, {"graph", "business_topology_report", "bill_of_materials"}),
        (Stratum.TACTICS,  {"df_apu_costos", "df_tiempo", "df_rendimiento", "df_final"}),
        (Stratum.PHYSICS,  {"df_presupuesto", "df_insumos", "df_apus_raw", "df_merged"}),
    ]

    for stratum, signature_keys in stratum_signatures:
        if keys & signature_keys:  # Intersecci√≥n no vac√≠a
            return stratum

    return None

Cambio: Inversi√≥n del orden de evaluaci√≥n. Antes, la presencia de df_presupuesto (siempre presente tras el paso 1) hac√≠a que el m√©todo retornara PHYSICS en todos los pasos subsiguientes, inutilizando la validaci√≥n de regresi√≥n de estrato.


### 4. run_single_step ‚Äî Validaci√≥n de estrato robusta

def run_single_step(
    self,
    step_name: str,
    session_id: str,
    initial_context: Optional[Dict[str, Any]] = None,
    validate_stratum: bool = True
) -> Dict[str, Any]:
    """
    Ejecuta un √∫nico paso del pipeline con validaci√≥n de filtraci√≥n.
    
    Refinamiento:
    - Usa `stratum_level()` en vez de asumir atributo `.level` en el Enum.
    - Valida que el paso no intente operar en un estrato inferior al ya alcanzado
      (regresi√≥n), lo cual violar√≠a la filtraci√≥n.
    - Propaga `initial_context` al contexto cargado de sesi√≥n con precedencia expl√≠cita.
    """
    self.logger.info(f"Executing step: {step_name} (Session: {session_id[:8]}...)")

    # 1. Cargar contexto de sesi√≥n
    context = self._load_context_state(session_id)

    # 2. Fusionar initial_context (las claves de sesi√≥n tienen precedencia
    #    sobre initial_context para evitar regresi√≥n de estado)
    if initial_context:
        # initial_context provee valores base; el estado guardado prevalece
        merged = {**initial_context, **context}
        context = merged

    try:
        # 3. Resolver vector base
        basis_vector = self.mic.get_basis_vector(step_name)
        if not basis_vector:
            available = self.mic.get_available_labels()
            raise ValueError(
                f"Step '{step_name}' not found. Available: {available}"
            )

        # 4. Validar filtraci√≥n de estratos
        if validate_stratum:
            current_stratum = self._infer_current_stratum_from_context(context)
            target_stratum = basis_vector.stratum

            if current_stratum is not None:
                current_level = stratum_level(current_stratum)
                target_level = stratum_level(target_stratum)

                if target_level < current_level:
                    self.logger.warning(
                        f"‚ö†Ô∏è Stratum regression detected: context at "
                        f"{current_stratum.name} (level {current_level}), "
                        f"but step '{step_name}' targets "
                        f"{target_stratum.name} (level {target_level}). "
                        f"This may indicate a pipeline ordering defect."
                    )

        # 5. Instanciar y ejecutar
        step_instance = basis_vector.operator_class(self.config, self.thresholds)
        updated_context = step_instance.execute(context, self.telemetry)

        if updated_context is None:
            raise ValueError(
                f"Step '{step_name}' returned None context. "
                f"All steps must return the (possibly modified) context dict."
            )

        # 6. Persistir estado actualizado
        self._save_context_state(session_id, updated_context)

        self.logger.info(f"Step '{step_name}' completed successfully.")
        return {
            "status": "success",
            "step": step_name,
            "stratum": basis_vector.stratum.name,
            "session_id": session_id,
            "context_keys": list(updated_context.keys()),
        }

    except Exception as e:
        self.logger.error(f"Error executing step '{step_name}': {e}", exc_info=True)
        self.telemetry.record_error(step_name, str(e))
        return {
            "status": "error",
            "step": step_name,
            "error": str(e),
            "session_id": session_id,
        }

Cambios:

    Reemplaza hasattr(stratum, 'level') por la funci√≥n auxiliar stratum_level() que opera sobre el mapa expl√≠cito _STRATUM_ORDER.
    Fusi√≥n de initial_context con precedencia de sesi√≥n (evita regresi√≥n accidental).
    Mensaje de error incluye los labels disponibles.


### 5. execute_pipeline_orchestrated ‚Äî Robustez en flujo y limpieza

def execute_pipeline_orchestrated(self, initial_context: dict) -> dict:
    """
    Ejecuta el pipeline completo de forma orquestada.
    
    Refinamiento:
    - Verifica que el guardado inicial de contexto fue exitoso antes de continuar.
    - Usa la receta generada por la MIC como fallback en vez de reconstruirla.
    - Pasa initial_context al primer paso como respaldo defensivo.
    - Limpia archivos de sesi√≥n al finalizar exitosamente.
    """
    session_id = str(uuid.uuid4())
    self.logger.info(f"Starting orchestrated pipeline (Session ID: {session_id})")

    # Obtener receta de ejecuci√≥n
    default_recipe = self.mic.get_execution_sequence()
    recipe = self.config.get("pipeline_recipe", default_recipe)

    # Guardado inicial del contexto ‚Äî verificar que no falle silenciosamente
    self._save_context_state(session_id, initial_context)
    verification = self._load_context_state(session_id)
    if not verification:
        raise IOError(
            f"Failed to persist initial context for session {session_id}. "
            f"Check disk permissions on {self.session_dir}."
        )

    first_step = True
    for step_idx, step_config in enumerate(recipe):
        step_name = step_config.get("step")
        enabled = step_config.get("enabled", True)

        if not step_name:
            self.logger.warning(f"Recipe entry {step_idx} has no 'step' key. Skipping.")
            continue

        if not enabled:
            self.logger.info(f"‚è≠Ô∏è Skipping disabled step: {step_name}")
            continue

        self.logger.info(
            f"Orchestrating step [{step_idx + 1}/{len(recipe)}]: {step_name}"
        )

        # En el primer paso, pasar initial_context como respaldo defensivo
        ctx_override = initial_context if first_step else None
        result = self.run_single_step(
            step_name, session_id, initial_context=ctx_override
        )
        first_step = False

        if result["status"] == "error":
            error_msg = (
                f"Pipeline failed at step '{step_name}' "
                f"[{step_idx + 1}/{len(recipe)}]: {result.get('error')}"
            )
            self.logger.critical(error_msg)
            # No limpiar sesi√≥n en error para permitir an√°lisis forense
            raise RuntimeError(error_msg)

    final_context = self._load_context_state(session_id)

    # Limpieza de archivo de sesi√≥n tras √©xito
    self._cleanup_session(session_id)

    self.logger.info(f"Pipeline completed successfully (Session: {session_id})")
    return final_context


def _cleanup_session(self, session_id: str):
    """Elimina el archivo de sesi√≥n tras finalizaci√≥n exitosa."""
    try:
        session_file = self.session_dir / f"{session_id}.pkl"
        if session_file.exists():
            session_file.unlink()
            self.logger.debug(f"Session file cleaned: {session_id}")
    except OSError as e:
        self.logger.warning(f"Could not clean session file {session_id}: {e}")


Cambios:

    Verificaci√≥n round-trip del guardado inicial (detecta fallos de I/O silenciosos).
    Usa mic.get_execution_sequence() como receta por defecto.
    Pasa initial_context al primer paso como defensa en profundidad.
    A√±ade _cleanup_session para evitar acumulaci√≥n de archivos .pkl.
    Preserva archivos de sesi√≥n en error para an√°lisis forense.


### 6. _load_context_state / _save_context_state ‚Äî Integridad

def _load_context_state(self, session_id: str) -> dict:
    """
    Carga el estado de una sesi√≥n con validaci√≥n de tipo.
    
    Refinamiento: Valida que el objeto deserializado sea un dict.
    Pickle puede retornar cualquier tipo; sin validaci√≥n, un archivo corrupto
    puede inyectar un objeto arbitrario que se propaga como contexto.
    """
    if not session_id:
        return {}
    try:
        session_file = self.session_dir / f"{session_id}.pkl"
        if session_file.exists():
            with open(session_file, "rb") as f:
                data = pickle.load(f)
            if not isinstance(data, dict):
                self.logger.error(
                    f"Corrupted session {session_id}: expected dict, got {type(data).__name__}"
                )
                return {}
            return data
    except (pickle.UnpicklingError, EOFError, ModuleNotFoundError) as e:
        self.logger.error(f"Failed to deserialize session {session_id}: {e}")
    except Exception as e:
        self.logger.error(f"Failed to load context for session {session_id}: {e}")
    return {}


def _save_context_state(self, session_id: str, context: dict):
    """
    Guarda el estado de una sesi√≥n con escritura at√≥mica.
    
    Refinamiento: Escribe a archivo temporal y renombra (operaci√≥n at√≥mica en POSIX)
    para evitar estados parciales si el proceso se interrumpe durante la escritura.
    """
    try:
        session_file = self.session_dir / f"{session_id}.pkl"
        tmp_file = session_file.with_suffix(".pkl.tmp")
        with open(tmp_file, "wb") as f:
            pickle.dump(context, f, protocol=pickle.HIGHEST_PROTOCOL)
        tmp_file.replace(session_file)  # At√≥mica en POSIX
        self.logger.debug(f"Context saved for session {session_id}")
    except Exception as e:
        self.logger.error(f"Failed to save context for session {session_id}: {e}")
        # Limpiar archivo temporal si qued√≥
        try:
            if tmp_file.exists():
                tmp_file.unlink()
        except Exception:
            pass


Cambios:

    Validaci√≥n de tipo post-deserializaci√≥n.
    Captura de errores espec√≠ficos de pickle.
    Escritura at√≥mica via archivo temporal + rename.


### 7. AuditedMergeStep.execute ‚Äî Null Safety

class AuditedMergeStep(ProcessingStep):
    """
    Paso de Fusi√≥n con Auditor√≠a Topol√≥gica (Mayer-Vietoris).
    
    Refinamiento: Validaci√≥n de precondiciones antes de operar.
    """
    def __init__(self, config: dict, thresholds: ProcessingThresholds):
        self.config = config
        self.thresholds = thresholds

    def execute(self, context: dict, telemetry: TelemetryContext) -> dict:
        telemetry.start_step("audited_merge")
        try:
            df_a = context.get("df_presupuesto")
            df_b = context.get("df_apus_raw")
            df_insumos = context.get("df_insumos")

            # ‚îÄ‚îÄ Precondici√≥n: las fuentes de la fusi√≥n NO pueden ser None ‚îÄ‚îÄ
            if df_b is None:
                error = "df_apus_raw is None: cannot proceed with merge."
                telemetry.record_error("audited_merge", error)
                raise ValueError(error)
            if df_insumos is None:
                error = "df_insumos is None: cannot proceed with merge."
                telemetry.record_error("audited_merge", error)
                raise ValueError(error)

            # ‚îÄ‚îÄ Auditor√≠a topol√≥gica (no bloquea la fusi√≥n si falla) ‚îÄ‚îÄ
            if df_a is not None:
                try:
                    builder = BudgetGraphBuilder()
                    graph_a = builder.build(df_a, pd.DataFrame())
                    graph_b = builder.build(pd.DataFrame(), df_b)

                    analyzer = BusinessTopologicalAnalyzer(telemetry=telemetry)
                    audit_result = analyzer.audit_integration_homology(
                        graph_a, graph_b
                    )

                    delta_beta_1 = audit_result.get("delta_beta_1", 0)
                    if delta_beta_1 > 0:
                        logger.warning(
                            f"üö® Mayer-Vietoris: {delta_beta_1} emergent cycle(s) detected. "
                            f"Narrative: {audit_result.get('narrative', 'N/A')}"
                        )
                        telemetry.record_metric(
                            "topology", "emergent_cycles", delta_beta_1
                        )
                        context["integration_risk_alert"] = audit_result
                    else:
                        logger.info("‚úÖ Auditor√≠a Mayer-Vietoris: homolog√≠a preservada.")
                except Exception as e_audit:
                    logger.error(
                        f"‚ùå Auditor√≠a Mayer-Vietoris fall√≥ (no bloquea fusi√≥n): {e_audit}"
                    )
                    telemetry.record_error("audited_merge_audit", str(e_audit))
            else:
                logger.info(
                    "‚ÑπÔ∏è df_presupuesto no disponible; auditor√≠a Mayer-Vietoris omitida."
                )

            # ‚îÄ‚îÄ Fusi√≥n f√≠sica ‚îÄ‚îÄ
            logger.info("üõ†Ô∏è Ejecutando fusi√≥n f√≠sica de datos...")
            merger = DataMerger(self.thresholds)
            df_merged = merger.merge_apus_with_insumos(df_b, df_insumos)

            if df_merged is None or df_merged.empty:
                error = "Merge produced empty DataFrame"
                telemetry.record_error("audited_merge", error)
                raise ValueError(error)

            telemetry.record_metric("audited_merge", "merged_rows", len(df_merged))
            context["df_merged"] = df_merged

            telemetry.end_step("audited_merge", "success")
            return context

        except Exception as e:
            telemetry.record_error("audited_merge", str(e))
            telemetry.end_step("audited_merge", "error")
            raise

Cambios:

    Validaci√≥n expl√≠cita de df_b y df_insumos antes de usarlos.
    Validaci√≥n del resultado de la fusi√≥n.
    Log informativo cuando df_a es None (en vez de silencio).


### 8. CalculateCostsStep.execute ‚Äî Eliminaci√≥n de actualizaci√≥n redundante

class CalculateCostsStep(ProcessingStep):
    """Paso de C√°lculo de Costos."""
    def __init__(self, config: dict, thresholds: ProcessingThresholds):
        self.config = config
        self.thresholds = thresholds

    def execute(self, context: dict, telemetry: TelemetryContext) -> dict:
        telemetry.start_step("calculate_costs")
        try:
            df_merged = context.get("df_merged")
            if df_merged is None or df_merged.empty:
                error = "df_merged is missing or empty: cannot calculate costs."
                telemetry.record_error("calculate_costs", error)
                raise ValueError(error)

            processor = APUProcessor(self.config)
            df_apu_costos, df_tiempo, df_rendimiento = processor.process_vectors(
                df_merged
            )

            telemetry.record_metric(
                "calculate_costs", "costos_rows", len(df_apu_costos)
            )
            telemetry.record_metric(
                "calculate_costs", "tiempo_rows", len(df_tiempo)
            )

            # Solo agregar las claves nuevas; df_merged ya est√° en el contexto
            context["df_apu_costos"] = df_apu_costos
            context["df_tiempo"] = df_tiempo
            context["df_rendimiento"] = df_rendimiento

            telemetry.end_step("calculate_costs", "success")
            return context

        except Exception as e:
            telemetry.record_error("calculate_costs", str(e))
            telemetry.end_step("calculate_costs", "error")
            raise

Cambios:

    Elimina "df_merged": df_merged del context.update() (ya estaba en contexto, nunca se modifica).
    A√±ade validaci√≥n de precondici√≥n para df_merged.
    Registra m√©tricas de df_tiempo adem√°s de costos.


### 9. BusinessTopologyStep.execute ‚Äî Flujo limpio y desacoplamiento

class BusinessTopologyStep(ProcessingStep):
    """
    Paso de An√°lisis de Negocio.
    
    Refinamiento:
    - Separaci√≥n clara entre fase de materializaci√≥n del grafo y fase de evaluaci√≥n.
    - Propagaci√≥n de errores consistente: fallos en la construcci√≥n del grafo
      son fatales; fallos en la evaluaci√≥n del agente son warnings.
    - Eliminaci√≥n de la dependencia directa a `current_app.mic` dentro del paso.
    """
    def __init__(self, config: dict, thresholds: ProcessingThresholds):
        self.config = config
        self.thresholds = thresholds

    def _resolve_mic_instance(self):
        """
        Intenta resolver la instancia global de MIC para el BusinessAgent.
        Aislado en m√©todo separado para facilitar testing e inyecci√≥n.
        """
        try:
            return getattr(current_app, "mic", None)
        except RuntimeError:
            # Fuera de contexto Flask (ej. testing, batch mode)
            logger.warning(
                "‚ö†Ô∏è No Flask app context. BusinessAgent financial analysis unavailable."
            )
            return None

    def execute(self, context: dict, telemetry: TelemetryContext) -> dict:
        telemetry.start_step("business_topology")
        try:
            df_final = context.get("df_final")
            df_merged = context.get("df_merged")

            if df_final is None:
                error = "df_final is required for BusinessTopologyStep."
                telemetry.record_error("business_topology", error)
                raise ValueError(error)

            # ‚îÄ‚îÄ Fase 1: Materializaci√≥n del grafo topol√≥gico ‚îÄ‚îÄ
            builder = BudgetGraphBuilder()
            graph = builder.build(df_final, df_merged if df_merged is not None else pd.DataFrame())
            context["graph"] = graph
            logger.info(
                f"üï∏Ô∏è Grafo de negocio materializado: "
                f"{graph.number_of_nodes()} nodos, {graph.number_of_edges()} aristas"
            )
            telemetry.record_metric("business_topology", "graph_nodes", graph.number_of_nodes())
            telemetry.record_metric("business_topology", "graph_edges", graph.number_of_edges())

            # ‚îÄ‚îÄ Fase 2: Registro de estratos validados ‚îÄ‚îÄ
            validated = context.get("validated_strata")
            if not isinstance(validated, set):
                validated = set()
            validated.update({Stratum.PHYSICS, Stratum.TACTICS})
            context["validated_strata"] = validated

            # ‚îÄ‚îÄ Fase 3: Evaluaci√≥n por BusinessAgent (degradable) ‚îÄ‚îÄ
            mic_instance = self._resolve_mic_instance()
            if mic_instance:
                try:
                    agent = BusinessAgent(
                        config=self.config,
                        mic=mic_instance,
                        telemetry=telemetry,
                    )
                    report = agent.evaluate_project(context)
                    if report:
                        context["business_topology_report"] = report
                        logger.info("‚úÖ BusinessAgent complet√≥ la evaluaci√≥n.")
                    else:
                        logger.warning("‚ö†Ô∏è BusinessAgent retorn√≥ reporte vac√≠o.")
                except Exception as ba_error:
                    logger.warning(
                        f"‚ö†Ô∏è BusinessAgent evaluation degraded: {ba_error}",
                        exc_info=True,
                    )
                    telemetry.record_error("business_agent", str(ba_error))
            else:
                logger.warning(
                    "‚ö†Ô∏è Sin instancia MIC global. "
                    "Evaluaci√≥n de negocio limitada a grafo topol√≥gico."
                )

            telemetry.end_step("business_topology", "success")
            return context

        except Exception as e:
            logger.error(f"‚ùå Error en BusinessTopologyStep: {e}", exc_info=True)
            telemetry.record_error("business_topology", str(e))
            telemetry.end_step("business_topology", "error")
            raise  # ‚Üê Ahora propaga en vez de retornar contexto incompleto

Cambios:

    df_final is None ahora es un error fatal (precondici√≥n).
    Resoluci√≥n de MIC aislada en _resolve_mic_instance().
    RuntimeError de Flask capturado (batch mode sin app context).
    Error fatal (raise) en vez de return context silencioso.
    M√©tricas del grafo registradas.


### 10. MaterializationStep.execute ‚Äî Manejo de errores consistente

class MaterializationStep(ProcessingStep):
    """
    Paso de Materializaci√≥n (BOM).
    
    Refinamiento:
    - Distingue entre "precondici√≥n no cumplida" (skip leg√≠timo) y
      "error durante ejecuci√≥n" (fallo).
    - Los skips leg√≠timos NO lanzan excepci√≥n pero registran telemetr√≠a.
    - Los errores de ejecuci√≥n S√ç propagan la excepci√≥n.
    """
    def __init__(self, config: dict, thresholds: ProcessingThresholds):
        self.config = config
        self.thresholds = thresholds

    def execute(self, context: dict, telemetry: TelemetryContext) -> dict:
        telemetry.start_step("materialization")

        # ‚îÄ‚îÄ Precondici√≥n: reporte topol√≥gico requerido ‚îÄ‚îÄ
        if "business_topology_report" not in context:
            logger.warning(
                "‚ö†Ô∏è business_topology_report ausente. "
                "Materializaci√≥n omitida (degradaci√≥n controlada)."
            )
            telemetry.record_metric("materialization", "skipped", True)
            telemetry.end_step("materialization", "skipped")
            return context

        try:
            # ‚îÄ‚îÄ Resolver o construir el grafo ‚îÄ‚îÄ
            graph = context.get("graph")
            if not graph:
                builder = BudgetGraphBuilder()
                df_final = context.get("df_final")
                df_merged = context.get("df_merged")

                if df_final is None:
                    error = "Cannot materialize: df_final missing and no prebuilt graph."
                    telemetry.record_error("materialization", error)
                    raise ValueError(error)

                graph = builder.build(
                    df_final,
                    df_merged if df_merged is not None else pd.DataFrame(),
                )
                context["graph"] = graph
                logger.info("üï∏Ô∏è Grafo reconstruido para materializaci√≥n.")

            # ‚îÄ‚îÄ Extraer m√©tricas de estabilidad ‚îÄ‚îÄ
            report = context["business_topology_report"]
            stability = 10.0
            if hasattr(report, "details") and isinstance(report.details, dict):
                stability = report.details.get("pyramid_stability", 10.0)

            flux_metrics = {
                "pyramid_stability": stability,
                "avg_saturation": 0.0,
            }

            # ‚îÄ‚îÄ Generar BOM ‚îÄ‚îÄ
            generator = MatterGenerator()
            bom = generator.materialize_project(
                graph, flux_metrics=flux_metrics, telemetry=telemetry
            )

            context["bill_of_materials"] = bom
            context["logistics_plan"] = asdict(bom)

            telemetry.record_metric(
                "materialization", "total_items", len(bom.requirements)
            )
            logger.info(
                f"‚úÖ Materializaci√≥n completada. Total √≠tems: {len(bom.requirements)}"
            )
            telemetry.end_step("materialization", "success")
            return context

        except Exception as e:
            logger.error(f"‚ùå Error en MaterializationStep: {e}", exc_info=True)
            telemetry.record_error("materialization", str(e))
            telemetry.end_step("materialization", "error")
            raise  # ‚Üê Ahora propaga

Cambios:

    Skip leg√≠timo (sin reporte) no lanza excepci√≥n.
    Error de ejecuci√≥n ahora propaga (raise) en vez de return context.
    Protecci√≥n contra df_merged None en reconstrucci√≥n del grafo.


### 11. BuildOutputStep.execute ‚Äî Checksum robusto

class BuildOutputStep(ProcessingStep):
    """
    Paso de Construcci√≥n de Salida.
    
    Refinamiento:
    - Checksum de linaje cubre el payload completo (no solo presupuesto).
    - Generaci√≥n del hash es resistente a fallos de serializaci√≥n parcial.
    """
    def __init__(self, config: dict, thresholds: ProcessingThresholds):
        self.config = config
        self.thresholds = thresholds

    def _compute_lineage_hash(self, payload: dict) -> str:
        """
        Calcula un hash SHA-256 sobre el payload completo.
        
        Refinamiento: Itera sobre TODAS las claves serializables del payload,
        no solo 'presupuesto'. Claves no serializables se representan por su
        tipo y longitud.
        """
        import json

        hash_input_parts = []
        for key in sorted(payload.keys()):
            value = payload[key]
            try:
                sanitized = sanitize_for_json(value) if isinstance(value, (list, dict)) else value
                part = json.dumps(
                    {key: sanitized}, sort_keys=True, default=str
                )
            except (TypeError, ValueError):
                # Fallback para objetos no serializables
                part = f"{key}:type={type(value).__name__},len={len(value) if hasattr(value, '__len__') else 'N/A'}"
            hash_input_parts.append(part)

        composite = "|".join(hash_input_parts)
        return hashlib.sha256(composite.encode("utf-8")).hexdigest()

    def execute(self, context: dict, telemetry: TelemetryContext) -> dict:
        telemetry.start_step("build_output")
        try:
            # ‚îÄ‚îÄ Extraer artefactos requeridos ‚îÄ‚îÄ
            required_keys = [
                "df_final", "df_insumos", "df_merged",
                "df_apus_raw", "df_apu_costos", "df_tiempo", "df_rendimiento",
            ]
            missing = [k for k in required_keys if k not in context]
            if missing:
                error = f"BuildOutputStep missing required context keys: {missing}"
                telemetry.record_error("build_output", error)
                raise ValueError(error)

            df_final = context["df_final"]
            df_insumos = context["df_insumos"]
            df_merged = context["df_merged"]
            df_apus_raw = context["df_apus_raw"]
            df_apu_costos = context["df_apu_costos"]
            df_tiempo = context["df_tiempo"]
            df_rendimiento = context["df_rendimiento"]

            # ‚îÄ‚îÄ Sincronizaci√≥n ‚îÄ‚îÄ
            df_merged = synchronize_data_sources(df_merged, df_final)
            df_processed_apus = build_processed_apus_dataframe(
                df_apu_costos, df_apus_raw, df_tiempo, df_rendimiento
            )

            # ‚îÄ‚îÄ Ensamblaje del producto de datos ‚îÄ‚îÄ
            has_strategy_artifacts = (
                "graph" in context and "business_topology_report" in context
            )

            if has_strategy_artifacts:
                graph = context["graph"]
                report = context["business_topology_report"]
                translator = SemanticTranslator()
                result_dict = translator.assemble_data_product(graph, report)
                result_dict["presupuesto"] = df_final.to_dict("records")
                result_dict["insumos"] = df_insumos.to_dict("records")
                logger.info("ü¶â WISDOM: Producto de datos ensamblado por SemanticTranslator")
            else:
                logger.warning(
                    "‚ö†Ô∏è Sin artefactos de Estrategia. Generando salida b√°sica."
                )
                result_dict = build_output_dictionary(
                    df_final, df_insumos, df_merged, df_apus_raw, df_processed_apus
                )

            # ‚îÄ‚îÄ Validaci√≥n y enriquecimiento ‚îÄ‚îÄ
            validated_result = validate_and_clean_data(
                result_dict, telemetry_context=telemetry
            )
            validated_result["raw_insumos_df"] = df_insumos.to_dict("records")

            if "business_topology_report" in context:
                validated_result["audit_report"] = asdict(
                    context["business_topology_report"]
                )

            if "logistics_plan" in context:
                validated_result["logistics_plan"] = context["logistics_plan"]

            # ‚îÄ‚îÄ Narrativa t√©cnica ‚îÄ‚îÄ
            try:
                narrator = TelemetryNarrator()
                tech_narrative = narrator.summarize_execution(telemetry)
                validated_result["technical_audit"] = tech_narrative
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Narrativa t√©cnica degradada: {e}")
                validated_result["technical_audit"] = {
                    "status": "degraded",
                    "error": str(e),
                }

            # ‚îÄ‚îÄ Hash de linaje ‚îÄ‚îÄ
            lineage_hash = self._compute_lineage_hash(validated_result)

            data_product = {
                "kind": "DataProduct",
                "metadata": {
                    "version": "3.0",
                    "lineage_hash": lineage_hash,
                    "generated_at": datetime.datetime.now(
                        datetime.timezone.utc
                    ).isoformat(),
                    "generator": "APU_Filter_Pipeline_v2.1",
                    "strata_validated": [
                        s.name
                        for s in context.get("validated_strata", set())
                        if isinstance(s, Stratum)
                    ],
                },
                "payload": validated_result,
            }

            context["final_result"] = data_product
            telemetry.end_step("build_output", "success")
            return context

        except Exception as e:
            telemetry.record_error("build_output", str(e))
            telemetry.end_step("build_output", "error")
            raise

Cambios:

    Checksum ahora cubre todo el payload via _compute_lineage_hash().
    Validaci√≥n de claves requeridas antes de extracci√≥n.
    Timestamp con timezone UTC (datetime.timezone.utc).
    Metadata incluye strata_validated.
    Variable booleana expl√≠cita has_strategy_artifacts en vez de condici√≥n anidada.


### 12. process_all_files ‚Äî Telemetr√≠a null-safe

def process_all_files(
    presupuesto_path: Union[str, Path],
    apus_path: Union[str, Path],
    insumos_path: Union[str, Path],
    config: dict = None,
    telemetry: TelemetryContext = None,
) -> dict:
    """
    Funci√≥n de entrada principal para el pipeline (Batch Mode).
    
    Refinamiento:
    - Crea TelemetryContext por defecto si no se provee.
    - Valida existencia de archivos antes de instanciar el pipeline.
    - Retorna el DataProduct directamente (no el contexto completo).
    """
    if config is None:
        config = {}

    # Garantizar telemetr√≠a (evita AttributeError en todos los pasos)
    if telemetry is None:
        telemetry = TelemetryContext()
        logger.info("‚ÑπÔ∏è No telemetry context provided; created default instance.")

    # Resolver y validar rutas
    paths = {
        "presupuesto_path": Path(presupuesto_path).resolve(),
        "apus_path": Path(apus_path).resolve(),
        "insumos_path": Path(insumos_path).resolve(),
    }

    for name, path in paths.items():
        if not path.exists():
            error = f"File not found: {name} = {path}"
            telemetry.record_error("process_all_files", error)
            raise FileNotFoundError(error)

    director = PipelineDirector(config, telemetry)

    initial_context = {k: str(v) for k, v in paths.items()}

    try:
        final_context = director.execute_pipeline_orchestrated(initial_context)

        # Retornar el DataProduct si existe; sino, el contexto completo
        return final_context.get("final_result", final_context)

    except Exception as e:
        logger.critical(f"üî• Critical failure in process_all_files: {e}", exc_info=True)
        telemetry.record_error("process_all_files", str(e))
        raise

Cambios:

    Crea TelemetryContext() por defecto ‚Üí elimina el AttributeError cuando telemetry=None.
    Validaci√≥n de existencia de archivos antes de construir el pipeline.
    Retorna final_result directamente (el DataProduct), con fallback al contexto completo.


### 13. _load_thresholds ‚Äî Validaci√≥n de tipos

def _load_thresholds(self, config: dict) -> ProcessingThresholds:
    """
    Carga umbrales desde configuraci√≥n con validaci√≥n de tipo.
    
    Refinamiento: Solo aplica valores cuyo tipo coincida con el default
    del atributo correspondiente.
    """
    thresholds = ProcessingThresholds()
    overrides = config.get("processing_thresholds", {})

    if not isinstance(overrides, dict):
        self.logger.warning(
            f"processing_thresholds is not a dict (got {type(overrides).__name__}). "
            f"Using defaults."
        )
        return thresholds

    for key, value in overrides.items():
        if not hasattr(thresholds, key):
            self.logger.warning(f"Unknown threshold key '{key}'. Ignored.")
            continue

        current_value = getattr(thresholds, key)
        if current_value is not None and not isinstance(value, type(current_value)):
            self.logger.warning(
                f"Threshold '{key}': expected {type(current_value).__name__}, "
                f"got {type(value).__name__}. Ignored."
            )
            continue

        setattr(thresholds, key, value)

    return thresholds

Cambio: Validaci√≥n de tipo antes de setattr para evitar inyecci√≥n de tipos incorrectos.