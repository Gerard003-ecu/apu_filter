import logging
from typing import Dict, List, Optional, Tuple, Union

import numpy as np
import pandas as pd
from flask import current_app
from sentence_transformers import SentenceTransformer

from .utils import normalize_text

logger = logging.getLogger(__name__)


def _calculate_match_score(
    desc_words: set, keywords: List[str]
) -> Tuple[int, float]:
    """
    Calcula el puntaje de coincidencia entre una descripciÃ³n normalizada y palabras clave.

    Args:
        desc_words (set): Conjunto de palabras de la descripciÃ³n normalizada.
        keywords (List[str]): Lista de palabras clave a buscar (no vacÃ­a).

    Returns:
        Tuple[int, float]: NÃºmero de palabras coincidentes y porcentaje de cobertura.
    """
    if not keywords:
        return 0, 0.0

    matches = sum(1 for keyword in keywords if keyword in desc_words)
    percentage = (matches / len(keywords)) * 100.0
    return matches, percentage


def _find_best_keyword_match(
    df_pool: pd.DataFrame,
    keywords: List[str],
    log: List[str],
    strict: bool = False,
    min_match_percentage: float = 30.0,
    match_mode: str = 'words'
) -> Optional[pd.Series]:
    """
    Encuentra la mejor coincidencia de APU para una lista de palabras clave.
    Soporta modos: 'words' (coincidencia exacta de palabras) y 'substring' (contiene toda la cadena).

    Args:
        df_pool (pd.DataFrame): DataFrame con APUs procesados.
        keywords (List[str]): Palabras clave a buscar.
        log (List[str]): Lista de mensajes de log (mutables).
        strict (bool): Si True, requiere 100% de coincidencia.
        min_match_percentage (float): Umbral mÃ­nimo de coincidencia para modo flexible.
        match_mode (str): 'words' o 'substring'.

    Returns:
        pd.Series o None: El APU con mejor coincidencia, o None si no cumple criterios.
    """
    # ValidaciÃ³n inicial de entradas
    if not isinstance(df_pool, pd.DataFrame):
        log.append("  âŒ ERROR: df_pool no es un DataFrame.")
        return None
    if df_pool.empty:
        log.append("  --> Pool vacÃ­o, retornando None.")
        return None
    if not keywords or not any(k.strip() for k in keywords):
        log.append("  --> Keywords vacÃ­as o nulas, retornando None.")
        return None

    # Normalizar keywords (limpiar espacios, convertir a minÃºsculas)
    keywords_clean = [k.strip().lower() for k in keywords if k.strip()]
    if not keywords_clean:
        log.append("  --> DespuÃ©s de limpiar, keywords vacÃ­as, retornando None.")
        return None

    log.append(f"  ğŸ” Buscando: {' '.join(keywords_clean)}")
    log.append(f"  ğŸ“Š Pool size: {len(df_pool)} APUs")
    modo_str = "ESTRICTO (100%)" if strict else f"FLEXIBLE (â‰¥{min_match_percentage:.0f}%)"
    log.append(f" âš™ï¸ Modo: {modo_str} | Estrategia: {match_mode}")

    best_match = None
    best_score = -1
    best_percentage = -1.0
    candidates = []

    for idx, apu in df_pool.iterrows():
        # Obtener descripciÃ³n normalizada con manejo seguro
        desc_normalized = apu.get("DESC_NORMALIZED", "")
        if pd.isna(desc_normalized) or not isinstance(desc_normalized, str):
            desc_normalized = ""

        desc_normalized = desc_normalized.strip().lower()
        if not desc_normalized:
            continue  # Saltar descripciones vacÃ­as

        matches = 0
        percentage = 0.0

        if match_mode == 'words':
            desc_words = set(desc_normalized.split())
            matches, percentage = _calculate_match_score(desc_words, keywords_clean)
        elif match_mode == 'substring':
            keyword_str = ' '.join(keywords_clean)
            if keyword_str in desc_normalized:
                matches = len(keywords_clean)
                percentage = 100.0
        else:
            log.append(f"  âš ï¸ Modo '{match_mode}' no soportado, saltando este APU.")
            continue

        if matches == 0:
            continue

        # Guardar candidato
        original_desc = apu.get("original_description", "").strip()
        if not original_desc:
            original_desc = "DescripciÃ³n no disponible"

        candidates.append({
            'description': original_desc,
            'matches': matches,
            'percentage': percentage,
            'apu': apu
        })

        # Actualizar mejor coincidencia (prioriza matches, luego por %)
        if matches > best_score or (matches == best_score and percentage > best_percentage):
            best_match = apu
            best_score = matches
            best_percentage = percentage

    # Ordenar candidatos por relevancia
    candidates.sort(key=lambda x: (x['matches'], x['percentage']), reverse=True)

    # Mostrar top 3 candidatos
    if candidates:
        top_n = min(3, len(candidates))
        log.append(f"  ğŸ“‹ Top {top_n} candidatos:")
        for i, cand in enumerate(candidates[:top_n], 1):
            desc_snippet = cand['description'][:60] + "..." if len(cand['description']) > 60 else cand['description']
            log.append(
                f"    {i}. [{cand['matches']}/{len(keywords_clean)}] "
                f"({cand['percentage']:.0f}%) - {desc_snippet}"
            )

    # DecisiÃ³n final
    if strict:
        if best_percentage == 100.0:
            log.append("  âœ… Match ESTRICTO encontrado!")
            return best_match
        else:
            log.append(f"  âŒ No se encontrÃ³ match estricto (mejor: {best_percentage:.0f}%)")
            return None
    else:
        if best_percentage >= min_match_percentage:
            log.append(f"  âœ… Match FLEXIBLE encontrado ({best_percentage:.0f}%)")
            return best_match
        else:
            log.append(f"  âŒ Sin match vÃ¡lido (mejor: {best_percentage:.0f}% | umbral: {min_match_percentage:.0f}%)")
            return None


def _find_best_semantic_match(
    df_pool: pd.DataFrame,
    query_text: str,
    log: List[str],
    min_similarity: float = 0.5,
    top_k: int = 5,
) -> Optional[pd.Series]:
    """
    Encuentra la mejor coincidencia semÃ¡ntica para un texto de consulta.

    Utiliza un Ã­ndice FAISS y embeddings de `sentence-transformers` cargados
    en la aplicaciÃ³n Flask para encontrar los APUs mÃ¡s relevantes.

    Args:
        df_pool (pd.DataFrame): DataFrame con APUs procesados a considerar.
        query_text (str): Texto de consulta (ej. "muro de ladrillo").
        log (List[str]): Lista de mensajes de log (mutable).
        min_similarity (float): Umbral mÃ­nimo de similitud de coseno para considerar una coincidencia vÃ¡lida.
        top_k (int): NÃºmero de vecinos a buscar en el Ã­ndice FAISS.

    Returns:
        pd.Series o None: El APU con mejor coincidencia, o None si no cumple criterios.
    """
    # --- 1. Obtener artefactos de bÃºsqueda semÃ¡ntica desde la app ---
    model: Optional[SentenceTransformer] = current_app.config.get("EMBEDDING_MODEL")
    faiss_index = current_app.config.get("FAISS_INDEX")
    id_map: Optional[dict] = current_app.config.get("ID_MAP")

    if not all([model, faiss_index, id_map]):
        log.append("  âŒ ERROR: Faltan artefactos de bÃºsqueda semÃ¡ntica. La funciÃ³n estÃ¡ desactivada.")
        return None

    # --- 2. ValidaciÃ³n de entradas ---
    if not isinstance(df_pool, pd.DataFrame) or df_pool.empty:
        log.append("  --> Pool de APUs vacÃ­o, retornando None.")
        return None
    if not query_text or not query_text.strip():
        log.append("  --> Texto de consulta vacÃ­o, retornando None.")
        return None

    log.append(f"  ğŸ” BÃºsqueda SemÃ¡ntica: '{query_text}'")
    log.append(f"  ğŸ“Š Pool size: {len(df_pool)} APUs")
    log.append(f"  âš™ï¸ Umbral de similitud: {min_similarity:.2f}")

    # --- 3. Generar embedding para la consulta ---
    try:
        query_embedding = model.encode(
            [query_text],
            convert_to_numpy=True,
            normalize_embeddings=True
        )
    except Exception as e:
        log.append(f"  âŒ ERROR al generar embedding para la consulta: {e}")
        return None

    # --- 4. Buscar en el Ã­ndice FAISS ---
    try:
        # FAISS espera un array 2D de float32
        distances, indices = faiss_index.search(query_embedding.astype(np.float32), k=top_k)
    except Exception as e:
        log.append(f"  âŒ ERROR durante la bÃºsqueda en FAISS: {e}")
        return None

    # --- 5. Procesar y filtrar resultados ---
    candidates = []
    if indices.size == 0 or distances.size == 0:
        log.append("  --> No se encontraron resultados en el Ã­ndice.")
        return None

    # Iterar sobre los resultados encontrados
    for i in range(len(indices[0])):
        faiss_idx = indices[0][i]
        similarity = distances[0][i]

        # Obtener el CODIGO_APU desde el mapeo
        apu_code = id_map.get(str(faiss_idx))
        if apu_code is None:
            log.append(f"  âš ï¸ Ãndice FAISS {faiss_idx} no encontrado en el mapa de IDs.")
            continue

        # Buscar el APU en el DataFrame del pool actual
        apu_match = df_pool[df_pool["CODIGO_APU"] == apu_code]

        if not apu_match.empty:
            candidates.append({
                "apu": apu_match.iloc[0],
                "similarity": float(similarity),
            })

    if not candidates:
        log.append("  --> Ninguno de los candidatos del Ã­ndice estaba en el pool filtrado.")
        return None

    # --- 6. Log y selecciÃ³n final ---
    # Ordenar candidatos por similitud
    candidates.sort(key=lambda x: x['similarity'], reverse=True)

    log.append(f"  ğŸ“‹ Top {len(candidates)} candidatos encontrados:")
    for i, cand in enumerate(candidates, 1):
        apu = cand['apu']
        desc = apu.get("original_description", "N/A")
        desc_snippet = desc[:70] + "..." if len(desc) > 70 else desc
        log.append(
            f"    {i}. Sim: {cand['similarity']:.3f} | "
            f"CÃ³digo: {apu.get('CODIGO_APU')} | Desc: {desc_snippet}"
        )

    # Seleccionar el mejor candidato que cumpla el umbral
    best_candidate = candidates[0]
    if best_candidate["similarity"] >= min_similarity:
        log.append(
            f"  âœ… Coincidencia encontrada con similitud "
            f"({best_candidate['similarity']:.3f}) >= {min_similarity:.2f}"
        )
        return best_candidate["apu"]
    else:
        log.append(
            f"  âŒ Sin coincidencia vÃ¡lida. Mejor similitud "
            f"({best_candidate['similarity']:.3f}) < umbral ({min_similarity:.2f})"
        )
        return None


def calculate_estimate(
    params: Dict[str, str], data_store: Dict, config: Dict
) -> Dict[str, Union[str, float, List[str]]]:
    """
    Estima el costo de construcciÃ³n desglosado en suministro, cuadrilla y tarea.
    Usa coincidencias semÃ¡nticas en APU para inferir valores.

    Args:
        params (Dict): ParÃ¡metros de entrada: material, cuadrilla, zona, izaje, seguridad.
        data_store (Dict): AlmacÃ©n de datos: processed_apus, apus_detail.
        config (Dict): ConfiguraciÃ³n: param_map, estimator_rules.

    Returns:
        Dict: Resultado estimado con valores, descripciones y log detallado.
    """
    log: List[str] = []
    log.append("ğŸ•µï¸ ESTIMADOR DETECTIVE INICIADO")
    log.append("=" * 70)

    # ============================================
    # 1. CARGA Y VALIDACIÃ“N DE DATOS
    # ============================================
    processed_apus_list = data_store.get("processed_apus", [])
    if not isinstance(processed_apus_list, list):
        error_msg = "âŒ ERROR: 'processed_apus' no es una lista."
        log.append(error_msg)
        return {"error": error_msg, "log": "\n".join(log)}

    if not processed_apus_list:
        error_msg = "âŒ ERROR: No hay datos de APU procesados disponibles."
        log.append(error_msg)
        return {"error": error_msg, "log": "\n".join(log)}

    try:
        df_processed_apus = pd.DataFrame(processed_apus_list)
    except Exception as e:
        error_msg = f"âŒ ERROR al convertir processed_apus a DataFrame: {str(e)}"
        log.append(error_msg)
        return {"error": error_msg, "log": "\n".join(log)}

    log.append(f"ğŸ“š Datos cargados: {len(df_processed_apus)} APUs disponibles")

    # Validar columnas crÃ­ticas
    required_cols = {"DESC_NORMALIZED", "original_description", "tipo_apu", "VALOR_SUMINISTRO_UN", "UNIDAD", "EQUIPO", "CODIGO_APU"}
    missing_cols = required_cols - set(df_processed_apus.columns)
    if missing_cols:
        error_msg = f"âŒ Columnas faltantes en APUs: {missing_cols}"
        log.append(error_msg)
        return {"error": error_msg, "log": "\n".join(log)}

    # Extraer parÃ¡metros con validaciÃ³n
    material = (params.get("material", "") or "").strip().upper()
    cuadrilla = (params.get("cuadrilla", "0") or "").strip()
    zona = (params.get("zona", "ZONA 0") or "").strip()
    izaje = (params.get("izaje", "MANUAL") or "").strip()
    seguridad = (params.get("seguridad", "NORMAL") or "").strip()

    log.append(f"ğŸ“ Material: '{material}' | Cuadrilla: '{cuadrilla}'")
    log.append(f"ğŸ“ Config: Zona='{zona}', Izaje='{izaje}', Seguridad='{seguridad}'")

    # Mapeo de material
    param_map = config.get("param_map", {})
    material_mapped = (param_map.get("material", {}).get(material, material) or "").strip()
    if material_mapped != material:
        log.append(f"ğŸ”„ Material mapeado: '{material}' â†’ '{material_mapped}'")

    # Normalizar keywords de material
    material_keywords = normalize_text(material_mapped).split()
    if not material_keywords:
        log.append("âš ï¸ Material mapeado resultÃ³ en keywords vacÃ­as. La bÃºsqueda de suministro y tarea serÃ¡ inefectiva.")

    # ============================================
    # 2. BÃšSQUEDA DE SUMINISTRO
    # ============================================
    log.append("\n" + "=" * 70)
    log.append("ğŸ¯ BÃšSQUEDA #1: SUMINISTRO")
    log.append("-" * 70)

    valor_suministro = 0.0
    apu_suministro_desc = "No encontrado"

    # Filtrar solo tipos de suministro
    supply_types = ["Suministro", "Suministro (Pre-fabricado)"]
    df_suministro_pool = df_processed_apus[
        df_processed_apus["tipo_apu"].isin(supply_types)
    ].copy()

    log.append(f"ğŸ“¦ Pool de suministros: {len(df_suministro_pool)} APUs")

    apu_suministro = _find_best_semantic_match(
        df_pool=df_suministro_pool,
        query_text=material_mapped,
        log=log,
        min_similarity=0.30  # Umbral mÃ¡s bajo para suministros
    )

    if apu_suministro is not None:
        valor_suministro = float(apu_suministro.get("VALOR_SUMINISTRO_UN", 0.0) or 0.0)
        apu_suministro_desc = str(apu_suministro.get("original_description", "")).strip()
        log.append(f"ğŸ’° Valor encontrado: ${valor_suministro:,.2f}")
    else:
        log.append("âš ï¸ No se encontrÃ³ suministro")

    # ============================================
    # 3. BÃšSQUEDA DE CUADRILLA
    # ============================================
    log.append("\n" + "=" * 70)
    log.append("ğŸ¯ BÃšSQUEDA #2: CUADRILLA")
    log.append("-" * 70)

    costo_diario_cuadrilla = 0.0
    apu_cuadrilla_desc = "No encontrada"

    if cuadrilla and cuadrilla != "0":
        # Filtrar por UNIDAD == "DIA" (case-insensitive)
        df_cuadrilla_pool = df_processed_apus[
            df_processed_apus["UNIDAD"].astype(str).str.upper().str.strip() == "DIA"
        ].copy()

        log.append(f"ğŸ‘¥ Pool de cuadrillas: {len(df_cuadrilla_pool)} APUs con UNIDAD=DIA")

        cuadrilla_mapped = (param_map.get("cuadrilla", {}).get(cuadrilla, cuadrilla) or "").strip()
        search_term = f"cuadrilla {cuadrilla_mapped}"
        cuadrilla_keywords_norm = normalize_text(search_term).split()

        apu_cuadrilla = _find_best_keyword_match(
            df_cuadrilla_pool,
            cuadrilla_keywords_norm,
            log,
            strict=False,
            min_match_percentage=50.0,
            match_mode='substring'  # Buscar la frase completa
        )

        if apu_cuadrilla is not None:
            costo_diario_cuadrilla = float(apu_cuadrilla.get("VALOR_CONSTRUCCION_UN", 0.0) or 0.0)
            apu_cuadrilla_desc = str(apu_cuadrilla.get("original_description", "")).strip()
            log.append(f"ğŸ’° Costo diario: ${costo_diario_cuadrilla:,.2f}")
        else:
            log.append("âš ï¸ No se encontrÃ³ cuadrilla exacta")
    else:
        log.append("â„¹ï¸ Sin cuadrilla especificada")

    # ============================================
    # 4. BÃšSQUEDA DE TAREA (RENDIMIENTO Y EQUIPO)
    # ============================================
    log.append("\n" + "=" * 70)
    log.append("ğŸ¯ BÃšSQUEDA #3: TAREA (RENDIMIENTO Y EQUIPO)")
    log.append("-" * 70)

    rendimiento_dia = 0.0
    costo_equipo = 0.0
    apu_tarea_desc = "No encontrado"

    df_tarea_pool = df_processed_apus[df_processed_apus["tipo_apu"] == "InstalaciÃ³n"].copy()
    log.append(f"ğŸ”§ Pool de instalaciÃ³n: {len(df_tarea_pool)} APUs")

    apu_tarea = _find_best_semantic_match(
        df_pool=df_tarea_pool,
        query_text=material_mapped,
        log=log,
        min_similarity=0.40
    )

    if apu_tarea is not None:
        apu_tarea_desc = str(apu_tarea.get("original_description", "")).strip()
        costo_equipo = float(apu_tarea.get("EQUIPO", 0.0) or 0.0)
        apu_code = str(apu_tarea.get("CODIGO_APU", "")).strip()

        log.append(f"ğŸ“Š APU encontrado: {apu_code}")

        # Buscar rendimiento desde apus_detail
        apus_detail_list = data_store.get("apus_detail", [])
        if isinstance(apus_detail_list, list) and apus_detail_list:
            try:
                df_detail = pd.DataFrame(apus_detail_list)
                required_detail_cols = {"CODIGO_APU", "TIPO_INSUMO", "CANTIDAD_APU"}
                missing_detail = required_detail_cols - set(df_detail.columns)
                if missing_detail:
                    log.append(f"âš ï¸ Columnas faltantes en apus_detail: {missing_detail}")
                else:
                    apu_details = df_detail[df_detail["CODIGO_APU"].astype(str).str.strip() == apu_code]
                    mano_obra = apu_details[apu_details["TIPO_INSUMO"].astype(str).str.strip() == "MANO DE OBRA"]
                    if not mano_obra.empty:
                        tiempo_total = mano_obra["CANTIDAD_APU"].sum()
                        if tiempo_total > 0:
                            rendimiento_dia = 1.0 / tiempo_total
                            log.append(f"â±ï¸ Rendimiento calculado: {rendimiento_dia:.2f} un/dÃ­a")
            except Exception as e:
                log.append(f"âš ï¸ Error procesando apus_detail: {str(e)}")
        else:
            log.append("â„¹ï¸ No hay datos de apus_detail para calcular rendimiento")
    else:
        log.append("âš ï¸ No se encontrÃ³ tarea de instalaciÃ³n")

    # Si no se encontrÃ³ tarea, crear una sintÃ©tica basada en el material
    if apu_tarea is None and apu_suministro is not None:
        apu_tarea_desc = f"INSTALACION {material_mapped}"
        log.append(f"âœ… Tarea sintÃ©tica creada: '{apu_tarea_desc}'")
        rendimiento_dia = 0.0
        costo_equipo = 0.0

    # ============================================
    # 5. CÃLCULO FINAL CON REGLAS DE NEGOCIO
    # ============================================
    log.append("\n" + "=" * 70)
    log.append("ğŸ§® CÃLCULO FINAL CON REGLAS DE NEGOCIO")
    log.append("-" * 70)

    rules = config.get("estimator_rules", {})
    if not isinstance(rules, dict):
        log.append("âš ï¸ ConfiguraciÃ³n 'estimator_rules' no es un dict. Usando valores por defecto.")
        rules = {}

    factor_zona = rules.get("factores_zona", {}).get(zona, 1.0)
    costo_adicional_izaje = rules.get("costo_adicional_izaje", {}).get(izaje, 0)
    factor_seguridad = rules.get("factor_seguridad", {}).get(seguridad, 1.0)

    # Calcular costo de mano de obra base
    costo_mo_base = 0.0
    if rendimiento_dia > 0:
        costo_mo_base = costo_diario_cuadrilla / rendimiento_dia
    else:
        log.append("âš ï¸ Rendimiento = 0 â†’ No se puede calcular costo de mano de obra base.")

    costo_mo_ajustado = costo_mo_base * factor_seguridad
    valor_instalacion = (
        (costo_mo_ajustado + costo_equipo) * factor_zona + costo_adicional_izaje
    )
    valor_construccion = valor_suministro + valor_instalacion

    # ============================================
    # RESUMEN FINAL
    # ============================================
    log.append("\n" + "=" * 70)
    log.append("ğŸ“Š RESUMEN EJECUTIVO")
    log.append("=" * 70)
    log.append(f"ğŸ“¦ Suministro: ${valor_suministro:,.2f} ({apu_suministro_desc[:50]}{'...' if len(apu_suministro_desc) > 50 else ''})")
    log.append(f"ğŸ”¨ InstalaciÃ³n:   ${valor_instalacion:,.2f}")
    log.append(f"ğŸ’° TOTAL:         ${valor_construccion:,.2f}")

    apu_encontrado_str = (
        f"Suministro: {apu_suministro_desc} | "
        f"Tarea: {apu_tarea_desc} | "
        f"Cuadrilla: {apu_cuadrilla_desc}"
    )

    # Retornar resultados limpios y tipados
    return {
        "valor_suministro": float(valor_suministro),
        "valor_instalacion": float(valor_instalacion),
        "valor_construccion": float(valor_construccion),
        "rendimiento_m2_por_dia": float(rendimiento_dia),
        "apu_encontrado": apu_encontrado_str,
        "log": "\n".join(log),
    }
