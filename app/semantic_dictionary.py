"""
Microservicio: Semantic Dictionary (El Guardi√°n de la Ontolog√≠a)
Estrato DIKW: WISDOM (Nivel 0)

Responsabilidad:
    Aloja todas las plantillas narrativas y diccionarios de traducci√≥n.
    Recibe m√©tricas crudas (telemetry_schemas) y las transforma en "Empat√≠a T√°ctica"
    (prescripciones estrat√©gicas) para el usuario final.

Invariantes Topol√≥gicos:
    - Preserva la homotop√≠a entre el espacio de datos y el espacio narrativo
    - Mantiene la fibraci√≥n sem√°ntica sobre el grafo del presupuesto
"""
import logging
import random
import re
import string
import threading
import time
import traceback
from collections import OrderedDict
from dataclasses import dataclass, field
from enum import IntEnum
from functools import lru_cache
from typing import (
    Any, 
    Callable, 
    Dict, 
    Final, 
    FrozenSet, 
    List, 
    Literal, 
    Optional, 
    Set, 
    Tuple, 
    TypeVar, 
    Union,
)

# =============================================================================
# IMPORT SEGURO CON FALLBACK ROBUSTO
# =============================================================================

try:
    from app.schemas import Stratum
except ImportError:
    class Stratum(IntEnum):
        """
        Representaci√≥n jer√°rquica del modelo DIKW.
        
        Corresponde a una estratificaci√≥n topol√≥gica donde cada estrato
        define un nivel de abstracci√≥n en la pir√°mide de conocimiento.
        
        Propiedades Algebraicas:
            - Forma un conjunto totalmente ordenado (cadena)
            - El orden induce una filtraci√≥n: WISDOM ‚äÇ STRATEGY ‚äÇ TACTICS ‚äÇ PHYSICS
        """
        WISDOM = 0      # S√≠ntesis estrat√©gica (√Åpice)
        STRATEGY = 1    # Planificaci√≥n financiera  
        TACTICS = 2     # Estructura operativa
        PHYSICS = 3     # Datos f√≠sicos/cimentaci√≥n (Base)


logger = logging.getLogger("SemanticDictionary")

# =============================================================================
# CONSTANTES Y TIPOS
# =============================================================================

NodeType = Literal["ROOT", "CAPITULO", "APU", "INSUMO"]
VALID_NODE_TYPES: Final[FrozenSet[str]] = frozenset({"ROOT", "CAPITULO", "APU", "INSUMO"})

T = TypeVar('T')


# =============================================================================
# UTILIDADES DE CACH√â THREAD-SAFE CON TTL
# =============================================================================

class TTLCache:
    """
    Cach√© LRU con Time-To-Live y l√≠mite de tama√±o.
    
    Implementa evicci√≥n perezosa (lazy eviction) por TTL y evicci√≥n
    activa por capacidad m√°xima siguiendo pol√≠tica LRU.
    
    Thread-safe mediante RLock para operaciones anidadas.
    """
    
    __slots__ = ('_cache', '_timestamps', '_ttl', '_maxsize', '_lock', '_hits', '_misses')
    
    def __init__(self, ttl_seconds: float = 300.0, maxsize: int = 1000):
        if ttl_seconds <= 0:
            raise ValueError("TTL debe ser positivo")
        if maxsize <= 0:
            raise ValueError("maxsize debe ser positivo")
            
        self._cache: OrderedDict[str, Any] = OrderedDict()
        self._timestamps: Dict[str, float] = {}
        self._ttl: float = ttl_seconds
        self._maxsize: int = maxsize
        self._lock = threading.RLock()
        self._hits: int = 0
        self._misses: int = 0
    
    def get(self, key: str) -> Optional[Any]:
        """Obtiene valor si existe y no ha expirado."""
        with self._lock:
            if key not in self._cache:
                self._misses += 1
                return None
            
            timestamp = self._timestamps.get(key, 0)
            if time.time() - timestamp >= self._ttl:
                # Expirado: eliminar
                self._evict_key(key)
                self._misses += 1
                return None
            
            # Mover al final (m√°s reciente) para LRU
            self._cache.move_to_end(key)
            self._hits += 1
            return self._cache[key]
    
    def set(self, key: str, value: Any) -> None:
        """Almacena valor con timestamp actual."""
        with self._lock:
            # Si ya existe, actualizar y mover al final
            if key in self._cache:
                self._cache.move_to_end(key)
            else:
                # Verificar capacidad antes de insertar
                while len(self._cache) >= self._maxsize:
                    self._evict_oldest()
            
            self._cache[key] = value
            self._timestamps[key] = time.time()
    
    def _evict_key(self, key: str) -> None:
        """Elimina una clave espec√≠fica."""
        self._cache.pop(key, None)
        self._timestamps.pop(key, None)
    
    def _evict_oldest(self) -> None:
        """Elimina la entrada m√°s antigua (LRU)."""
        if self._cache:
            oldest_key = next(iter(self._cache))
            self._evict_key(oldest_key)
    
    def clear(self) -> None:
        """Limpia todo el cach√©."""
        with self._lock:
            self._cache.clear()
            self._timestamps.clear()
    
    def cleanup_expired(self) -> int:
        """
        Limpieza activa de entradas expiradas.
        
        Returns:
            N√∫mero de entradas eliminadas.
        """
        with self._lock:
            now = time.time()
            expired_keys = [
                k for k, ts in self._timestamps.items()
                if now - ts >= self._ttl
            ]
            for key in expired_keys:
                self._evict_key(key)
            return len(expired_keys)
    
    @property
    def stats(self) -> Dict[str, Any]:
        """Estad√≠sticas del cach√©."""
        with self._lock:
            total = self._hits + self._misses
            return {
                "size": len(self._cache),
                "maxsize": self._maxsize,
                "ttl_seconds": self._ttl,
                "hits": self._hits,
                "misses": self._misses,
                "hit_rate": self._hits / total if total > 0 else 0.0,
            }


# =============================================================================
# CLASES DE DATOS TOPOL√ìGICAS
# =============================================================================

@dataclass(frozen=True)
class PyramidalSemanticVector:
    """
    Vector de estado sem√°ntico para un nodo dentro del Grafo del Presupuesto.
    
    Codifica su posici√≥n en la estructura piramidal (DIKW) y su carga topol√≥gica.
    Act√∫a como un tensor de informaci√≥n para la generaci√≥n de GraphRAG.
    
    Definiciones Topol√≥gicas:
        - in_degree: |{e ‚àà E : target(e) = v}| (aristas entrantes)
        - out_degree: |{e ‚àà E : source(e) = v}| (aristas salientes)
        - is_critical_bridge: v es un cut-vertex (su eliminaci√≥n desconecta el grafo)
        
    Nota: Un cut-vertex NO se determina solo por grados, sino por an√°lisis
    de conectividad (DFS/Tarjan). El flag debe ser calculado externamente.
    
    Invariantes:
        - in_degree >= 0, out_degree >= 0
        - node_type ‚àà VALID_NODE_TYPES
    """
    node_id: str
    node_type: NodeType
    stratum: Stratum
    in_degree: int
    out_degree: int
    is_critical_bridge: bool = False
    
    def __post_init__(self):
        """Validaciones post-construcci√≥n para integridad topol√≥gica."""
        # Validar grados no negativos
        if self.in_degree < 0:
            raise ValueError(
                f"in_degree no puede ser negativo: {self.in_degree}"
            )
        if self.out_degree < 0:
            raise ValueError(
                f"out_degree no puede ser negativo: {self.out_degree}"
            )
        
        # Validar node_type
        if self.node_type not in VALID_NODE_TYPES:
            raise ValueError(
                f"node_type inv√°lido: '{self.node_type}'. "
                f"Valores permitidos: {VALID_NODE_TYPES}"
            )
        
        # Validar node_id no vac√≠o
        if not self.node_id or not self.node_id.strip():
            raise ValueError("node_id no puede estar vac√≠o")
    
    @property
    def total_degree(self) -> int:
        """Grado total del nodo (suma de entrantes y salientes)."""
        return self.in_degree + self.out_degree
    
    @property
    def is_leaf(self) -> bool:
        """Verdadero si el nodo es una hoja (sin salientes)."""
        return self.out_degree == 0
    
    @property
    def is_root(self) -> bool:
        """Verdadero si el nodo es ra√≠z (sin entrantes)."""
        return self.in_degree == 0
    
    @property
    def is_isolated(self) -> bool:
        """Verdadero si el nodo est√° aislado."""
        return self.total_degree == 0
    
    def to_dict(self) -> Dict[str, Any]:
        """Serializa a diccionario."""
        return {
            "node_id": self.node_id,
            "node_type": self.node_type,
            "stratum": self.stratum.name,
            "in_degree": self.in_degree,
            "out_degree": self.out_degree,
            "is_critical_bridge": self.is_critical_bridge,
            "total_degree": self.total_degree,
        }


# =============================================================================
# PROYECTOR SEM√ÅNTICO DE GRAFOS
# =============================================================================

class GraphSemanticProjector:
    """
    Proyecta la topolog√≠a algebraica del presupuesto hacia el espacio narrativo.
    
    Este Functor es el motor central de GraphRAG: navega el grafo y traduce
    los invariantes matem√°ticos en "La Voz del Consejo".
    
    Propiedades Algebraicas:
        - Act√∫a como un morfismo F: Top ‚Üí Narr entre categor√≠as
        - Preserva composici√≥n: F(g ‚àò f) = F(g) ‚àò F(f)
        - Preserva identidades: F(id_X) = id_{F(X)}
    """
    
    def __init__(
        self, 
        dictionary_service: 'SemanticDictionaryService',
        cache_ttl: float = 300.0,
        cache_maxsize: int = 500
    ):
        self._dictionary = dictionary_service
        self._cache = TTLCache(ttl_seconds=cache_ttl, maxsize=cache_maxsize)
    
    def _build_cache_key(self, prefix: str, *args) -> str:
        """Construye clave de cach√© determin√≠stica."""
        components = [prefix] + [str(a) for a in args]
        return ":".join(components)
    
    def project_pyramidal_stress(
        self, 
        vector: PyramidalSemanticVector
    ) -> Dict[str, Any]:
        """
        Proyecta un punto de estr√©s topol√≥gico a narrativa.
        
        Consumo PASIVO: Asume que el Arquitecto ya valid√≥ que es un punto de estr√©s.
        Solo inyecta los datos en la plantilla narrativa.
        
        Args:
            vector: Nodo cr√≠tico identificado por an√°lisis topol√≥gico
        
        Returns:
            Diccionario con narrativa estructurada sobre el punto de estr√©s
        """
        cache_key = self._build_cache_key(
            "stress",
            vector.node_id,
            vector.in_degree,
            vector.out_degree
        )
        
        cached = self._cache.get(cache_key)
        if cached is not None:
            # Retornar copia para evitar mutaciones
            return dict(cached)
        
        result = self._dictionary.fetch_narrative(
            domain="MISC",
            classification="STRESS_POINT",
            params={
                "node": vector.node_id,
                "degree": vector.total_degree,
                "in_degree": vector.in_degree,
                "out_degree": vector.out_degree,
            }
        )
        
        # Enriquecer con metadatos del vector
        result["vector_metadata"] = vector.to_dict()
        
        self._cache.set(cache_key, result)
        return result
    
    def project_cycle_path(self, path_nodes: List[str]) -> Dict[str, Any]:
        """
        Proyecta la ruta de un ciclo detectado a narrativa.
        
        Args:
            path_nodes: Secuencia ordenada de nodos formando el ciclo detectado.
                       El ciclo se cierra impl√≠citamente (√∫ltimo ‚Üí primero).
        
        Returns:
            Narrativa explicando la circularidad y sus implicaciones.
        """
        # Validaci√≥n de entrada
        if not path_nodes:
            logger.warning("project_cycle_path llamado con lista vac√≠a")
            return {
                "success": False, 
                "error": "Ruta vac√≠a proporcionada.",
                "suggestion": "Verifique el algoritmo de detecci√≥n de ciclos.",
            }
        
        # Sanitizar y convertir a strings
        sanitized_nodes = [str(n).strip() for n in path_nodes if n]
        
        if not sanitized_nodes:
            return {
                "success": False,
                "error": "Todos los nodos de la ruta son inv√°lidos.",
            }
        
        if len(sanitized_nodes) == 1:
            logger.warning(f"Ciclo trivial (self-loop) detectado: {sanitized_nodes[0]}")
        
        # Construir representaci√≥n de la ruta
        path_str = " ‚Üí ".join(sanitized_nodes)
        cycle_length = len(sanitized_nodes)
        
        # Cache key basado en contenido ordenado
        cache_key = self._build_cache_key("cycle", hash(tuple(sanitized_nodes)))
        
        cached = self._cache.get(cache_key)
        if cached is not None:
            return dict(cached)
        
        result = self._dictionary.fetch_narrative(
            domain="MISC",
            classification="CYCLE_PATH",
            params={
                "path": path_str,
                "first_node": sanitized_nodes[0],
                "cycle_length": cycle_length,
            }
        )
        
        # Metadatos adicionales
        result["cycle_metadata"] = {
            "nodes": sanitized_nodes,
            "length": cycle_length,
            "is_self_loop": cycle_length == 1,
        }
        
        self._cache.set(cache_key, result)
        return result
    
    def project_fragmentation(
        self, 
        beta_0: int, 
        component_sizes: Optional[List[int]] = None
    ) -> Dict[str, Any]:
        """
        Proyecta la fragmentaci√≥n topol√≥gica (n√∫mero de Betti Œ≤‚ÇÄ) a narrativa.
        
        Args:
            beta_0: N√∫mero de componentes conexas
            component_sizes: Tama√±os de cada componente (opcional)
        
        Returns:
            Narrativa sobre conectividad del grafo
        """
        cache_key = self._build_cache_key("fragmentation", beta_0)
        
        cached = self._cache.get(cache_key)
        if cached is not None:
            return dict(cached)
        
        if beta_0 == 0:
            classification = "empty"
        elif beta_0 == 1:
            classification = "unified"
        elif beta_0 <= 5:
            classification = "fragmented"
        else:
            classification = "severely_fragmented"
        
        result = self._dictionary.fetch_narrative(
            domain="TOPOLOGY_CONNECTIVITY",
            classification=classification,
            params={"beta_0": beta_0}
        )
        
        if component_sizes:
            result["component_analysis"] = {
                "sizes": component_sizes,
                "largest": max(component_sizes),
                "smallest": min(component_sizes),
                "gini_coefficient": self._calculate_gini(component_sizes),
            }
        
        self._cache.set(cache_key, result)
        return result
    
    @staticmethod
    def _calculate_gini(values: List[int]) -> float:
        """
        Calcula el coeficiente de Gini para medir desigualdad.
        
        Gini = 0: Perfecta igualdad
        Gini = 1: M√°xima desigualdad
        """
        if not values or len(values) == 1:
            return 0.0
        
        sorted_values = sorted(values)
        n = len(sorted_values)
        cumsum = sum(sorted_values)
        
        if cumsum == 0:
            return 0.0
        
        numerator = sum(
            (2 * (i + 1) - n - 1) * v 
            for i, v in enumerate(sorted_values)
        )
        return numerator / (n * cumsum)
    
    @property
    def cache_stats(self) -> Dict[str, Any]:
        """Estad√≠sticas del cach√© del proyector."""
        return self._cache.stats


# =============================================================================
# UTILIDADES PARA VALIDACI√ìN DE PLANTILLAS
# =============================================================================

class TemplateValidator:
    """
    Validador de plantillas con extracci√≥n robusta de placeholders.
    
    Utiliza string.Formatter para parseo correcto de format strings.
    """
    
    # Patr√≥n para detectar placeholders con formato
    _PLACEHOLDER_PATTERN = re.compile(r'\{(\w+)(?::[^}]*)?\}')
    
    @classmethod
    def extract_placeholders(cls, template: str) -> Set[str]:
        """
        Extrae todos los placeholders de una plantilla.
        
        Maneja correctamente formatos como {value:.2f}, {name!r}, etc.
        
        Args:
            template: String de plantilla con placeholders
            
        Returns:
            Conjunto de nombres de placeholders
        """
        formatter = string.Formatter()
        placeholders = set()
        
        try:
            for _, field_name, _, _ in formatter.parse(template):
                if field_name is not None:
                    # Extraer solo el nombre base (sin √≠ndices ni atributos)
                    base_name = field_name.split('.')[0].split('[')[0]
                    if base_name:
                        placeholders.add(base_name)
        except (ValueError, IndexError) as e:
            logger.warning(f"Error parseando plantilla: {e}")
            # Fallback a regex
            placeholders = set(cls._PLACEHOLDER_PATTERN.findall(template))
        
        return placeholders
    
    @classmethod
    def validate_template(
        cls, 
        template: str, 
        required_params: Optional[Set[str]] = None
    ) -> Tuple[bool, Optional[str]]:
        """
        Valida que una plantilla sea sint√°cticamente correcta.
        
        Args:
            template: Plantilla a validar
            required_params: Par√°metros que deben estar presentes (opcional)
            
        Returns:
            Tupla (es_v√°lida, mensaje_error)
        """
        try:
            placeholders = cls.extract_placeholders(template)
            
            # Crear diccionario de prueba con valores dummy
            test_params = {p: "" for p in placeholders}
            
            # Intentar formatear
            template.format(**test_params)
            
            # Verificar par√°metros requeridos
            if required_params:
                missing = required_params - placeholders
                if missing:
                    return False, f"Faltan placeholders requeridos: {missing}"
            
            return True, None
            
        except (KeyError, ValueError, IndexError) as e:
            return False, str(e)
    
    @classmethod
    def validate_all_templates(
        cls, 
        templates: Dict[str, Any],
        path: str = ""
    ) -> List[Dict[str, str]]:
        """
        Valida recursivamente todas las plantillas en un diccionario.
        
        Returns:
            Lista de errores encontrados
        """
        errors = []
        
        for key, value in templates.items():
            current_path = f"{path}.{key}" if path else key
            
            if isinstance(value, dict):
                errors.extend(cls.validate_all_templates(value, current_path))
            elif isinstance(value, str) and '{' in value:
                is_valid, error_msg = cls.validate_template(value)
                if not is_valid:
                    errors.append({
                        "path": current_path,
                        "error": error_msg,
                        "template_preview": value[:100] + "..." if len(value) > 100 else value,
                    })
        
        return errors


# =============================================================================
# SERVICIO PRINCIPAL DEL DICCIONARIO SEM√ÅNTICO
# =============================================================================

class SemanticDictionaryService:
    """
    Servicio Central de Traducci√≥n Sem√°ntica.
    
    Transforma m√©tricas t√©cnicas crudas en narrativa estrat√©gica comprensible.
    Implementa el patr√≥n Template Method para extensibilidad controlada.
    
    Thread Safety:
        - Todas las operaciones de lectura son thread-safe por dise√±o inmutable
        - Las operaciones de escritura al cach√© est√°n protegidas por locks
    """
    
    # =========================================================================
    # UMBRALES DE CLASIFICACI√ìN
    # Definidos como constantes de clase para permitir override en subclases
    # =========================================================================
    
    # Umbrales de estabilidad (Œ®): ratio insumos/APUs
    STABILITY_THRESHOLDS: Final[Dict[str, float]] = {
        "robust": 0.85,     # Redundancia significativa
        "stable": 0.70,     # Equilibrio aceptable
        "warning": 0.50,    # Margen m√≠nimo de seguridad
        "critical": 0.30,   # Base insuficiente
    }
    
    # Umbrales de entrop√≠a (S): desorden del sistema
    # Nota: Para entrop√≠a, MAYOR valor = PEOR estado
    ENTROPY_THRESHOLDS: Final[Dict[str, float]] = {
        "high": 0.70,    # Caos administrativo
        "low": 0.30,     # Procesos estructurados
    }
    
    # Umbrales de cohesi√≥n espectral (Fiedler eigenvalue)
    COHESION_THRESHOLDS: Final[Dict[str, float]] = {
        "high": 0.70,      # Fiedler ‚â• 0.7
        "standard": 0.40,  # 0.4 ‚â§ Fiedler < 0.7
        "low": 0.0,        # Fiedler < 0.4
    }
    
    # Umbrales de temperatura (volatilidad de precios)
    TEMPERATURE_THRESHOLDS: Final[Dict[str, float]] = {
        "critical": 100.0,
        "hot": 75.0,
        "warm": 50.0,
        "stable": 25.0,
        "cold": 0.0,
    }
    
    def __init__(self):
        """Inicializa el repositorio de plantillas con validaci√≥n integral."""
        self._lock = threading.RLock()
        self._templates = self._load_templates()
        self._market_contexts = self._load_market_contexts()
        self._projector: Optional[GraphSemanticProjector] = None
        
        # Validar plantillas en inicializaci√≥n
        validation_errors = TemplateValidator.validate_all_templates(self._templates)
        if validation_errors:
            logger.warning(
                f"Se encontraron {len(validation_errors)} plantillas con "
                f"posibles problemas de formato"
            )
            for err in validation_errors[:5]:  # Mostrar solo primeros 5
                logger.warning(f"  - {err['path']}: {err['error']}")
        
        logger.info("‚úÖ SemanticDictionaryService inicializado exitosamente")
    
    def _load_market_contexts(self) -> Tuple[str, ...]:
        """Carga los contextos de mercado como tupla inmutable."""
        return (
            "Suelo Estable: Precios de cemento sin variaci√≥n significativa.",
            "Terreno Inflacionario: Acero al alza (+2.5%). Reforzar estimaciones.",
            "Vientos de Cambio: Volatilidad cambiaria favorable para importaciones.",
            "Falla Geol√≥gica Laboral: Escasez de mano de obra calificada.",
            "Mercado Saturado: Alta competencia presiona m√°rgenes.",
        )
    
    def _load_templates(self) -> Dict[str, Any]:
        """
        Carga las plantillas narrativas.
        
        Las plantillas est√°n organizadas por dominio sem√°ntico y clasificaci√≥n.
        Cada plantilla puede contener placeholders {nombre} o {nombre:formato}.
        
        Returns:
            Diccionario anidado de plantillas
        """
        templates = {
            # ========== AN√ÅLISIS TOPOL√ìGICO ==========
            "TOPOLOGY_CYCLES": {
                "clean": (
                    "‚úÖ Integridad Estructural (G√©nero 0): No se detectan socavones l√≥gicos "
                    "(Œ≤‚ÇÅ = 0). La Trazabilidad de Carga de Costos fluye verticalmente desde "
                    "la Cimentaci√≥n hasta el √Åpice sin recirculaciones."
                ),
                "minor": (
                    "üî∂ Falla Estructural Local (G√©nero {beta_1}): Se detectaron {beta_1} "
                    "socavones l√≥gicos en la estructura de costos. Estos 'agujeros' impiden "
                    "la correcta Trazabilidad de Carga y deben ser corregidos para evitar "
                    "asentamientos diferenciales en el presupuesto."
                ),
                "moderate": (
                    "üö® Estructura Geol√≥gicamente Inestable (G√©nero {beta_1}): "
                    "Se detect√≥ un G√©nero Estructural de {beta_1}, indicando una estructura "
                    "tipo 'esponja'. Existen m√∫ltiples bucles de retroalimentaci√≥n de costos "
                    "que impiden la Trazabilidad de Carga y hacen colapsar cualquier "
                    "valoraci√≥n est√°tica."
                ),
                "critical": (
                    "üíÄ COLAPSO TOPOL√ìGICO (G√©nero {beta_1}): "
                    "La estructura est√° completamente perforada con {beta_1} ciclos "
                    "independientes. Es matem√°ticamente imposible calcular costos "
                    "determin√≠sticos. Se requiere redise√±o fundamental."
                ),
            },
            
            "TOPOLOGY_CONNECTIVITY": {
                "empty": "‚ö†Ô∏è Terreno Vac√≠o: No hay estructura proyectada (Œ≤‚ÇÄ = 0).",
                "unified": (
                    "üîó Unidad de Obra Monol√≠tica: El proyecto funciona como un solo "
                    "edificio interconectado (Œ≤‚ÇÄ = 1). Todas las cargas t√°cticas (APUs) "
                    "se transfieren correctamente hacia un √∫nico √Åpice Estrat√©gico."
                ),
                "fragmented": (
                    "‚ö†Ô∏è Edificios Desconectados (Fragmentaci√≥n): El proyecto no es una "
                    "estructura √∫nica, sino un archipi√©lago de {beta_0} sub-estructuras "
                    "aisladas. No existe un √Åpice unificado que centralice la carga financiera."
                ),
                "severely_fragmented": (
                    "üö® Fragmentaci√≥n Severa: El proyecto est√° fragmentado en {beta_0} islas "
                    "completamente desconectadas. Esto indica m√∫ltiples proyectos empaquetados "
                    "como uno solo, o datos severamente incompletos."
                ),
            },
            
            "STABILITY": {
                "critical": (
                    "üìâ COLAPSO POR BASE ESTRECHA (Pir√°mide Invertida): Œ® = {stability:.2f}. "
                    "La Cimentaci√≥n Log√≠stica (Insumos) es demasiado angosta para soportar el "
                    "Peso T√°ctico (APUs) que tiene encima. El centro de gravedad est√° muy alto; "
                    "riesgo inminente de vuelco financiero."
                ),
                "warning": (
                    "‚öñÔ∏è Equilibrio Precario (Isost√°tico): Œ® = {stability:.2f}. "
                    "El proyecto tiene la m√≠nima base necesaria, sin redundancia. Cualquier "
                    "perturbaci√≥n en el suministro puede desestabilizar toda la estructura."
                ),
                "stable": (
                    "‚öñÔ∏è Estructura Isost√°tica (Estable): Œ® = {stability:.2f}. "
                    "El equilibrio entre la carga de actividades y el soporte de insumos es "
                    "adecuado, aunque no posee redundancia s√≠smica."
                ),
                "robust": (
                    "üõ°Ô∏è ESTRUCTURA ANTIS√çSMICA (Resiliente): Œ® = {stability:.2f}. "
                    "La Cimentaci√≥n de Recursos es amplia y redundante. El proyecto tiene un "
                    "bajo centro de gravedad, capaz de absorber vibraciones del mercado "
                    "(volatilidad) sin sufrir da√±os estructurales."
                ),
            },
            
            "SPECTRAL_COHESION": {
                "high": (
                    "üîó Alta Cohesi√≥n del Equipo (Eigenvalor Fiedler={fiedler:.2f}): "
                    "La estructura de costos est√° fuertemente sincronizada."
                ),
                "standard": (
                    "‚öñÔ∏è Cohesi√≥n Est√°ndar (Eigenvalor Fiedler={fiedler:.2f}): "
                    "El proyecto presenta un acoplamiento t√≠pico entre sus componentes."
                ),
                "low": (
                    "üíî Fractura Organizacional (Eigenvalor Fiedler={fiedler:.3f}): "
                    "Baja cohesi√≥n espectral. Los subsistemas operan aislados, "
                    "riesgo de desalineaci√≥n en ejecuci√≥n."
                ),
            },
            
            "SPECTRAL_RESONANCE": {
                "risk": (
                    "üîä RIESGO DE RESONANCIA FINANCIERA (Œª={wavelength:.2f}): "
                    "El espectro de vibraci√≥n est√° peligrosamente concentrado. "
                    "Un impacto externo (inflaci√≥n/escasez) podr√≠a amplificarse en toda "
                    "la estructura simult√°neamente."
                ),
                "safe": (
                    "üåä Disipaci√≥n Ondulatoria (Œª={wavelength:.2f}): "
                    "La estructura tiene capacidad para amortiguar impactos locales sin entrar "
                    "en resonancia sist√©mica."
                ),
            },
            
            "THERMAL_TEMPERATURE": {
                "cold": (
                    "‚ùÑÔ∏è Temperatura Estable ({temperature:.1f}¬∞C): "
                    "El proyecto est√° termodin√°micamente equilibrado (Precios fr√≠os/fijos)."
                ),
                "stable": (
                    "üå°Ô∏è Temperatura Normal ({temperature:.1f}¬∞C): "
                    "Condiciones t√©rmicas est√°ndar del mercado."
                ),
                "warm": (
                    "üå°Ô∏è Calentamiento Operativo ({temperature:.1f}¬∞C): "
                    "Existe una exposici√≥n moderada a la volatilidad de precios."
                ),
                "hot": (
                    "üî• EL PROYECTO TIENE FIEBRE ({temperature:.1f}¬∞C): "
                    "El √çndice de Inflaci√≥n Interna es cr√≠tico. Los costos de insumos vol√°tiles "
                    "est√°n sobrecalentando la estructura de precios."
                ),
                "critical": (
                    "‚ò¢Ô∏è FUSI√ìN T√âRMICA ({temperature:.1f}¬∞C): "
                    "Temperatura cr√≠tica alcanzada. Los costos est√°n en espiral inflacionaria. "
                    "Riesgo de colapso financiero por sobrecalentamiento incontrolado."
                ),
            },
            
            "THERMAL_ENTROPY": {
                "low": (
                    "üìã Orden Administrativo (S={entropy:.2f}): "
                    "Baja entrop√≠a indica procesos bien estructurados y datos limpios."
                ),
                "high": (
                    "üå™Ô∏è Alta Entrop√≠a (S={entropy:.2f}): Caos administrativo detectado. "
                    "La energ√≠a del dinero se disipa en fricci√≥n operativa "
                    "(datos sucios o desorganizados)."
                ),
            },
            
            "GYROSCOPIC_STABILITY": {
                "stable": "‚úÖ Giroscopio Estable: Flujo con momento angular constante.",
                "precession": "‚ö†Ô∏è Precesi√≥n Detectada: Oscilaci√≥n lateral en el flujo de datos.",
                "nutation": (
                    "üö® NUTACI√ìN CR√çTICA: Inestabilidad rotacional. El proceso corre riesgo "
                    "de colapso inercial."
                ),
            },
            
            "LAPLACE_CONTROL": {
                "robust": "üõ°Ô∏è Control Robusto: Margen de fase s√≥lido (>45¬∞).",
                "marginal": "‚ö†Ô∏è Estabilidad Marginal: Respuesta oscilatoria ante transitorios.",
                "unstable": "‚õî DIVERGENCIA MATEM√ÅTICA: Polos en el semiplano derecho (RHP).",
            },
            
            "PUMP_DYNAMICS": {
                "efficiency_high": (
                    "Eficiencia de Inyecci√≥n: ALTA.\n"
                    "El costo administrativo de procesar esta informaci√≥n es "
                    "{joules_per_record:.2e} Joules por registro."
                ),
                "efficiency_low": (
                    "Eficiencia de Inyecci√≥n: BAJA.\n"
                    "El costo administrativo de procesar esta informaci√≥n es "
                    "{joules_per_record:.2e} Joules por registro."
                ),
                "water_hammer": (
                    "üí• Inestabilidad de Tuber√≠a: Se detectaron golpes de ariete "
                    "(Presi√≥n={pressure:.2f}). "
                    "El flujo se detiene bruscamente, causando ondas de choque."
                ),
                "accumulator_pressure": (
                    "üîã Presi√≥n del Acumulador: {pressure:.1f}%. "
                    "Capacidad de amortiguamiento disponible."
                ),
            },
            
            "FINANCIAL_VERDICT": {
                "accept": "üöÄ Veredicto: VIABLE (IR={pi:.2f}). Estructura financiable.",
                "conditional": "üîµ Veredicto: CONDICIONAL (IR={pi:.2f}). Viable con ajustes.",
                "review": "üîç Veredicto: REVISI√ìN REQUERIDA.",
                "reject": "üõë Veredicto: RIESGO CR√çTICO (IR={pi:.2f}). No procedente.",
            },
            
            "FINAL_VERDICTS": {
                "synergy_risk": (
                    "üõë PARADA DE EMERGENCIA (Efecto Domin√≥): Se detectaron ciclos interconectados "
                    "que comparten recursos cr√≠ticos. El riesgo no es aditivo, es multiplicativo. "
                    "Cualquier fallo en el suministro provocar√° un colapso sist√©mico en m√∫ltiples "
                    "frentes. Desacoplar los ciclos antes de continuar."
                ),
                "inverted_pyramid_viable": (
                    "‚ö†Ô∏è PRECAUCI√ìN LOG√çSTICA (Estructura Inestable): Aunque los n√∫meros "
                    "financieros cuadran, el proyecto es una Pir√°mide Invertida (Œ®={stability:.2f}). "
                    "Se sostiene sobre una base de recursos demasiado estrecha. "
                    "RECOMENDACI√ìN: Ampliar la base de proveedores antes de construir."
                ),
                "inverted_pyramid_reject": (
                    "‚ùå PROYECTO INVIABLE (Riesgo de Colapso): Combinaci√≥n letal de inestabilidad "
                    "estructural (Pir√°mide Invertida) e inviabilidad financiera. "
                    "No proceder bajo ninguna circunstancia sin redise√±o total."
                ),
                "has_holes": (
                    "üõë DETENER PARA REPARACIONES: Se detectaron {beta_1} socavones l√≥gicos "
                    "(ciclos). No se puede verter dinero en una estructura con agujeros. "
                    "Sanear la topolog√≠a antes de aprobar presupuesto."
                ),
                "certified": (
                    "‚úÖ CERTIFICADO DE SOLIDEZ: Estructura piramidal estable, sin socavones "
                    "l√≥gicos y financieramente viable. Proceder a fase de ejecuci√≥n."
                ),
                "review_required": (
                    "üîç REVISI√ìN T√âCNICA REQUERIDA: La estructura es s√≥lida pero los n√∫meros "
                    "no convencen."
                ),
                "analysis_failed": (
                    "‚ö†Ô∏è AN√ÅLISIS ESTRUCTURAL INTERRUMPIDO: Se detectaron inconsistencias "
                    "matem√°ticas o falta de datos cr√≠ticos que impiden certificar la solidez "
                    "del proyecto. Revise los errores en las secciones t√©cnicas."
                ),
            },
            
            "MISC": {
                "MAYER_VIETORIS": (
                    "üß© Incoherencia de Integraci√≥n: La fusi√≥n de los presupuestos ha generado "
                    "{delta_beta_1} ciclos l√≥gicos fantasmas (Anomal√≠a de Mayer-Vietoris). "
                    "Los datos individuales son v√°lidos, pero su uni√≥n crea una contradicci√≥n "
                    "topol√≥gica."
                ),
                "THERMAL_DEATH": (
                    "‚ò¢Ô∏è MUERTE T√âRMICA DEL SISTEMA: La entrop√≠a ha alcanzado el equilibrio "
                    "m√°ximo. No hay energ√≠a libre para procesar informaci√≥n √∫til."
                ),
                "SYNERGY": (
                    "üî• Riesgo de Contagio (Efecto Domin√≥): Se detect√≥ una 'Sinergia de Riesgo' "
                    "en {count} puntos de intersecci√≥n cr√≠tica. Los errores no son aislados; "
                    "si uno falla, provocar√° una reacci√≥n en cadena a trav√©s de los frentes de "
                    "obra compartidos."
                ),
                "EULER_EFFICIENCY": (
                    "üï∏Ô∏è Sobrecarga de Gesti√≥n (Entrop√≠a): La eficiencia de Euler es baja "
                    "({efficiency:.2f}). Existe una complejidad innecesaria de enlaces que "
                    "dificulta la supervisi√≥n y aumenta los costos indirectos de administraci√≥n."
                ),
                "CYCLE_PATH": (
                    "üîÑ Ruta del Ciclo Detectada: La circularidad sigue el camino: [{path}]. "
                    "Esto significa que el costo de '{first_node}' depende indirectamente de "
                    "s√≠ mismo, creando una indeterminaci√≥n matem√°tica en la valoraci√≥n."
                ),
                "STRESS_POINT": (
                    "‚ö° Punto de Estr√©s Estructural: El elemento '{node}' act√∫a como una "
                    "'Piedra Angular' cr√≠tica, soportando {degree} conexiones directas. "
                    "Una variaci√≥n en su precio o disponibilidad impactar√° desproporcionadamente "
                    "a toda la estructura del proyecto (Punto √önico de Falla)."
                ),
                "WACC": "üí∞ Costo de Oportunidad: WACC = {wacc:.2%}.",
                "CONTINGENCY": "üìä Blindaje Financiero: Contingencia sugerida de ${contingency:,.2f}.",
            },
            
            # ========== TELEMETRY SUCCESS/WARNING/FAILURE ==========
            "TELEMETRY_SUCCESS": {
                "PHYSICS": (
                    "‚úÖ **Cimentaci√≥n Estable**:\n"
                    "Flujo laminar de datos confirmado. Sin turbulencia (Flyback).\n"
                    "La base f√≠sica del proyecto es s√≥lida."
                ),
                "TACTICS": (
                    "‚úÖ **Estructura Coherente**:\n"
                    "Topolog√≠a conexa (Œ≤‚ÇÄ=1) y ac√≠clica (Œ≤‚ÇÅ=0).\n"
                    "El grafo de dependencias es v√°lido."
                ),
                "STRATEGY": (
                    "‚úÖ **Viabilidad Confirmada**:\n"
                    "El modelo financiero es robusto ante la volatilidad.\n"
                    "Los indicadores de riesgo est√°n dentro de umbrales aceptables."
                ),
                "WISDOM": (
                    "‚úÖ **S√≠ntesis Completa**:\n"
                    "Respuesta generada exitosamente.\n"
                    "Todas las capas del an√°lisis convergen."
                ),
            },
            
            "TELEMETRY_WARNINGS": {
                "PHYSICS": (
                    "‚ö†Ô∏è **Se√±ales de Turbulencia**:\n"
                    "Se detectaron fluctuaciones en el flujo de datos.\n"
                    "Monitorear la situaci√≥n."
                ),
                "TACTICS": (
                    "‚ö†Ô∏è **Estructura Sub√≥ptima**:\n"
                    "El grafo presenta redundancias o complejidad excesiva.\n"
                    "Considerar simplificaci√≥n."
                ),
                "STRATEGY": (
                    "‚ö†Ô∏è **Sensibilidad Alta**:\n"
                    "El modelo financiero es sensible a variaciones.\n"
                    "Realizar an√°lisis de escenarios."
                ),
                "WISDOM": (
                    "‚ö†Ô∏è **S√≠ntesis Parcial**:\n"
                    "La respuesta se gener√≥ con algunas limitaciones.\n"
                    "Revisar calidad de inputs."
                ),
            },
            
            "TELEMETRY_FAILURES_PHYSICS": {
                "default": (
                    "üî• **Falla en Cimentaci√≥n**:\n"
                    "Se detect√≥ inestabilidad f√≠sica (Saturaci√≥n/Flyback).\n"
                    "Los datos no son confiables."
                ),
                "saturation": (
                    "‚ö° **Sobrecarga Detectada**:\n"
                    "El sistema alcanz√≥ saturaci√≥n cr√≠tica.\n"
                    "Reducir carga o escalar recursos."
                ),
                "corruption": (
                    "üí• **Datos Corruptos**:\n"
                    "La integridad de los datos de entrada est√° comprometida.\n"
                    "Verificar fuentes."
                ),
                "nutation": (
                    "üö® **NUTACI√ìN CR√çTICA**:\n"
                    "Inestabilidad rotacional detectada. El proceso corre riesgo de "
                    "colapso inercial por oscilaciones no amortiguadas."
                ),
                "thermal_death": (
                    "‚ò¢Ô∏è **MUERTE T√âRMICA DEL SISTEMA**:\n"
                    "La entrop√≠a ha alcanzado el equilibrio m√°ximo.\n"
                    "No hay energ√≠a libre para procesar informaci√≥n √∫til."
                ),
                "laplace_unstable": (
                    "‚õî **DIVERGENCIA MATEM√ÅTICA**:\n"
                    "Polos en el semiplano derecho (RHP). El sistema es intr√≠nsecamente "
                    "explosivo ante variaciones de entrada."
                ),
                "water_hammer": (
                    "üåä **GOLPE DE ARIETE DETECTADO**:\n"
                    "Ondas de choque en la tuber√≠a de datos (Presi√≥n > 0.7).\n"
                    "Riesgo de ruptura en la persistencia."
                ),
                "high_injection_work": (
                    "üí™ **Fase de Ingesta (Sobrecarga)**:\n"
                    "Alto esfuerzo de inyecci√≥n detectado. La fricci√≥n de los datos "
                    "est√° consumiendo energ√≠a cr√≠tica."
                ),
            },
            
            "TELEMETRY_FAILURES_TACTICS": {
                "default": (
                    "üèóÔ∏è **Fragmentaci√≥n Estructural**:\n"
                    "El grafo del proyecto est√° desconectado.\n"
                    "Existen islas de datos sin conexi√≥n."
                ),
                "cycles": (
                    "üîÑ **Socav√≥n L√≥gico Detectado**:\n"
                    "La estructura contiene bucles infinitos (Œ≤‚ÇÅ > 0).\n"
                    "El costo es incalculable."
                ),
                "disconnected": (
                    "üß© **Componentes Aislados**:\n"
                    "Œ≤‚ÇÄ > 1 indica m√∫ltiples componentes desconectados.\n"
                    "Revisar enlaces entre m√≥dulos."
                ),
                "mayer_vietoris": (
                    "üß© **ANOMAL√çA DE INTEGRACI√ìN (Mayer-Vietoris)**:\n"
                    "La fusi√≥n de datasets ha generado ciclos l√≥gicos que no exist√≠an "
                    "en las fuentes originales. Inconsistencia topol√≥gica."
                ),
            },
            
            "TELEMETRY_FAILURES_STRATEGY": {
                "default": (
                    "üìâ **Riesgo Sist√©mico**:\n"
                    "Aunque la estructura es v√°lida,\n"
                    "la simulaci√≥n financiera proyecta p√©rdidas."
                ),
                "high_var": (
                    "üé≤ **Alta Volatilidad**:\n"
                    "El VaR excede umbrales aceptables.\n"
                    "Considerar coberturas o reducir exposici√≥n."
                ),
                "negative_npv": (
                    "üí∏ **Destrucci√≥n de Valor**:\n"
                    "El NPV proyectado es negativo.\n"
                    "El proyecto no genera valor econ√≥mico."
                ),
            },
            
            "TELEMETRY_FAILURES_WISDOM": {
                "default": (
                    "‚ö†Ô∏è **S√≠ntesis Comprometida**:\n"
                    "Hubo problemas generando la respuesta final.\n"
                    "Revisar pasos anteriores."
                ),
            },
            
            "TELEMETRY_VERDICTS": {
                "APPROVED": (
                    "üèõÔ∏è **CERTIFICADO DE SOLIDEZ INTEGRAL**\n"
                    "El Consejo valida el proyecto en todas sus dimensiones:\n"
                    "F√≠sicamente estable, Topol√≥gicamente conexo y Financieramente viable."
                ),
                "REJECTED_PHYSICS": (
                    "‚õî **PROCESO ABORTADO POR INESTABILIDAD F√çSICA**\n"
                    "El Guardi√°n detect√≥ que el flujo de datos es turbulento o corrupto.\n"
                    "No tiene sentido analizar la estrategia financiera de datos que "
                    "no existen f√≠sicamente."
                ),
                "REJECTED_TACTICS": (
                    "üöß **VETO ESTRUCTURAL DEL ARQUITECTO**\n"
                    "Los datos son legibles, pero forman una estructura imposible.\n"
                    "Cualquier c√°lculo financiero sobre esta base ser√≠a una alucinaci√≥n."
                ),
                "REJECTED_STRATEGY": (
                    "üìâ **ALERTA FINANCIERA DEL OR√ÅCULO**\n"
                    "La estructura es s√≥lida, pero el mercado es hostil o el proyecto "
                    "no es rentable."
                ),
                "REJECTED_WISDOM": (
                    "‚ö†Ô∏è **FALLO EN S√çNTESIS FINAL**\n"
                    "Todas las capas base son v√°lidas, pero hubo un error generando "
                    "la respuesta."
                ),
            },
        }
        
        return templates
    
    @property
    def projector(self) -> GraphSemanticProjector:
        """Obtiene o crea el proyector sem√°ntico (lazy initialization)."""
        if self._projector is None:
            with self._lock:
                # Double-check locking
                if self._projector is None:
                    self._projector = GraphSemanticProjector(self)
        return self._projector
    
    def fetch_narrative(
        self,
        domain: str,
        classification: Optional[str] = None,
        params: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Construye la narrativa basada en el dominio y la clasificaci√≥n.
        
        Args:
            domain: Grupo tem√°tico de la plantilla (TOPOLOGY, STABILITY, etc.)
            classification: Estado espec√≠fico dentro del dominio
            params: Variables de sustituci√≥n para formateo
            **kwargs: Argumentos adicionales (merged con params)
            
        Returns:
            Diccionario con resultado de operaci√≥n y narrativa generada
        """
        # Merge params y kwargs
        effective_params = {**(params or {}), **kwargs}
        
        # Manejo especial para MARKET_CONTEXT
        if domain == "MARKET_CONTEXT":
            return self._handle_market_context(effective_params)
        
        # Obtener grupo de plantillas
        template_group = self._templates.get(domain)
        if template_group is None:
            logger.warning(f"Domain '{domain}' no encontrado en plantillas")
            return {
                "success": False,
                "error": f"Domain '{domain}' not found",
                "available_domains": sorted(self._templates.keys()),
            }
        
        try:
            narrative = self._resolve_template(
                template_group, 
                classification, 
                effective_params
            )
            
            return {
                "success": True,
                "narrative": narrative,
                "stratum": Stratum.WISDOM.name,
                "domain": domain,
                "classification": classification,
            }
            
        except KeyError as e:
            logger.error(
                f"Placeholder faltante en {domain}.{classification}: {e}"
            )
            return {
                "success": False,
                "error": f"Missing required parameter: {e}",
                "domain": domain,
                "classification": classification,
                "provided_params": list(effective_params.keys()),
            }
        except Exception as e:
            logger.exception(
                f"Error generando narrativa para {domain}.{classification}"
            )
            return {
                "success": False,
                "error": str(e),
                "traceback": traceback.format_exc(),
            }
    
    def _handle_market_context(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Maneja solicitudes de contexto de mercado."""
        deterministic = params.get("deterministic", False)
        
        if deterministic:
            index = params.get("index", 0)
            narrative = self._market_contexts[index % len(self._market_contexts)]
        else:
            narrative = random.choice(self._market_contexts)
        
        return {
            "success": True,
            "narrative": narrative,
            "stratum": Stratum.WISDOM.name,
            "domain": "MARKET_CONTEXT",
            "total_contexts": len(self._market_contexts),
        }
    
    def _resolve_template(
        self,
        template_group: Union[str, Dict[str, str]],
        classification: Optional[str],
        params: Dict[str, Any]
    ) -> str:
        """
        Resuelve una plantilla a su texto final.
        
        Args:
            template_group: Puede ser string directo o dict de clasificaciones
            classification: Clave de clasificaci√≥n si template_group es dict
            params: Par√°metros de sustituci√≥n
            
        Returns:
            Texto narrativo formateado
        """
        if isinstance(template_group, str):
            return template_group.format(**params)
        
        if isinstance(template_group, dict):
            default_msg = "‚ö†Ô∏è Estado desconocido. Clasificaci√≥n no encontrada."
            template = template_group.get(classification, default_msg)
            return template.format(**params)
        
        # Fallback para otros tipos
        return str(template_group)
    
    def get_classification_by_threshold(
        self,
        metric_name: str,
        value: float,
        inverse: bool = False
    ) -> str:
        """
        Determina clasificaci√≥n basada en umbrales predefinidos.
        
        Args:
            metric_name: Nombre del umbral (STABILITY, ENTROPY, COHESION, TEMPERATURE)
            value: Valor medido
            inverse: Si True, invierte la l√≥gica (menor valor = mejor clasificaci√≥n)
            
        Returns:
            Clasificaci√≥n correspondiente
        """
        threshold_map = {
            "STABILITY": (self.STABILITY_THRESHOLDS, False),
            "ENTROPY": (self.ENTROPY_THRESHOLDS, True),  # Mayor entrop√≠a = peor
            "COHESION": (self.COHESION_THRESHOLDS, False),
            "TEMPERATURE": (self.TEMPERATURE_THRESHOLDS, True),  # Mayor temp = peor
        }
        
        config = threshold_map.get(metric_name.upper())
        if config is None:
            raise ValueError(
                f"M√©trica '{metric_name}' no tiene umbrales definidos. "
                f"Disponibles: {list(threshold_map.keys())}"
            )
        
        thresholds, default_inverse = config
        should_inverse = inverse or default_inverse
        
        # Ordenar umbrales
        sorted_items = sorted(
            thresholds.items(),
            key=lambda x: x[1],
            reverse=not should_inverse
        )
        
        for classification, threshold in sorted_items:
            if should_inverse:
                if value >= threshold:
                    return classification
            else:
                if value >= threshold:
                    return classification
        
        # Retornar la clasificaci√≥n con menor umbral
        return min(thresholds.keys(), key=lambda k: thresholds[k])
    
    def convert_stratum_value(self, value: Union[int, str, Stratum]) -> Stratum:
        """
        Convierte cualquier representaci√≥n v√°lida de Stratum al Enum.
        
        Args:
            value: Puede ser int, string, o ya un Stratum
            
        Returns:
            Instancia Stratum v√°lida
            
        Raises:
            ValueError: Si el valor no corresponde a ning√∫n Stratum v√°lido
            TypeError: Si el tipo no es soportado
        """
        if isinstance(value, Stratum):
            return value
        
        if isinstance(value, int):
            try:
                return Stratum(value)
            except ValueError as e:
                valid_values = [s.value for s in Stratum]
                raise ValueError(
                    f"Valor entero {value} no es un Stratum v√°lido. "
                    f"Valores v√°lidos: {valid_values}"
                ) from e
        
        if isinstance(value, str):
            normalized = value.upper().strip()
            try:
                return Stratum[normalized]
            except KeyError as e:
                valid_names = [s.name for s in Stratum]
                raise ValueError(
                    f"'{value}' no es un nombre de Stratum v√°lido. "
                    f"Nombres v√°lidos: {valid_names}"
                ) from e
        
        raise TypeError(
            f"Tipo no soportado para conversi√≥n de Stratum: {type(value).__name__}. "
            f"Se esperaba int, str o Stratum."
        )
    
    def project_graph_narrative(
        self, 
        payload: Dict[str, Any], 
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Proyecta una anomal√≠a del grafo (ciclos o estr√©s) a una narrativa.
        
        Esta funci√≥n act√∫a como adapter entre el motor topol√≥gico y el
        lenguaje natural.
        
        Args:
            payload: Datos crudos de la anomal√≠a detectada
            context: Informaci√≥n adicional del entorno de ejecuci√≥n
            
        Returns:
            Narrativa estructurada sobre la anomal√≠a
        """
        context = context or {}
        anomaly_type = payload.get("anomaly_type", "").upper()
        
        handlers = {
            "CYCLE": self._project_cycle_anomaly,
            "STRESS": self._project_stress_anomaly,
            "FRAGMENTATION": self._project_fragmentation_anomaly,
        }
        
        handler = handlers.get(anomaly_type)
        if handler is None:
            return {
                "success": False,
                "error": f"Tipo de anomal√≠a '{anomaly_type}' no soportada.",
                "supported_types": list(handlers.keys()),
            }
        
        try:
            return handler(payload, context)
        except Exception as e:
            logger.exception(f"Error proyectando anomal√≠a {anomaly_type}")
            return {
                "success": False,
                "error": str(e),
                "anomaly_type": anomaly_type,
                "traceback": traceback.format_exc(),
            }
    
    def _project_cycle_anomaly(
        self, 
        payload: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Proyecta anomal√≠a de ciclo."""
        path_nodes = payload.get("path_nodes", [])
        
        if not isinstance(path_nodes, (list, tuple)):
            path_nodes = [path_nodes] if path_nodes else []
        
        return self.projector.project_cycle_path(list(path_nodes))
    
    def _project_stress_anomaly(
        self, 
        payload: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Proyecta anomal√≠a de estr√©s estructural."""
        vector_data = payload.get("vector", {})
        
        if not isinstance(vector_data, dict):
            return {
                "success": False,
                "error": "Campo 'vector' debe ser un diccionario.",
                "received_type": type(vector_data).__name__,
            }
        
        # Conversi√≥n robusta de stratum
        if "stratum" in vector_data:
            try:
                vector_data["stratum"] = self.convert_stratum_value(
                    vector_data["stratum"]
                )
            except (ValueError, TypeError) as e:
                logger.warning(f"Conversi√≥n de Stratum fallida: {e}")
                vector_data["stratum"] = Stratum.TACTICS
        else:
            vector_data["stratum"] = Stratum.TACTICS
        
        # Validar campos requeridos
        required_fields = {"node_id", "node_type", "stratum", "in_degree", "out_degree"}
        provided_fields = set(vector_data.keys())
        missing = required_fields - provided_fields
        
        if missing:
            return {
                "success": False,
                "error": f"Faltan campos requeridos: {sorted(missing)}",
                "received_fields": sorted(provided_fields),
                "required_fields": sorted(required_fields),
            }
        
        # Validar node_type
        if vector_data["node_type"] not in VALID_NODE_TYPES:
            return {
                "success": False,
                "error": f"node_type inv√°lido: '{vector_data['node_type']}'",
                "valid_types": sorted(VALID_NODE_TYPES),
            }
        
        try:
            vector = PyramidalSemanticVector(**vector_data)
            return self.projector.project_pyramidal_stress(vector)
        except (ValueError, TypeError) as e:
            return {
                "success": False,
                "error": f"Error construyendo vector: {str(e)}",
                "vector_data": vector_data,
            }
    
    def _project_fragmentation_anomaly(
        self, 
        payload: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Proyecta anomal√≠a de fragmentaci√≥n."""
        beta_0 = payload.get("beta_0", 0)
        component_sizes = payload.get("component_sizes")
        
        if not isinstance(beta_0, int) or beta_0 < 0:
            return {
                "success": False,
                "error": "beta_0 debe ser un entero no negativo.",
                "received": beta_0,
            }
        
        return self.projector.project_fragmentation(beta_0, component_sizes)
    
    def register_in_mic(self, mic_registry: Any) -> bool:
        """
        Registra el diccionario en la MIC (Microservice Interface Controller).
        
        Expone vectores de servicio para consultas de plantillas y
        proyecci√≥n de anomal√≠as topol√≥gicas.
        
        Args:
            mic_registry: Instancia del registro de servicios
            
        Returns:
            True si el registro fue exitoso, False en caso contrario
        """
        try:
            from app.tools_interface import MICRegistry
        except ImportError:
            logger.warning(
                "MICRegistry no disponible. "
                "El servicio funcionar√° en modo standalone."
            )
            return False
        
        if not isinstance(mic_registry, MICRegistry):
            logger.error(
                f"Tipo de registro inv√°lido: {type(mic_registry).__name__}. "
                f"Se esperaba MICRegistry."
            )
            return False
        
        try:
            mic_registry.register_vector(
                service_name="fetch_narrative",
                stratum=Stratum.WISDOM,
                handler=self.fetch_narrative,
                description="Traductor de m√©tricas a narrativa estrat√©gica",
            )
            
            mic_registry.register_vector(
                service_name="project_graph_narrative",
                stratum=Stratum.WISDOM,
                handler=self.project_graph_narrative,
                description="Proyector de anomal√≠as topol√≥gicas a lenguaje natural",
            )
            
            logger.info("‚úÖ Vectores Sem√°nticos registrados en la MIC")
            return True
            
        except Exception as e:
            logger.exception(f"Error registrando vectores en MIC: {e}")
            return False
    
    def health_check(self) -> Dict[str, Any]:
        """
        Endpoint de salud para monitoreo.
        
        Returns:
            Diccionario con estado del servicio y m√©tricas b√°sicas
        """
        projector_stats = {}
        if self._projector is not None:
            projector_stats = self._projector.cache_stats
        
        return {
            "status": "healthy",
            "service": "SemanticDictionaryService",
            "stratum": Stratum.WISDOM.name,
            "template_domains": len(self._templates),
            "market_contexts_count": len(self._market_contexts),
            "strata_available": [s.name for s in Stratum],
            "thresholds": {
                "stability": self.STABILITY_THRESHOLDS,
                "entropy": self.ENTROPY_THRESHOLDS,
                "cohesion": self.COHESION_THRESHOLDS,
            },
            "projector_cache": projector_stats,
            "timestamp": time.time(),
        }
    
    def get_available_domains(self) -> List[str]:
        """Retorna lista de dominios de plantillas disponibles."""
        return sorted(self._templates.keys())
    
    def get_domain_classifications(self, domain: str) -> Optional[List[str]]:
        """
        Retorna las clasificaciones disponibles para un dominio.
        
        Args:
            domain: Nombre del dominio
            
        Returns:
            Lista de clasificaciones o None si el dominio no existe
        """
        template_group = self._templates.get(domain)
        
        if template_group is None:
            return None
        
        if isinstance(template_group, dict):
            return sorted(template_group.keys())
        
        return []


# =============================================================================
# FACTORY FUNCTION
# =============================================================================

def create_semantic_dictionary_service() -> SemanticDictionaryService:
    """
    Factory function para crear instancias del servicio.
    
    Permite inyecci√≥n de dependencias y configuraci√≥n centralizada.
    
    Returns:
        Instancia configurada de SemanticDictionaryService
    """
    service = SemanticDictionaryService()
    logger.info(f"Servicio creado con {len(service.get_available_domains())} dominios")
    return service