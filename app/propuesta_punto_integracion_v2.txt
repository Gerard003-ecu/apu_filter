1Ô∏è‚É£ ReportParserCrudo - Validaci√≥n con Lark Integrado

# En app/report_parser_crudo.py

import re
from typing import List, Optional, Dict, Any, Tuple
from dataclasses import dataclass, field
from lark import Lark
from lark.exceptions import LarkError

@dataclass
class LineValidationResult:
    """Resultado detallado de la validaci√≥n de una l√≠nea."""
    is_valid: bool
    reason: str = ""
    fields_count: int = 0
    has_numeric_fields: bool = False
    validation_layer: str = ""  # "basic", "lark", "both"
    lark_tree: Any = None  # √Årbol de parsing si fue exitoso

@dataclass
class ValidationStats:
    """Estad√≠sticas detalladas de validaci√≥n."""
    total_evaluated: int = 0
    passed_basic: int = 0
    passed_lark: int = 0
    passed_both: int = 0
    
    failed_basic_fields: int = 0
    failed_basic_numeric: int = 0
    failed_basic_subtotal: int = 0
    failed_basic_junk: int = 0
    
    failed_lark_parse: int = 0
    failed_lark_unexpected_input: int = 0
    failed_lark_unexpected_chars: int = 0
    
    cached_parses: int = 0
    
    failed_samples: List[Dict[str, Any]] = field(default_factory=list)

class ReportParserCrudo:
    """
    Parser crudo con validaci√≥n unificada usando Lark.
    
    Este parser ahora usa la MISMA gram√°tica que APUProcessor para
    pre-validar l√≠neas, eliminando el problema del "falso positivo".
    """
    
    def __init__(self, config, profile=None, lark_grammar: Optional[str] = None):
        """
        Inicializa el parser crudo con capacidad de pre-validaci√≥n Lark.
        
        Args:
            config: Configuraci√≥n del sistema.
            profile: Perfil de parsing (debe ser el MISMO que usa APUProcessor).
            lark_grammar: Gram√°tica Lark para validaci√≥n (opcional, se carga autom√°ticamente).
        """
        self.config = config
        self.profile = profile or {}
        
        # üî• CR√çTICO: Usar el MISMO parser que APUProcessor
        self.lark_parser = self._initialize_lark_parser(lark_grammar)
        
        # Cache de parsing para evitar duplicaci√≥n
        self._parse_cache: Dict[str, Tuple[bool, Any]] = {}
        
        # Estad√≠sticas detalladas
        self.stats = {
            "apus_detected": 0,
            "insumos_extracted": 0,
            "lines_ignored_in_context": 0,
            "junk_lines_skipped": 0,
        }
        
        self.validation_stats = ValidationStats()
        
        # Configuraci√≥n de validaci√≥n
        self.validation_mode = self.config.get("validation_mode", "strict")  # strict | permissive | dual
        self.max_failed_samples = self.config.get("max_failed_samples", 10)
        
        self.raw_records = []
        
        logger.info(
            f"ReportParserCrudo inicializado con validaci√≥n Lark: {self.lark_parser is not None}"
        )
        logger.info(f"Modo de validaci√≥n: {self.validation_mode}")
    
    def _initialize_lark_parser(self, grammar: Optional[str] = None) -> Optional[Lark]:
        """
        Inicializa el parser Lark con la MISMA gram√°tica que usa APUProcessor.
        
        Args:
            grammar: String con la gram√°tica Lark. Si es None, se carga desde archivo.
        
        Returns:
            Instancia de Lark o None si falla la inicializaci√≥n.
        """
        try:
            if grammar is None:
                # Cargar desde el mismo lugar que APUProcessor
                from app.grammars.apu_grammar import APU_GRAMMAR
                grammar = APU_GRAMMAR
            
            parser = Lark(
                grammar,
                start='line',
                parser='lalr',
                # Usar las mismas opciones que APUProcessor
                maybe_placeholders=False,
                cache=True,
            )
            
            logger.info("‚úì Parser Lark inicializado correctamente para pre-validaci√≥n")
            return parser
            
        except Exception as e:
            logger.error(
                f"‚úó Error al inicializar parser Lark: {e}\n"
                f"  Continuando SIN validaci√≥n Lark (modo permisivo forzado)"
            )
            return None
    
    def _validate_with_lark(
        self, 
        line: str, 
        use_cache: bool = True
    ) -> Tuple[bool, Optional[Any], str]:
        """
        Valida una l√≠nea usando el parser Lark.
        
        Esta es la validaci√≥n CR√çTICA que garantiza que solo pasamos l√≠neas
        que APUProcessor podr√° procesar exitosamente.
        
        Args:
            line: L√≠nea a validar.
            use_cache: Si True, usa cache de parsing.
        
        Returns:
            Tupla (es_v√°lida, √°rbol_parsing, raz√≥n_fallo)
        """
        if not self.lark_parser:
            return (True, None, "Lark no disponible - validaci√≥n omitida")
        
        # Verificar cache
        if use_cache and line in self._parse_cache:
            self.validation_stats.cached_parses += 1
            is_valid, tree = self._parse_cache[line]
            return (is_valid, tree, "" if is_valid else "Cached failure")
        
        line_clean = line.strip()
        
        try:
            tree = self.lark_parser.parse(line_clean)
            
            # Cache de √©xito
            if use_cache:
                self._parse_cache[line] = (True, tree)
            
            return (True, tree, "")
        
        except Exception as e:
            # Cache de fallo
            if use_cache:
                self._parse_cache[line] = (False, None)
            
            error_type = type(e).__name__
            error_msg = str(e)
            
            # Clasificar tipo de error
            if "UnexpectedInput" in error_type:
                self.validation_stats.failed_lark_unexpected_input += 1
            elif "UnexpectedCharacters" in error_type:
                self.validation_stats.failed_lark_unexpected_chars += 1
            else:
                self.validation_stats.failed_lark_parse += 1
            
            return (False, None, f"Lark {error_type}: {error_msg}")
    
    def _validate_basic_structure(
        self, 
        line: str, 
        fields: List[str]
    ) -> Tuple[bool, str]:
        """
        Validaci√≥n b√°sica PRE-Lark para filtrado r√°pido.
        
        Esta validaci√≥n es R√ÅPIDA y elimina casos obvios antes de invocar Lark.
        
        Args:
            line: L√≠nea completa.
            fields: Campos separados por ";".
        
        Returns:
            Tupla (es_v√°lida, raz√≥n_si_inv√°lida)
        """
        # Validaci√≥n 1: N√∫mero m√≠nimo de campos
        if len(fields) < 5:
            self.validation_stats.failed_basic_fields += 1
            return (False, f"Insuficientes campos: {len(fields)} < 5")
        
        # Validaci√≥n 2: Campo de descripci√≥n no vac√≠o
        if not fields[0] or not fields[0].strip():
            self.validation_stats.failed_basic_fields += 1
            return (False, "Campo de descripci√≥n vac√≠o")
        
        # Validaci√≥n 3: Detectar subtotales/totales
        line_upper = line.upper()
        subtotal_keywords = [
            "SUBTOTAL", "TOTAL", "SUMA", "SUMATORIA",
            "COSTO DIRECTO", "COSTO TOTAL", "PRECIO TOTAL"
        ]
        
        if any(keyword in line_upper for keyword in subtotal_keywords):
            self.validation_stats.failed_basic_subtotal += 1
            return (False, "L√≠nea de subtotal/total")
        
        # Validaci√≥n 4: L√≠neas decorativas
        if self._is_junk_line(line_upper):
            self.validation_stats.failed_basic_junk += 1
            return (False, "L√≠nea decorativa/separador")
        
        # Validaci√≥n 5: Al menos un campo num√©rico
        has_numeric = False
        numeric_pattern = re.compile(r'\d+[.,]\d+|\d+')
        
        for field in fields[1:]:  # Saltar descripci√≥n
            if numeric_pattern.search(field.strip()):
                has_numeric = True
                break
        
        if not has_numeric:
            self.validation_stats.failed_basic_numeric += 1
            return (False, "Sin campos num√©ricos detectables")
        
        self.validation_stats.passed_basic += 1
        return (True, "")
    
    def _validate_insumo_line(
        self, 
        line: str, 
        fields: List[str]
    ) -> LineValidationResult:
        """
        Validaci√≥n UNIFICADA de una l√≠nea candidata a insumo.
        
        Estrategia de validaci√≥n en dos capas:
        1. Validaci√≥n b√°sica (r√°pida, filtro de casos obvios)
        2. Validaci√≥n Lark (estricta, garantiza compatibilidad)
        
        Args:
            line: La l√≠nea original completa.
            fields: Los campos ya separados por ";".
        
        Returns:
            LineValidationResult con el resultado detallado.
        """
        self.validation_stats.total_evaluated += 1
        
        # CAPA 1: Validaci√≥n b√°sica (filtro r√°pido)
        basic_valid, basic_reason = self._validate_basic_structure(line, fields)
        
        if not basic_valid:
            return LineValidationResult(
                is_valid=False,
                reason=f"B√°sica: {basic_reason}",
                fields_count=len(fields),
                validation_layer="basic"
            )
        
        # CAPA 2: Validaci√≥n Lark (el juez final)
        if self.validation_mode in ["strict", "dual"]:
            lark_valid, lark_tree, lark_reason = self._validate_with_lark(line)
            
            if lark_valid:
                self.validation_stats.passed_lark += 1
                self.validation_stats.passed_both += 1
                
                return LineValidationResult(
                    is_valid=True,
                    reason="Validaci√≥n completa exitosa",
                    fields_count=len(fields),
                    has_numeric_fields=True,
                    validation_layer="both",
                    lark_tree=lark_tree
                )
            else:
                # Fallo en Lark
                if self.validation_mode == "dual":
                    # Modo dual: registrar pero aceptar
                    logger.debug(f"Modo DUAL: L√≠nea pasa b√°sica pero falla Lark: {lark_reason}")
                    return LineValidationResult(
                        is_valid=True,  # Aceptar en modo dual
                        reason=f"Dual mode: {lark_reason}",
                        fields_count=len(fields),
                        has_numeric_fields=True,
                        validation_layer="basic_only"
                    )
                else:
                    # Modo strict: rechazar
                    self._record_failed_sample(line, fields, lark_reason)
                    
                    return LineValidationResult(
                        is_valid=False,
                        reason=f"Lark: {lark_reason}",
                        fields_count=len(fields),
                        has_numeric_fields=True,
                        validation_layer="lark_failed"
                    )
        
        # Modo permisivo: solo validaci√≥n b√°sica
        return LineValidationResult(
            is_valid=True,
            reason="Validaci√≥n b√°sica exitosa (modo permisivo)",
            fields_count=len(fields),
            has_numeric_fields=True,
            validation_layer="basic"
        )
    
    def _record_failed_sample(
        self, 
        line: str, 
        fields: List[str], 
        reason: str
    ):
        """
        Registra una muestra de l√≠nea fallida para an√°lisis posterior.
        
        Args:
            line: L√≠nea que fall√≥.
            fields: Campos de la l√≠nea.
            reason: Raz√≥n del fallo.
        """
        if len(self.validation_stats.failed_samples) < self.max_failed_samples:
            self.validation_stats.failed_samples.append({
                "line": line[:200],  # Truncar si es muy larga
                "fields": fields,
                "fields_count": len(fields),
                "reason": reason,
                "has_empty_fields": any(not f.strip() for f in fields),
                "empty_field_positions": [i for i, f in enumerate(fields) if not f.strip()],
            })
    
    def _parse_by_lines(self, lines: List[str]) -> bool:
        """
        M√°quina de estados con validaci√≥n UNIFICADA usando Lark.
        
        Cambio cr√≠tico: Ahora usa el MISMO parser que APUProcessor para
        garantizar que solo se extraen l√≠neas que ser√°n procesables.
        
        Args:
            lines: La lista de todas las l√≠neas del archivo.
        
        Returns:
            True si se extrajo al menos un insumo v√°lido, False en caso contrario.
        """
        current_apu_context: Optional[APUContext] = None
        current_category = "INDEFINIDO"
        i = 0

        logger.info(f"Iniciando parsing de {len(lines)} l√≠neas con validaci√≥n Lark")

        while i < len(lines):
            line = lines[i].strip()

            if not line:
                i += 1
                continue

            # Estado 1: Buscar encabezado de APU
            is_header_line = "UNIDAD:" in line.upper()
            is_item_line_next = (i + 1) < len(lines) and "ITEM:" in lines[i + 1].upper()

            if is_header_line and is_item_line_next:
                header_line = line
                item_line = lines[i + 1].strip()

                try:
                    apu_desc = header_line.split(";")[0].strip()
                    unit_match = re.search(r"UNIDAD:\s*(\S+)", header_line, re.IGNORECASE)
                    apu_unit = (
                        unit_match.group(1) if unit_match else self.config.default_unit
                    )

                    item_match = re.search(r"ITEM:\s*([\S,]+)", item_line, re.IGNORECASE)
                    apu_code_raw = (
                        item_match.group(1) if item_match else f"UNKNOWN_APU_{i + 1}"
                    )
                    apu_code = clean_apu_code(apu_code_raw)

                    current_apu_context = APUContext(
                        apu_code=apu_code,
                        apu_desc=apu_desc,
                        apu_unit=apu_unit,
                        source_line=i + 1,
                    )
                    current_category = "INDEFINIDO"
                    self.stats["apus_detected"] += 1
                    
                    logger.info(
                        f"‚úì APU detectado [l√≠nea {i + 1}]: {apu_code} - {apu_desc[:50]}"
                    )
                    
                    i += 2
                    continue
                    
                except Exception as e:
                    logger.warning(
                        f"‚úó Fallo al parsear encabezado de APU en l√≠nea {i + 1}: {e}"
                    )
                    current_apu_context = None
                    i += 1
                    continue

            # Estado 2: Procesar l√≠neas dentro de contexto de APU
            if current_apu_context:
                line_upper = line.upper()

                # Detectar categor√≠a
                new_category = self._detect_category(line_upper)
                if new_category:
                    current_category = new_category
                    self.stats[f"category_{current_category}"] += 1
                    logger.debug(f"  ‚Üí Categor√≠a: {current_category}")
                    i += 1
                    continue

                # Detectar ruido
                if self._is_junk_line(line_upper):
                    self.stats["junk_lines_skipped"] += 1
                    i += 1
                    continue

                # üî• VALIDACI√ìN CR√çTICA CON LARK
                fields = [f.strip() for f in line.split(";")]
                validation_result = self._validate_insumo_line(line, fields)
                
                if validation_result.is_valid:
                    # ‚úÖ L√çNEA V√ÅLIDA - Garantizada procesable por APUProcessor
                    record = {
                        "apu_code": current_apu_context.apu_code,
                        "apu_desc": current_apu_context.apu_desc,
                        "apu_unit": current_apu_context.apu_unit,
                        "category": current_category,
                        "insumo_line": line,
                        "source_line": i + 1,
                        "fields_count": validation_result.fields_count,
                        "validation_layer": validation_result.validation_layer,
                        # üî• OPTIMIZACI√ìN: Guardar √°rbol de parsing para reutilizar
                        "_lark_tree": validation_result.lark_tree,
                    }
                    self.raw_records.append(record)
                    self.stats["insumos_extracted"] += 1
                    
                    logger.debug(
                        f"  ‚úì Insumo v√°lido [l√≠nea {i + 1}] [{validation_result.validation_layer}]: "
                        f"{fields[0][:40]}... ({validation_result.fields_count} campos)"
                    )
                else:
                    # ‚ùå L√çNEA RECHAZADA
                    logger.debug(
                        f"  ‚úó Rechazada [l√≠nea {i + 1}]: {validation_result.reason}\n"
                        f"    Contenido: {line[:80]}..."
                    )
                    self.stats["lines_ignored_in_context"] += 1

            i += 1

        # Log de estad√≠sticas finales
        self._log_validation_summary()
        
        return self.stats["insumos_extracted"] > 0
    
    def _log_validation_summary(self):
        """Registra un resumen detallado de la validaci√≥n."""
        total = self.validation_stats.total_evaluated
        valid = self.stats["insumos_extracted"]
        
        logger.info("=" * 80)
        logger.info("üìä RESUMEN DE VALIDACI√ìN CON LARK")
        logger.info("=" * 80)
        logger.info(f"Total l√≠neas evaluadas:              {total}")
        logger.info(f"‚úì Insumos v√°lidos (ambas capas):     {valid} ({valid/total*100:.1f}% si total > 0 else 0)")
        logger.info(f"  - Pasaron validaci√≥n b√°sica:       {self.validation_stats.passed_basic}")
        logger.info(f"  - Pasaron validaci√≥n Lark:         {self.validation_stats.passed_lark}")
        logger.info(f"  - Cache hits:                      {self.validation_stats.cached_parses}")
        logger.info("")
        logger.info("Rechazos por validaci√≥n b√°sica:")
        logger.info(f"  - Campos insuficientes/vac√≠os:     {self.validation_stats.failed_basic_fields}")
        logger.info(f"  - Sin datos num√©ricos:             {self.validation_stats.failed_basic_numeric}")
        logger.info(f"  - Subtotales:                      {self.validation_stats.failed_basic_subtotal}")
        logger.info(f"  - L√≠neas decorativas:              {self.validation_stats.failed_basic_junk}")
        logger.info("")
        logger.info("Rechazos por validaci√≥n Lark:")
        logger.info(f"  - Parse error gen√©rico:            {self.validation_stats.failed_lark_parse}")
        logger.info(f"  - Unexpected input:                {self.validation_stats.failed_lark_unexpected_input}")
        logger.info(f"  - Unexpected characters:           {self.validation_stats.failed_lark_unexpected_chars}")
        logger.info("=" * 80)
        
        # Mostrar muestras de fallos
        if self.validation_stats.failed_samples:
            logger.info("")
            logger.info("üîç MUESTRAS DE L√çNEAS RECHAZADAS POR LARK:")
            logger.info("-" * 80)
            
            for idx, sample in enumerate(self.validation_stats.failed_samples, 1):
                logger.info(f"\nMuestra #{idx}:")
                logger.info(f"  Raz√≥n: {sample['reason']}")
                logger.info(f"  Campos: {sample['fields_count']}")
                logger.info(f"  Campos vac√≠os: {sample['has_empty_fields']}")
                if sample['has_empty_fields']:
                    logger.info(f"  Posiciones vac√≠as: {sample['empty_field_positions']}")
                logger.info(f"  Contenido: {sample['line']}")
                logger.info(f"  Campos: {sample['fields']}")
            
            logger.info("-" * 80)
        
        # Alertas cr√≠ticas
        if valid == 0 and total > 0:
            logger.error(
                "üö® CR√çTICO: 0 insumos v√°lidos con validaci√≥n Lark.\n"
                "   Posibles causas:\n"
                "   1. Gram√°tica Lark incompatible con formato de datos\n"
                "   2. Perfil de configuraci√≥n incorrecto\n"
                "   3. Formato de archivo no esperado\n"
                "   ‚Üí Revise las muestras de l√≠neas rechazadas arriba"
            )
        elif valid < total * 0.5:
            logger.warning(
                f"‚ö†Ô∏è  Tasa de validaci√≥n baja: {valid/total*100:.1f}%\n"
                f"   Considere revisar la gram√°tica o el formato de datos"
            )
    
    def get_parse_cache(self) -> Dict[str, Any]:
        """
        Retorna el cache de parsing para reutilizaci√≥n en APUProcessor.
        
        Returns:
            Diccionario con l√≠neas parseadas y sus √°rboles Lark.
        """
        return {
            line: tree 
            for line, (is_valid, tree) in self._parse_cache.items() 
            if is_valid and tree is not None
        }

### 2Ô∏è‚É£ APUProcessor - Reutilizaci√≥n del Cache de Parsing

# En app/apu_processor.py

class APUProcessor:
    """
    Procesador de APUs con reutilizaci√≥n de cache de parsing.
    """
    
    def __init__(self, config, profile=None, parse_cache: Optional[Dict[str, Any]] = None):
        """
        Inicializa el procesador con cache opcional de parsing.
        
        Args:
            config: Configuraci√≥n del sistema.
            profile: Perfil de parsing.
            parse_cache: Cache de √°rboles Lark pre-parseados (de ReportParserCrudo).
        """
        self.config = config
        self.profile = profile or {}
        self.parser = self._initialize_parser()
        self.keyword_cache = {}
        
        # üî• OPTIMIZACI√ìN: Usar cache de parsing del ReportParserCrudo
        self.parse_cache = parse_cache or {}
        
        self.parsing_stats = ParsingStats()
        self.debug_mode = self.config.get("debug_mode", False)
        
        if self.parse_cache:
            logger.info(
                f"‚úì APUProcessor inicializado con cache de {len(self.parse_cache)} l√≠neas pre-parseadas"
            )
    
    def _process_apu_lines(
        self, lines: List[str], apu_context: Dict[str, Any]
    ) -> List[InsumoProcesado]:
        """
        Procesa l√≠neas de APU con reutilizaci√≥n de cache de parsing.
        
        Si una l√≠nea ya fue parseada por ReportParserCrudo, reutilizamos
        el √°rbol de parsing en lugar de parsear de nuevo.
        
        Args:
            lines: Lista de l√≠neas a procesar.
            apu_context: Contexto del APU.
        
        Returns:
            Lista de insumos procesados.
        """
        results = []
        self.parsing_stats = ParsingStats()
        
        logger.info(
            f"Procesando {len(lines)} l√≠neas para APU: {apu_context.get('apu_code', 'UNKNOWN')}"
        )

        for line_num, line in enumerate(lines, start=1):
            if not line or not line.strip():
                continue
            
            self.parsing_stats.total_lines += 1
            line_clean = line.strip()
            insumo = None

            try:
                if self.parser:
                    # üî• OPTIMIZACI√ìN: Usar cache si est√° disponible
                    tree = None
                    used_cache = False
                    
                    if line_clean in self.parse_cache:
                        tree = self.parse_cache[line_clean]
                        used_cache = True
                        logger.debug(f"  ‚ö° L√≠nea {line_num}: Usando √°rbol Lark del cache")
                    
                    if tree is None:
                        # Parsear normalmente
                        try:
                            tree = self.parser.parse(line_clean)
                        except LarkError as lark_error:
                            # Si falla aqu√≠, significa que ReportParserCrudo dej√≥ pasar algo
                            logger.warning(
                                f"  ‚ö†Ô∏è  L√≠nea {line_num}: Fall√≥ Lark pero pas√≥ validaci√≥n previa\n"
                                f"      Error: {lark_error}\n"
                                f"      Esto NO deber√≠a ocurrir con validaci√≥n unificada"
                            )
                            self.parsing_stats.lark_parse_errors += 1
                            continue
                    
                    # Transformar √°rbol a insumo
                    try:
                        transformer = APUTransformer(
                            apu_context, self.config, self.profile, self.keyword_cache
                        )
                        insumo = transformer.transform(tree)
                        
                        if isinstance(insumo, list):
                            if insumo:
                                insumo = insumo[0]
                                self.parsing_stats.successful_parses += 1
                            else:
                                self.parsing_stats.empty_results += 1
                                insumo = None
                        else:
                            self.parsing_stats.successful_parses += 1
                    
                    except Exception as transform_error:
                        self.parsing_stats.transformer_errors += 1
                        logger.error(
                            f"  ‚úó L√≠nea {line_num}: Error en transformer\n"
                            f"    Error: {transform_error}\n"
                            f"    L√≠nea: {line_clean[:100]}"
                        )
                        continue
                
                # Agregar resultado
                if insumo:
                    insumo.line_number = line_num
                    results.append(insumo)

            except Exception as unexpected_error:
                logger.error(
                    f"  üö® L√≠nea {line_num}: Error inesperado\n"
                    f"    Error: {unexpected_error}\n"
                    f"    L√≠nea: {line_clean}"
                )
                continue

        self._log_parsing_stats(apu_context.get("apu_code", "UNKNOWN"))
        
        return results

### 3Ô∏è‚É£ Orquestador Principal - Integraci√≥n

# En tu script principal o servicio de orquestaci√≥n

def process_apus_with_unified_validation(
    csv_file: str,
    config: Config,
    profile: Dict[str, Any]
) -> List[InsumoProcesado]:
    """
    Procesa APUs con validaci√≥n unificada.
    
    Flujo:
    1. ReportParserCrudo extrae y pre-valida con Lark
    2. APUProcessor reutiliza el parsing para transformar
    
    Args:
        csv_file: Ruta al archivo CSV.
        config: Configuraci√≥n del sistema.
        profile: Perfil de parsing (DEBE SER EL MISMO para ambos).
    
    Returns:
        Lista de insumos procesados.
    """
    from app.grammars.apu_grammar import APU_GRAMMAR
    
    # Paso 1: Inicializar ReportParserCrudo con Lark
    logger.info("=" * 80)
    logger.info("FASE 1: EXTRACCI√ìN Y PRE-VALIDACI√ìN CON LARK")
    logger.info("=" * 80)
    
    parser_crudo = ReportParserCrudo(
        config=config,
        profile=profile,
        lark_grammar=APU_GRAMMAR  # MISMA gram√°tica
    )
    
    # Paso 2: Parsear archivo
    with open(csv_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    success = parser_crudo._parse_by_lines(lines)
    
    if not success:
        logger.error("No se extrajeron registros v√°lidos")
        return []
    
    raw_records = parser_crudo.raw_records
    parse_cache = parser_crudo.get_parse_cache()
    
    logger.info(f"\n‚úì Fase 1 completa: {len(raw_records)} registros v√°lidos extra√≠dos")
    logger.info(f"‚úì Cache de parsing: {len(parse_cache)} √°rboles Lark guardados\n")
    
    # Paso 3: Procesar con APUProcessor
    logger.info("=" * 80)
    logger.info("FASE 2: TRANSFORMACI√ìN CON APUPROCESSOR")
    logger.info("=" * 80)
    
    apu_processor = APUProcessor(
        config=config,
        profile=profile,  # MISMO perfil
        parse_cache=parse_cache  # Reutilizar parsing
    )
    
    # Agrupar por APU
    apus_agrupados = {}
    for record in raw_records:
        apu_code = record["apu_code"]
        if apu_code not in apus_agrupados:
            apus_agrupados[apu_code] = {
                "context": {
                    "apu_code": record["apu_code"],
                    "apu_desc": record["apu_desc"],
                    "apu_unit": record["apu_unit"],
                },
                "lines": []
            }
        apus_agrupados[apu_code]["lines"].append(record["insumo_line"])
    
    # Procesar cada APU
    all_insumos = []
    for apu_code, data in apus_agrupados.items():
        insumos = apu_processor._process_apu_lines(
            data["lines"],
            data["context"]
        )
        all_insumos.extend(insumos)
    
    logger.info("\n" + "=" * 80)
    logger.info(f"‚úì PROCESO COMPLETO: {len(all_insumos)} insumos procesados")
    logger.info("=" * 80)
    
    return all_insumos

### 4Ô∏è‚É£ Herramienta de Diagn√≥stico de Gram√°tica

# En app/utils/grammar_diagnostics.py

def diagnose_grammar_mismatches(
    csv_file: str,
    grammar: str,
    profile: Dict[str, Any],
    output_file: str = "grammar_diagnosis.txt"
):
    """
    Diagn√≥stica l√≠neas que fallan parsing Lark para ajustar gram√°tica.
    
    Args:
        csv_file: Archivo a analizar.
        grammar: Gram√°tica Lark.
        profile: Perfil de parsing.
        output_file: Archivo de salida.
    """
    from lark import Lark
    from lark.exceptions import LarkError
    
    parser = Lark(grammar, start='line', parser='lalr')
    
    with open(csv_file, 'r', encoding='utf-8') as f:
        lines = [l.strip() for l in f.readlines() if l.strip()]
    
    failed_lines = []
    
    for idx, line in enumerate(lines, 1):
        # Saltar encabezados
        if "UNIDAD:" in line or "ITEM:" in line:
            continue
        
        # Intentar parsing
        try:
            parser.parse(line)
        except LarkError as e:
            failed_lines.append({
                "line_num": idx,
                "line": line,
                "error": str(e),
                "fields": line.split(";"),
                "fields_count": len(line.split(";")),
            })
    
    # Generar reporte
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=" * 100 + "\n")
        f.write("DIAGN√ìSTICO DE INCOMPATIBILIDAD GRAM√ÅTICA-DATOS\n")
        f.write("=" * 100 + "\n\n")
        
        f.write(f"Total l√≠neas analizadas: {len(lines)}\n")
        f.write(f"L√≠neas que fallan Lark: {len(failed_lines)}\n")
        f.write(f"Tasa de fallo: {len(failed_lines)/len(lines)*100:.2f}%\n\n")
        
        # An√°lisis de patrones
        empty_field_count = sum(
            1 for fl in failed_lines 
            if any(not f.strip() for f in fl["fields"])
        )
        
        f.write(f"L√≠neas con campos vac√≠os: {empty_field_count}\n\n")
        
        f.write("MUESTRAS DE L√çNEAS FALLIDAS:\n")
        f.write("-" * 100 + "\n")
        
        for fl in failed_lines[:20]:  # Primeras 20
            f.write(f"\nL√≠nea {fl['line_num']}:\n")
            f.write(f"  Error: {fl['error']}\n")
            f.write(f"  Campos: {fl['fields_count']}\n")
            f.write(f"  Contenido: {fl['line']}\n")
            f.write(f"  Campos: {fl['fields']}\n")
            
            # Detectar campos vac√≠os
            empty_positions = [
                i for i, f in enumerate(fl["fields"]) 
                if not f.strip()
            ]
            if empty_positions:
                f.write(f"  ‚ö†Ô∏è  Campos vac√≠os en posiciones: {empty_positions}\n")
    
    logger.info(f"‚úì Diagn√≥stico guardado en: {output_file}")
    return failed_lines

‚úÖ RESULTADOS ESPERADOS

Con esta implementaci√≥n:

    Eliminaci√≥n del falso positivo: Solo l√≠neas que Lark puede parsear pasan la validaci√≥n
    Performance optimizada: Cache de parsing evita parsear dos veces
    Diagn√≥stico preciso: Sabr√°s EXACTAMENTE qu√© l√≠neas fallan y por qu√©
    Trazabilidad: Estad√≠sticas detalladas en cada capa
    Flexibilidad: Modos strict/permissive/dual para diferentes escenarios