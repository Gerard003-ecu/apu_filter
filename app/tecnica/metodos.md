# IngenierÃ­a Bajo el CapÃ³: La GarantÃ­a de Estabilidad

En APU Filter, la tecnologÃ­a no es un adorno; es la estructura que sostiene el negocio. A continuaciÃ³n, detallamos cÃ³mo nuestros "Expertos Digitales" utilizan ingenierÃ­a avanzada para resolver problemas cotidianos de la construcciÃ³n.

---

## 1. El Estabilizador: Control de Flujo y Resiliencia
**Componente:** `app/flux_condenser.py`

El mayor enemigo de la gestiÃ³n de datos masivos es la inconsistencia y los picos de carga. Un sistema tradicional se bloquea (crash) cuando intenta procesar mÃ¡s de lo que puede masticar. Nosotros implementamos un sistema de **IngenierÃ­a de Confiabilidad (SRE)** basado en principios de **Backpressure (ContrapresiÃ³n)** y **Rate Limiting Adaptativo**.

### La LÃ³gica: Estabilidad ante el Caos
Imagine una autopista inteligente. Si hay demasiados carros (datos), los semÃ¡foros de entrada (el sistema) ajustan sus tiempos automÃ¡ticamente para evitar un trancÃ³n total.
El **Data Flux Condenser** gestiona la tasa de ingestiÃ³n de datos para asegurar que el servidor siempre opere en su zona Ã³ptima de rendimiento.

1.  **PresiÃ³n de Datos (Input Pressure):** Mide la cantidad de registros esperando ser procesados.
2.  **Inercia de Calidad (Quality Inertia):** Mide quÃ© tan "limpios" estÃ¡n los datos. Datos limpios fluyen rÃ¡pido; datos sucios requieren mÃ¡s tiempo.
3.  **FricciÃ³n Operativa (System Friction):** El esfuerzo computacional real que toma procesar el lote actual.

### El Cerebro del Estabilizador (Controlador PID)
Para gestionar estas variables, utilizamos un algoritmo de control **Proporcional-Integral-Derivativo (PID)**, el mismo tipo de lÃ³gica usada en controles industriales de temperatura o velocidad crucero de vehÃ­culos.

*   **Si los datos son complejos (Alta FricciÃ³n):** El sistema reduce automÃ¡ticamente el tamaÃ±o del lote (*Batch Size*) para procesar con precisiÃ³n quirÃºrgica sin saturar la memoria.
*   **Si los datos fluyen bien:** El sistema acelera, aumentando el tamaÃ±o del lote para maximizar el rendimiento.
*   **Resultado:** Un **Flujo Laminar** constante. El sistema nunca se detiene, solo ajusta su velocidad para sobrevivir.

> **Nota TÃ©cnica (InspiraciÃ³n Interna):** Bajo el capÃ³, modelamos estas mÃ©tricas usando ecuaciones anÃ¡logas a un circuito elÃ©ctrico RLC (Resistencia-Inductancia-Capacitancia) para calcular la "EnergÃ­a" del sistema, lo que nos permite predecir saturaciones antes de que ocurran.

#### âš™ï¸ Motor de FÃ­sica de Flujo (Energy-Based RLC)
A diferencia de los sistemas tradicionales que solo miden mÃ©tricas discretas como el uso de memoria o CPU, nuestro sistema modela el flujo de datos como un sistema fÃ­sico. No solo medimos el "voltaje" (carga), sino el **Balance EnergÃ©tico** total.

*   **EnergÃ­a Potencial ($E_p$):** La presiÃ³n acumulada por el volumen de datos en cola.
*   **EnergÃ­a CinÃ©tica ($E_k$):** La inercia del procesamiento de calidad.
*   **Potencia Disipada ($P_{diss}$):** La energÃ­a perdida por fricciÃ³n (procesamiento de datos basura).

Esta perspectiva termodinÃ¡mica nos permite detectar "sobrecalentamientos" lÃ³gicos antes de que se conviertan en fallos del sistema.

#### ðŸ§  Controlador PID Discreto con Anti-windup
El cerebro que ajusta el flujo no es un simple `if/else`. Es un controlador PID completo que ajusta el tamaÃ±o del lote en tiempo real.
*   **Anti-windup:** Implementamos lÃ³gica avanzada para evitar que el tÃ©rmino integral se acumule infinitamente cuando el sistema estÃ¡ saturado, garantizando una recuperaciÃ³n rÃ¡pida despuÃ©s de picos de carga.
*   **Filtrado de Ruido:** El controlador utiliza medias mÃ³viles exponenciales para ignorar fluctuaciones transitorias y responder solo a tendencias reales.

---

## 2. El Estratega: EstimaciÃ³n de "Caja Blanca"
**Componente:** `app/estimator.py`

En ingenierÃ­a, la confianza lo es todo. Un ingeniero no aceptarÃ¡ un precio solo porque "la mÃ¡quina lo dijo". Por eso, nuestro Estratega opera bajo una filosofÃ­a de **Transparencia Radical**. No es una Caja Negra; es una Caja de Cristal.

### Evidencia, no Magia
Cuando el sistema sugiere un costo, entrega un reporte forense de su decisiÃ³n:

#### A. BÃºsqueda SemÃ¡ntica (El Concepto)
El sistema entiende que *"Muro en ladrillo tolete"* y *"MamposterÃ­a de arcilla"* son lo mismo, aunque no compartan palabras.
*   **TecnologÃ­a:** Sentence-Transformers + FAISS Vector Database.
*   **Output al Usuario:** "EncontrÃ© este Ã­tem con una **Similitud Conceptual del 94%**".

#### B. BÃºsqueda por Palabras Clave (El Detalle)
Si la semÃ¡ntica falla, buscamos coincidencias exactas.
*   **Output al Usuario:** "EncontrÃ© este Ã­tem porque coincide en 3 de 4 palabras clave".

#### C. SimulaciÃ³n de Riesgo (El Futuro)
Usamos el MÃ©todo de Monte Carlo para proyectar 1,000 escenarios posibles de variaciÃ³n de precios.
*   **Output al Usuario:** "El precio base es $100, pero hay un **35% de probabilidad** de que suba a $115 debido a la volatilidad histÃ³rica".

---

## 3. El Director: OrquestaciÃ³n del Pipeline
**Componente:** `app/pipeline_director.py` (Anteriormente `procesador_csv.py`)

Para evitar el "cÃ³digo espagueti", hemos centralizado la lÃ³gica de control. El Director no procesa datos; Ã©l da las Ã³rdenes.

## 4. OrquestaciÃ³n Granular: El Pipeline como MÃ¡quina de Estados

A diferencia de los scripts lineales tradicionales, el `PipelineDirector` implementa una arquitectura de **EjecuciÃ³n AtÃ³mica con Persistencia de Estado**.

*   **Atomicidad:** Cada paso (ej. `CalculateCosts`) es una unidad discreta que recibe un contexto, lo procesa y retorna un nuevo estado.
*   **Persistencia:** Entre pasos, el "Vector de Estado" se serializa (Redis/Pickle). Esto permite al Agente intervenir, reintentar un paso especÃ­fico o pausar el flujo sin perder datos.
*   **MÃ©todo:** `run_single_step(step_name)` permite la ejecuciÃ³n quirÃºrgica de procesos.

## 5. Motor de Inteligencia Financiera (Financial Engine)

Superando la estimaciÃ³n de costos determinista, este mÃ³dulo inyecta variables estocÃ¡sticas de mercado:

*   **WACC (Weighted Average Cost of Capital):** Descuenta los flujos de caja futuros basÃ¡ndose en la estructura de capital y riesgo paÃ­s.
*   **VaR (Value at Risk):** Utiliza simulaciones de Monte Carlo para determinar la pÃ©rdida mÃ¡xima probable con un 95% de confianza.
*   **Opciones Reales:** Valora la flexibilidad estratÃ©gica (ej. la opciÃ³n de esperar o expandir) utilizando modelos binomiales, transformando la incertidumbre en un valor cuantificable.

#### Mecanismos de Defensa (SRE)
Esta no es una metÃ¡fora decorativa. Utilizamos lÃ³gica de sistemas dinÃ¡micos para proteger la infraestructura:

*   **Load Shedding (Disyuntor TÃ©rmico):** Si la "fricciÃ³n" (error rate o complejidad) supera un umbral de seguridad (> 50W de potencia disipada equivalente), el sistema activa un freno de emergencia, reduciendo drÃ¡sticamente la carga para "enfriar" el proceso.
*   **Anti-Windup:** Evita que el controlador PID se quede "pegado" tratando de corregir errores acumulados pasados, manteniendo la respuesta Ã¡gil ante cambios presentes.
*   **RecuperaciÃ³n Parcial:** Si un lote de datos estÃ¡ corrupto, el sistema lo aÃ­sla y continÃºa con el resto del archivo, en lugar de fallar todo el proceso.

---

## 6. MÃ©tricas de ConcentraciÃ³n LogÃ­stica (El Alquimista)

Para garantizar la viabilidad logÃ­stica, el sistema aplica mÃ©tricas econÃ³micas clÃ¡sicas al flujo de materiales.

### MÃ©tricas de ConcentraciÃ³n LogÃ­stica

*   **Ãndice de Gini ($G$):** Mide la desigualdad en la distribuciÃ³n del presupuesto.
    *   $G \approx 1$: Pocos materiales consumen todo el presupuesto (Alto Riesgo de Abastecimiento).
    *   $G \approx 0$: Costo distribuido uniformemente.
*   **Ratio de Pareto:** Porcentaje de Ã­tems que constituyen el 80% del costo total. Permite enfocar la gestiÃ³n de compras en los insumos crÃ­ticos.

#### âš™ï¸ Nivel 1: Motor de FÃ­sica RLC (El Sensor)
El sistema evoluciona mÃ¡s allÃ¡ de mÃ©tricas simples hacia un **Modelo EnergÃ©tico Escalar**. En lugar de monitorear solo voltaje o corriente, unificamos las unidades bajo un lenguaje comÃºn: La EnergÃ­a (Julios).

1.  **EnergÃ­a Potencial ($E_c = \frac{1}{2}CV^2$) - PresiÃ³n de Datos:**
    *   Representa la "carga de trabajo" acumulada por el volumen de registros.
    *   Calcula la presiÃ³n que ejerce el lote de datos sobre el sistema.
2.  **EnergÃ­a CinÃ©tica ($E_l = \frac{1}{2}LI^2$) - Inercia de Calidad:**
    *   Representa el momento o "inercia" de la calidad del flujo.
    *   Un flujo de alta calidad ($I \approx 1.0$) tiene una inercia fuerte que resiste perturbaciones, dificultando que errores menores desestabilicen el proceso.
3.  **Potencia Disipada ($P = I_{ruido}^2 R$) - Calor/FricciÃ³n:**
    *   **TermodinÃ¡mica del Software:** Calcula el "calor" generado por la resistencia dinÃ¡mica de los datos sucios.
    *   Si el sistema gasta demasiada energÃ­a procesando basura (ruido), se genera sobrecalentamiento lÃ³gico.

#### ðŸ§  Nivel 2: Controlador PI Discreto (El Cerebro)
Sobre la capa fÃ­sica, opera un **Lazo de Control Cerrado (Feedback Loop)** que ajusta el comportamiento del sistema en tiempo real, ahora con protecciÃ³n tÃ©rmica:

*   **Algoritmo:** Controlador **Proporcional-Integral (PI)** discreto.
*   **Setpoint:** Mantiene una saturaciÃ³n estable (Flujo Laminar).
*   **Variable de Control:** El tamaÃ±o del lote de procesamiento (*Batch Size*).
*   **Disyuntor TÃ©rmico (Nuevo):**
    *   AdemÃ¡s del PID, el sistema implementa un "Diodo de Rueda Libre" tÃ©rmico.
    *   Si la **Potencia Disipada** supera un umbral crÃ­tico (> 50W), el sistema activa un freno de emergencia, reduciendo drÃ¡sticamente el tamaÃ±o del lote independientemente de la saturaciÃ³n, para "enfriar" el proceso y evitar colapsos por calidad de datos.

**Resultado:** Un sistema bi-mimÃ©tico que no solo adapta su velocidad, sino que tambiÃ©n gestiona su "temperatura" operativa para garantizar una estabilidad del 100% bajo cualquier condiciÃ³n.

#### ðŸ›¡ï¸ Resiliencia y RecuperaciÃ³n
El sistema implementa mecanismos de defensa avanzados:
*   **Anti-Windup PID:** Previene la saturaciÃ³n del controlador ante cargas sostenidas.
*   **RecuperaciÃ³n Parcial:** Capacidad de aislar lotes corruptos y continuar el procesamiento del resto del archivo.
*   **ProtecciÃ³n TÃ©rmica:** Freno de emergencia automÃ¡tico si la disipaciÃ³n de energÃ­a (fricciÃ³n de datos) supera los umbrales de seguridad.

### MÃ©trica de Estabilidad Piramidal (`pyramid_stability`)

El sistema calcula un Ã­ndice de robustez arquitectÃ³nica del presupuesto utilizando la siguiente relaciÃ³n:

$$ \Psi = \frac{N_{insumos}}{N_{apus}} \times \frac{1}{\rho} $$

Donde:
*   $N_{insumos}$: Cantidad de recursos Ãºnicos (Amplitud de base).
*   $N_{apus}$: Cantidad de actividades (Complejidad tÃ¡ctica).
*   $\rho$: Densidad del grafo (Interconectividad).

**InterpretaciÃ³n:**
*   **$\Psi > 10$ (SÃ³lida):** Base ancha. El proyecto tiene recursos diversificados y dependencias claras.
*   **$\Psi < 1$ (Invertida):** Base estrecha. El proyecto depende crÃ­ticamente de muy pocos recursos altamente conectados. Un fallo en el suministro de un insumo clave podrÃ­a detener mÃºltiples frentes de obra.

---

## 4. El Agente: OrquestaciÃ³n AutÃ³noma
**Componente:** `agent/orchestrator.py`

La evoluciÃ³n de APU Filter introduce capacidades agÃ©nticas para coordinar tareas complejas de manera autÃ³noma. El Orquestador actÃºa como un sistema nervioso central que conecta los microservicios y asegura la coherencia del flujo de trabajo.

### Responsabilidades Clave:
*   **CoordinaciÃ³n de Tareas:** Descompone objetivos de alto nivel en pasos ejecutables.
*   **Monitoreo de Estado:** Supervisa la salud de los procesos en tiempo real.
*   **Toma de Decisiones:** Ajusta dinÃ¡micamente la ruta de ejecuciÃ³n basÃ¡ndose en la retroalimentaciÃ³n del sistema (feedback loops).

---

## TecnologÃ­as Utilizadas

La plataforma estÃ¡ construida sobre una pila de tecnologÃ­as modernas de alto rendimiento:

- **Backend:** **Flask** para la API web.
- **Inteligencia Artificial y Agentes:**
    - **Microservicios AgÃ©nticos:** Arquitectura modular para tareas autÃ³nomas.
- **AnÃ¡lisis de Datos y ML:**
    - **Pandas:** Utilizado como la base para la manipulaciÃ³n de datos.
    - **Sentence-Transformers:** Para la generaciÃ³n de embeddings de texto que potencian la bÃºsqueda semÃ¡ntica.
    - **FAISS (Facebook AI Similarity Search):** Para la bÃºsqueda vectorial de alta velocidad de los APUs mÃ¡s similares.
- **Parsing y Estructura de Datos:**
    - **Lark:** Para el parsing robusto de la gramÃ¡tica de los insumos en los archivos de APU.
    - **Dataclasses:** Para la creaciÃ³n de esquemas de datos (`schemas.py`) que garantizan la consistencia y validaciÃ³n.
- **Entorno y Dependencias:**
    - **Conda:** Para gestionar el entorno y las dependencias complejas con componentes binarios (ej. `faiss-cpu`).
- **Redis:** Para la gestiÃ³n de sesiones de usuario, garantizando la persistencia de datos entre solicitudes.
    - **uv & pip:** Para la gestiÃ³n rÃ¡pida y eficiente del resto de las dependencias de Python.
- **Calidad de CÃ³digo y Pruebas:**
    - **Pytest:** Para una suite de pruebas exhaustiva que cubre desde unidades hasta la integraciÃ³n completa.
    - **Ruff:** Para el formateo y linting del cÃ³digo, asegurando un estilo consistente y de alta calidad.

## InstalaciÃ³n y Uso

Esta secciÃ³n describe cÃ³mo configurar el entorno tÃ©cnico para su equipo de TI, garantizando una implementaciÃ³n robusta y segura.

### La Arquitectura de la InstalaciÃ³n: Una AnalogÃ­a de Engranajes

Para entender por quÃ© seguimos un orden de instalaciÃ³n especÃ­fico, podemos visualizar nuestro entorno como una caja de cambios de precisiÃ³n compuesta por tres engranajes diferentes, cada uno con una funciÃ³n especializada.

1.  **Conda: El Engranaje Principal y de Potencia (El Engranaje Grande)**
    *   **Rol:** Mueve las piezas mÃ¡s pesadas y complejas que no son de Python puro y dependen del sistema operativo (ej. librerÃ­as C++).
    *   **CaracterÃ­stica:** Es potente y fiable, diseÃ±ado para buscar e instalar paquetes pre-compilados que encajan perfectamente con la arquitectura de la mÃ¡quina.
    *   **En APU Filter:** Su Ãºnica tarea es instalar `faiss-cpu`, una librerÃ­a con dependencias complejas a nivel de sistema.

2.  **Pip (con `--index-url`): La Herramienta Especializada**
    *   **Rol:** Se utiliza para una pieza crÃ­tica que necesita una instalaciÃ³n muy especÃ­fica desde un repositorio exclusivo.
    *   **CaracterÃ­stica:** Comunica una intenciÃ³n precisa: "Ve Ãºnicamente a este almacÃ©n especÃ­fico (el de PyTorch para CPU) y trae la pieza exacta que encuentres allÃ­".
    *   **En APU Filter:** Su Ãºnica tarea es instalar la versiÃ³n `torch` optimizada exclusivamente para CPU, evitando la descarga de las pesadas librerÃ­as de CUDA.

3.  **uv/pip: El Engranaje de Alta Velocidad y PrecisiÃ³n (El Engranaje PequeÃ±o)**
    *   **Rol:** Ensambla todos los componentes de la aplicaciÃ³n que son de Python puro, comunicÃ¡ndose directamente con el ecosistema de Python (PyPI).
    *   **CaracterÃ­stica:** Es ultrarrÃ¡pido y Ã¡gil, ideal para manejar dependencias estÃ¡ndar de Python, pero no tiene la fuerza para gestionar las piezas pesadas que maneja Conda.
    *   **En APU Filter:** Su tarea es instalar todo lo demÃ¡s desde `requirements.txt` de forma eficiente.

### Pasos Detallados de InstalaciÃ³n

**Requisito Previo:** AsegÃºrese de tener instalado Miniconda o Anaconda. Puede descargarlo desde [aquÃ­](https://www.anaconda.com/products/distribution).

**Paso 1: Crear el Entorno Base (Conda)**
Cree un nuevo entorno Conda llamado `apu_filter_env` con Python 3.10, la versiÃ³n sobre la cual se construirÃ¡n los demÃ¡s componentes.
```bash
conda create --name apu_filter_env python=3.10
```

**Paso 2: Activar el Entorno**
Active el entorno reciÃ©n creado. **Debe hacer esto cada vez que trabaje en el proyecto.**
```bash
conda activate apu_filter_env
```

**Paso 3: Instalar Componentes Pesados (Conda y Pip Especializado)**
Instale los "engranajes" principales que requieren compilaciones y dependencias complejas.

*   **Instalar `faiss-cpu` (El Engranaje de Potencia):**
    ```bash
    conda install -c pytorch faiss-cpu
    ```

*   **Instalar `torch` (La Herramienta Especializada):**
    ```bash
    pip install torch --index-url https://download.pytorch.org/whl/cpu
    ```

**Paso 4: Instalar Dependencias de la AplicaciÃ³n (uv)**
Instale todas las demÃ¡s dependencias de Python puro con el "engranaje de alta velocidad".
```bash
uv pip install -r requirements.txt
uv pip install -r requirements-dev.txt
```

**Paso 5: Instalar y Configurar el Servidor de Sesiones (Redis)**
Para garantizar la persistencia de los datos del usuario entre solicitudes, la aplicaciÃ³n utiliza Redis.

*   **Instalar `redis` (El Engranaje de Estabilidad):**
    Es crucial instalar Redis a travÃ©s del canal `conda-forge` para asegurar la compatibilidad entre diferentes sistemas operativos, incluyendo macOS y Linux.
    ```bash
    conda install -c conda-forge redis
    ```

**Nota Importante:** El archivo `requirements.txt` no debe contener `faiss-cpu` ni `torch`. Si alguna vez necesita regenerar este archivo (ej. usando `uv pip compile requirements.in`), asegÃºrese de excluir estas dos librerÃ­as para evitar conflictos de instalaciÃ³n.

## Flujo de Trabajo del Proyecto

El ciclo de vida del desarrollo y uso de la aplicaciÃ³n sigue estos pasos:

1.  **ConfiguraciÃ³n:** La lÃ³gica de negocio (mapeo de columnas, umbrales, reglas del estimador) se gestiona en `app/config.json`.
2.  **Pre-procesamiento:** Si los datos de los APUs cambian, debe regenerar los embeddings ejecutando:
    ```bash
    python scripts/generate_embeddings.py --input path/to/processed_apus.json
    ```
3.  **EjecuciÃ³n de la AplicaciÃ³n:** Con el entorno activado, inicie el servidor Flask:
    ```bash
    python -m flask run --port=5002
    ```
4.  **ValidaciÃ³n y Pruebas:** Para verificar la integridad del cÃ³digo, ejecute la suite de pruebas completa:
    ```bash
    pytest -vv
    ```

## Estructura del Directorio

El proyecto estÃ¡ organizado con una clara separaciÃ³n de responsabilidades para facilitar la mantenibilidad y la escalabilidad.

```
apu_filter/
â”‚
â”œâ”€â”€ agent/                      # MÃ³dulo de Inteligencia Artificial y Agentes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ orchestrator.py         # Orquestador autÃ³nomo de microservicios
â”‚
â”œâ”€â”€ app/                        # LÃ³gica principal de la aplicaciÃ³n Flask
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                  # Factory de la app, endpoints API y carga de modelos
â”‚   â”œâ”€â”€ pipeline_director.py    # Orquestador del pipeline de procesamiento de datos
â”‚   â”œâ”€â”€ report_parser_crudo.py  # Parser especializado para archivos de APU semi-estructurados
â”‚   â”œâ”€â”€ apu_processor.py        # Motor de transformaciÃ³n que aplica lÃ³gica de negocio a los datos parseados
â”‚   â”œâ”€â”€ estimator.py            # LÃ³gica de estimaciÃ³n con bÃºsqueda semÃ¡ntica y por keywords
â”‚   â”œâ”€â”€ flux_condenser.py       # LÃ³gica del condensador de flujos de datos
â”‚   â”œâ”€â”€ data_loader.py          # Capa de abstracciÃ³n para leer datos (.csv, .xlsx, .pdf)
â”‚   â”œâ”€â”€ schemas.py              # DefiniciÃ³n de los esquemas de datos (dataclasses)
â”‚   â”œâ”€â”€ utils.py                # Funciones de utilidad generales (normalizaciÃ³n, parsing, etc.)
â”‚   â”œâ”€â”€ config.json             # Archivo de configuraciÃ³n de la lÃ³gica de negocio
â”‚   â””â”€â”€ embeddings/             # Directorio para los artefactos de ML (Ã­ndice FAISS, mapeo)
â”‚
â”œâ”€â”€ data/                       # Datos de entrada y resultados intermedmedios
â”‚   â”œâ”€â”€ presupuesto_clean.csv   # VersiÃ³n sanitizada del presupuesto, lista para el pipeline
â”‚   â”œâ”€â”€ insumos_clean.csv       # VersiÃ³n sanitizada de insumos, lista para el pipeline
â”‚   â””â”€â”€ apus_clean.csv          # VersiÃ³n sanitizada de apus, lista para el pipeline  
â”‚
â”œâ”€â”€ data_dirty/                 # Datos crudos y sin procesar
â”‚   â”œâ”€â”€ presupuesto.csv         # Archivo de presupuesto original con posibles errores
â”‚   â”œâ”€â”€ insumos.csv             # Archivo de insumos original con posibles errores
â”‚   â””â”€â”€ apus.csv                # Archivo de apus original con posibles errores  
â”‚
â”œâ”€â”€ models/                     # MÃ³dulos de lÃ³gica de negocio y anÃ¡lisis avanzado
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ probability_models.py   # Motor de simulaciÃ³n Monte Carlo para anÃ¡lisis de riesgos
â”‚
â”œâ”€â”€ scripts/                    # Herramientas de lÃ­nea de comandos para desarrolladores
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ generate_embeddings.py       # Script para generar el Ã­ndice de bÃºsqueda semÃ¡ntica
â”‚   â”œâ”€â”€ diagnose_apus_file.py        # Herramienta para analizar formatos de archivo de APU
â”‚   â”œâ”€â”€ diagnose_insumos_file.py     # Herramienta para analizar formatos de archivo de insumos
â”‚   â”œâ”€â”€ diagnose_presupuesto_file.py # Herramienta para analizar formatos de archivo de presupuesto
â”‚   â””â”€â”€ clean_csv.py                 # Herramienta para limpiar caracteres sucios y crear un archivo csv limpio 
â”‚
â”œâ”€â”€ tests/                      # Suite de pruebas completa del proyecto
â”‚   â”œâ”€â”€ test_app.py             # Pruebas de integraciÃ³n para los endpoints de la API
â”‚   â”œâ”€â”€ test_pipeline_director.py  # Pruebas para el orquestador del pipeline
â”‚   â”œâ”€â”€ test_apu_processor.py   # Pruebas para el motor de transformaciÃ³n
â”‚   â”œâ”€â”€ test_estimator.py       # Pruebas para la lÃ³gica de estimaciÃ³n
â”‚   â”œâ”€â”€ test_data_loader.py     # Pruebas para la capa de carga de datos
â”‚   â”œâ”€â”€ test_orchestrator.py    # Pruebas para el orquestador agÃ©ntico
â”‚   â””â”€â”€ test_data.py            # Datos de prueba centralizados
â”‚
â”œâ”€â”€ templates/                  # Plantillas HTML para la interfaz (si aplica)
â”œâ”€â”€ uploads/                    # Directorio temporal para archivos subidos
â”‚
â”œâ”€â”€ requirements.in             # Archivo fuente para definir dependencias
â”œâ”€â”€ requirements.txt            # Archivo de dependencias "congelado" generado por uv
â””â”€â”€ pyproject.toml              # Archivo de configuraciÃ³n del proyecto Python
```
