### propuesta 1

import logging
import textwrap
from dataclasses import asdict, dataclass, field
from typing import Any, Dict, List, Optional, Tuple

import networkx as nx
import pandas as pd

from app.constants import ColumnNames
from app.telemetry import TelemetryContext

logger = logging.getLogger(__name__)


@dataclass(frozen=True)
class TopologicalMetrics:
    """
    M√©tricas Topol√≥gicas Invariantes para el Grafo de Negocio.

    Attributes:
        beta_0 (int): N√∫mero de componentes conexas (fragmentaci√≥n).
        beta_1 (int): N√∫mero de ciclos independientes (complejidad de bucles).
        euler_characteristic (int): Caracter√≠stica de Euler (beta_0 - beta_1).
        euler_efficiency (float): Eficiencia topol√≥gica normalizada (0.0 - 1.0).
    """

    beta_0: int
    beta_1: int
    euler_characteristic: int
    euler_efficiency: float = 1.0

    @property
    def is_connected(self) -> bool:
        """Determina si el grafo est√° conectado (tiene una sola componente)."""
        return self.beta_0 == 1

    @property
    def is_simply_connected(self) -> bool:
        """Determina si el grafo es simplemente conexo (conexo y sin ciclos)."""
        return self.beta_0 == 1 and self.beta_1 == 0


class BusinessTopologicalAnalyzer:
    """Analizador de topolog√≠a de negocio V2 con Telemetr√≠a Granular."""

    def __init__(self, telemetry: Optional[TelemetryContext] = None, max_cycles: int = 100):
        """
        Inicializa el analizador topol√≥gico.

        Args:
            telemetry (Optional[TelemetryContext]): Contexto para registrar m√©tricas.
            max_cycles (int): N√∫mero m√°ximo de ciclos a detectar antes de truncar.
        """
        self.telemetry = telemetry
        self.max_cycles = max_cycles
        self.logger = logging.getLogger(self.__class__.__name__)

    def calculate_euler_efficiency(self, graph: nx.DiGraph) -> float:
        """
        Calcula la Eficiencia de Euler normalizada mediante decaimiento exponencial.

        La eficiencia mide la proximidad a una estructura arb√≥rica (ideal para jerarqu√≠as).
        F√≥rmula: Efficiency = exp(-excess_edges / V) donde excess_edges = max(0, E - (V - 1))
        Esta formulaci√≥n garantiza:
        - Eficiencia = 1.0 para √°rboles perfectos (exceso = 0)
        - Decaimiento suave a medida que aumenta la redundancia
        - L√≠mite inferior asint√≥tico a 0 para grafos densos

        Returns:
            float: Score entre 0.0 (caos/sobrecarga) y 1.0 (orden/jerarqu√≠a pura).
        """
        n_nodes = graph.number_of_nodes()
        n_edges = graph.number_of_edges()

        if n_nodes <= 1:
            return 1.0

        # √Årbol m√≠nimo conexo requiere V-1 aristas
        min_edges = n_nodes - 1
        excess_edges = max(0, n_edges - min_edges)

        # Decaimiento exponencial normalizado
        efficiency = np.exp(-excess_edges / n_nodes) if n_nodes > 0 else 1.0
        return round(efficiency, 4)

    def calculate_betti_numbers(self, graph: nx.DiGraph) -> TopologicalMetrics:
        """
        Calcula m√©tricas topol√≥gicas invariantes (N√∫meros de Betti) con validaci√≥n rigurosa.

        Teor√≠a: Para un grafo G (1-complejo simplicial):
        - Œ≤‚ÇÄ = n√∫mero de componentes conexas = dim(H‚ÇÄ(G))
        - Œ≤‚ÇÅ = n√∫mero de ciclos independientes = dim(H‚ÇÅ(G))
        - Caracter√≠stica de Euler: œá = V - E = Œ≤‚ÇÄ - Œ≤‚ÇÅ

        Args:
            graph (nx.DiGraph): El grafo a analizar.

        Returns:
            TopologicalMetrics: M√©tricas calculadas con coherencia algebraica.
        """
        if graph.number_of_nodes() == 0:
            return TopologicalMetrics(0, 0, 0, 1.0)

        # Usar grafo no dirigido para c√°lculo topol√≥gico (homolog√≠a simplicial)
        undirected = nx.Graph()
        undirected.add_nodes_from(graph.nodes())
        undirected.add_edges_from(graph.edges())

        # Œ≤‚ÇÄ: Componentes conexas (espacio de 0-homolog√≠a)
        beta_0 = nx.number_connected_components(undirected)

        # Conteos fundamentales
        n_edges = undirected.number_of_edges()
        n_nodes = undirected.number_of_nodes()

        # Œ≤‚ÇÅ: Ciclos independientes (espacio de 1-homolog√≠a)
        # Para grafos: Œ≤‚ÇÅ = E - V + Œ≤‚ÇÄ (f√≥rmula de homolog√≠a para 1-complejos)
        beta_1 = max(0, n_edges - n_nodes + beta_0)

        # Caracter√≠stica de Euler (invariante topol√≥gico)
        euler_char = beta_0 - beta_1

        # Validaci√≥n de coherencia: debe cumplirse V - E = Œ≤‚ÇÄ - Œ≤‚ÇÅ
        if (n_nodes - n_edges) != euler_char:
            self.logger.warning(
                f"Inconsistencia en caracter√≠stica de Euler: "
                f"V={n_nodes}, E={n_edges}, œá_calc={n_nodes - n_edges}, "
                f"œá_betti={euler_char}. Usando c√°lculo basado en Betti."
            )

        efficiency = self.calculate_euler_efficiency(graph)

        return TopologicalMetrics(
            beta_0=beta_0,
            beta_1=beta_1,
            euler_characteristic=euler_char,
            euler_efficiency=efficiency,
        )

    def calculate_pyramid_stability(self, graph: nx.DiGraph) -> float:
        """
        Calcula el √çndice de Estabilidad Piramidal (Œ®) con robustez mejorada.

        F√≥rmula: Œ® = log‚ÇÅ‚ÇÄ(1 + (I/A)) √ó (1 - D) √ó C
        donde:
        - I/A: ratio base/ancho (insumos/APUs)
        - D: densidad del grafo (penalizaci√≥n por sobreconexi√≥n)
        - C: factor de conectividad (0 si hay ciclos, 1 si es DAG)

        Interpretaci√≥n:
        - Œ® > 2.0: Estructura robusta (base amplia, baja densidad)
        - Œ® < 0.5: Riesgo estructural alto (base estrecha, alta complejidad)

        Args:
            graph: Grafo del presupuesto.

        Returns:
            float: Valor de estabilidad (0.0 si no se puede calcular).
        """
        # 1. Contar nodos por tipo
        nodes_data = graph.nodes(data=True)
        num_apus = sum(1 for _, d in nodes_data if d.get("type") == "APU")
        num_insumos = sum(1 for _, d in nodes_data if d.get("type") == "INSUMO")

        # 2. Validaciones
        if num_apus == 0 or num_insumos == 0:
            return 0.0

        # 3. Ratio base/ancho con suavizado logar√≠tmico
        base_ratio = num_insumos / num_apus
        ratio_term = np.log10(1 + base_ratio)

        # 4. Penalizaci√≥n por densidad
        density = nx.density(graph)
        density_penalty = 1.0 - min(density, 0.99)  # Evitar valores negativos

        # 5. Factor de conectividad: penalizaci√≥n por ciclos
        connectivity_factor = 1.0 if nx.is_directed_acyclic_graph(graph) else 0.7

        # 6. C√°lculo final
        stability = ratio_term * density_penalty * connectivity_factor
        return round(stability, 3)

    def audit_integration_homology(
        self, graph_a: nx.DiGraph, graph_b: nx.DiGraph
    ) -> Dict[str, Any]:
        """
        Ejecuta el Test de Mayer-Vietoris para detectar ciclos emergentes en fusiones.

        Teor√≠a: Para uniones de complejos A ‚à™ B, la sucesi√≥n de Mayer-Vietoris produce:
        ŒîŒ≤‚ÇÅ = Œ≤‚ÇÅ(A ‚à™ B) - [Œ≤‚ÇÅ(A) + Œ≤‚ÇÅ(B)] + Œ¥
        donde Œ¥ captura interacciones en la intersecci√≥n A ‚à© B.

        En nuestra aproximaci√≥n, Œ¥ se estima como |A ‚à© B| - Œ≤‚ÇÄ(A ‚à© B) + 1.

        Returns:
            Dict con diagn√≥stico topol√≥gico y narrativa estrat√©gica.
        """
        # 1. An√°lisis de las partes
        metrics_a = self.calculate_betti_numbers(graph_a)
        metrics_b = self.calculate_betti_numbers(graph_b)

        # 2. Uni√≥n topol√≥gica (A ‚à™ B)
        graph_union = nx.compose(graph_a, graph_b)
        metrics_union = self.calculate_betti_numbers(graph_union)

        # 3. Intersecci√≥n estimada (nodos comunes)
        nodes_a = set(graph_a.nodes())
        nodes_b = set(graph_b.nodes())
        common_nodes = nodes_a.intersection(nodes_b)

        # Grafo de intersecci√≥n aproximado
        graph_intersection = nx.DiGraph()
        if common_nodes:
            graph_intersection.add_nodes_from(common_nodes)
            # Solo mantener aristas donde ambos extremos est√°n en la intersecci√≥n
            for u, v in graph_a.edges():
                if u in common_nodes and v in common_nodes:
                    graph_intersection.add_edge(u, v)
            for u, v in graph_b.edges():
                if u in common_nodes and v in common_nodes:
                    graph_intersection.add_edge(u, v)

        metrics_intersection = self.calculate_betti_numbers(graph_intersection)

        # 4. F√≥rmula Mayer-Vietoris para grafos
        # Œ≤‚ÇÅ(A ‚à™ B) = Œ≤‚ÇÅ(A) + Œ≤‚ÇÅ(B) - Œ≤‚ÇÅ(A ‚à© B) + Œî
        # donde Œî = |A ‚à© B| - Œ≤‚ÇÄ(A ‚à© B) + 1 (t√©rmeno de conexi√≥n)
        delta = len(common_nodes) - metrics_intersection.beta_0 + 1

        # Ciclos emergentes te√≥ricos
        emergent_theoretical = (
            metrics_a.beta_1 + metrics_b.beta_1 - metrics_intersection.beta_1 + delta
        )

        # Ciclos emergentes observados
        emergent_observed = metrics_union.beta_1 - (metrics_a.beta_1 + metrics_b.beta_1)

        # 5. Diagn√≥stico diferencial
        discrepancy = abs(emergent_observed - emergent_theoretical)
        if discrepancy <= 1:  # Tolerancia peque√±a
            if emergent_observed > 0:
                verdict = "INTEGRATION_CONFLICT"
                narrative = (
                    f"üö® ALERTA MAYER-VIETORIS: La fusi√≥n gener√≥ {emergent_observed} "
                    f"nuevos ciclos de dependencia. Conflicto de interfaz detectado."
                )
            elif emergent_observed < 0:
                verdict = "TOPOLOGY_SIMPLIFIED"
                narrative = (
                    f"‚úÖ Fusi√≥n simplific√≥ la estructura. "
                    f"Se eliminaron {abs(emergent_observed)} ciclos redundantes."
                )
            else:
                verdict = "CLEAN_MERGE"
                narrative = "‚úÖ Fusi√≥n topol√≥gicamente neutra: sin riesgos estructurales nuevos."
        else:
            verdict = "INCONSISTENT_TOPOLOGY"
            narrative = (
                f"‚ö†Ô∏è Discrepancia topol√≥gica detectada (Œî={discrepancy}). "
                f"Revisar superposici√≥n de componentes."
            )

        return {
            "status": verdict,
            "delta_beta_1_observed": emergent_observed,
            "delta_beta_1_theoretical": emergent_theoretical,
            "discrepancy": discrepancy,
            "details": {
                "beta_1_A": metrics_a.beta_1,
                "beta_1_B": metrics_b.beta_1,
                "beta_1_Union": metrics_union.beta_1,
                "beta_1_Intersection": metrics_intersection.beta_1,
                "common_nodes_count": len(common_nodes),
                "delta_term": delta,
            },
            "narrative": narrative,
        }

    def _get_raw_cycles(self, graph: nx.DiGraph) -> Tuple[List[List[str]], bool]:
        """
        Obtiene los ciclos crudos con algoritmo Johnson optimizado y poda temprana.

        Complexity: O((V + E)(c + 1)) para c ciclos simples.
        Implementa truncamiento inteligente basado en longitud de ciclos.

        Returns:
            Tuple[List[List[str]], bool]: Ciclos y flag de truncamiento.
        """
        cycles = []
        truncated = False

        try:
            # Algoritmo Johnson para ciclos simples
            cycle_generator = nx.simple_cycles(graph)

            # L√≠mites duales: m√°ximo n√∫mero de ciclos y longitud m√°xima
            max_cycle_length = 10  # Ciclos muy largos son menos relevantes para riesgo

            for count, cycle in enumerate(cycle_generator):
                if count >= self.max_cycles:
                    truncated = True
                    self.logger.warning(f"Truncado de ciclos en {self.max_cycles}")
                    break

                # Podar ciclos demasiado largos (probablemente artefactos)
                if len(cycle) <= max_cycle_length:
                    cycles.append(cycle)
                else:
                    self.logger.debug(f"Ciclo largo ignorado (longitud {len(cycle)})")

        except Exception as e:
            self.logger.error(f"Error en detecci√≥n de ciclos: {e}")

        # Ordenar por longitud (ciclos cortos primero - m√°s cr√≠ticos)
        cycles.sort(key=len)
        return cycles, truncated

    def detect_risk_synergy(
        self, graph: nx.DiGraph, raw_cycles: Optional[List[List[str]]] = None
    ) -> Dict[str, Any]:
        """
        Detecta Sinergia de Riesgo (Producto Cup) mediante an√°lisis de intersecci√≥n
        y centralidad de betweenness.

        M√©trica: Dos ciclos C‚ÇÅ, C‚ÇÇ tienen sinergia si:
        1. |C‚ÇÅ ‚à© C‚ÇÇ| ‚â• 2 (comparten m√∫ltiples nodos cr√≠ticos)
        2. ‚àÉ v ‚àà C‚ÇÅ ‚à© C‚ÇÇ con betweenness_centrality(v) > Œ∏

        Returns:
            Dict con an√°lisis de sinergia y nodos puente cr√≠ticos.
        """
        if raw_cycles is None:
            raw_cycles, _ = self._get_raw_cycles(graph)

        if len(raw_cycles) < 2:
            return {
                "synergy_detected": False,
                "shared_nodes": [],
                "intersecting_cycles_count": 0,
                "bridge_nodes": [],
                "synergy_score": 0.0,
            }

        # 1. Calcular centralidad de betweenness (m√°s robusto que grado)
        try:
            betweenness = nx.betweenness_centrality(graph, normalized=True)
            # Umbral: percentil 75
            threshold = np.percentile(list(betweenness.values()), 75) if betweenness else 0.0
        except:
            betweenness = {}
            threshold = 0.0

        # 2. Identificar nodos cr√≠ticos (alto betweenness)
        critical_nodes = {n for n, c in betweenness.items() if c >= threshold}

        # 3. Buscar intersecciones significativas
        synergy_pairs = []
        bridge_nodes = set()
        cycle_sets = [set(c) for c in raw_cycles]

        for i in range(len(cycle_sets)):
            for j in range(i + 1, len(cycle_sets)):
                intersection = cycle_sets[i].intersection(cycle_sets[j])

                # Criterio 1: Intersecci√≥n con al menos 2 nodos
                if len(intersection) >= 2:
                    # Criterio 2: Al menos un nodo cr√≠tico en la intersecci√≥n
                    critical_intersection = intersection.intersection(critical_nodes)
                    if critical_intersection:
                        synergy_pairs.append((i, j))
                        bridge_nodes.update(critical_intersection)

        # 4. Calcular score de sinergia
        synergy_score = 0.0
        if synergy_pairs:
            # Score basado en n√∫mero de pares sin√©rgicos y nodos puente
            total_pairs = len(cycle_sets) * (len(cycle_sets) - 1) / 2
            synergy_score = min(1.0, len(synergy_pairs) / total_pairs * len(bridge_nodes))

        return {
            "synergy_detected": len(synergy_pairs) > 0,
            "shared_nodes": list(bridge_nodes),
            "intersecting_cycles_count": len(synergy_pairs),
            "bridge_nodes": list(bridge_nodes),
            "synergy_score": round(synergy_score, 3),
        }

    def _compute_connectivity_analysis(self, graph: nx.DiGraph) -> Dict[str, Any]:
        """
        Calcula m√©tricas de conectividad avanzadas con an√°lisis SCC y WCC.

        Incluye:
        - Componentes fuertemente conexas (SCC) no triviales
        - Componentes d√©bilmente conexas (WCC)
        - Puntos de articulaci√≥n (vulnerabilidades estructurales)
        - Coeficiente de clustering promedio

        Returns:
            Dict con m√©tricas de conectividad detalladas.
        """
        if graph.number_of_nodes() == 0:
            return {
                "is_dag": True,
                "num_wcc": 0,
                "is_weakly_connected": True,
                "num_scc": 0,
                "scc_sizes": [],
                "articulation_points": [],
                "average_clustering": 0.0,
            }

        # Convertir a no dirigido para an√°lisis de conectividad d√©bil
        undirected = graph.to_undirected()

        # Componentes fuertemente conexas
        scc = list(nx.strongly_connected_components(graph))
        non_trivial_scc = [c for c in scc if len(c) > 1]

        # Puntos de articulaci√≥n (nodos cuya remoci√≥n desconecta el grafo)
        articulation_points = list(nx.articulation_points(undirected))

        # Coeficiente de clustering (medida de redundancia local)
        try:
            avg_clustering = nx.average_clustering(undirected)
        except:
            avg_clustering = 0.0

        return {
            "is_dag": nx.is_directed_acyclic_graph(graph),
            "num_wcc": nx.number_weakly_connected_components(graph),
            "is_weakly_connected": nx.is_weakly_connected(graph),
            "num_scc": len(non_trivial_scc),
            "scc_sizes": [len(c) for c in non_trivial_scc],
            "non_trivial_scc": [list(c) for c in non_trivial_scc],
            "articulation_points": articulation_points,
            "average_clustering": round(avg_clustering, 4),
        }

    def generate_executive_report(
        self, graph: nx.DiGraph, financial_metrics: Optional[Dict[str, Any]] = None
    ) -> ConstructionRiskReport:
        """
        Genera reporte de riesgos con modelo de scoring bayesiano mejorado.

        Scoring: Integrity = 100 √ó [w‚ÇÅ¬∑EulerEfficiency + w‚ÇÇ¬∑(1 - Density) + w‚ÇÉ¬∑Stability]
        donde w‚ÇÅ=0.4, w‚ÇÇ=0.3, w‚ÇÉ=0.3

        Args:
            graph (nx.DiGraph): Grafo a reportar.
            financial_metrics (Optional[Dict[str, Any]]): M√©tricas financieras.

        Returns:
            ConstructionRiskReport: Reporte ejecutivo completo.
        """
        # 1. M√©tricas topol√≥gicas fundamentales
        metrics = self.calculate_betti_numbers(graph)
        raw_cycles, _ = self._get_raw_cycles(graph)
        cycles = [" ‚Üí ".join(c + [c[0]]) for c in raw_cycles]

        # 2. An√°lisis especializados
        synergy = self.detect_risk_synergy(graph, raw_cycles)
        anomalies = self._classify_anomalous_nodes(graph)
        pyramid_stability = self.calculate_pyramid_stability(graph)
        connectivity = self._compute_connectivity_analysis(graph)

        # 3. C√°lculo de scoring de integridad con pesos bayesianos
        density = nx.density(graph) if graph else 0.0

        # Factores normalizados
        euler_factor = metrics.euler_efficiency  # [0, 1]
        density_factor = 1.0 - min(density, 0.99)  # [0.01, 1]
        stability_factor = min(pyramid_stability / 3.0, 1.0)  # Normalizado a [0, 1]

        # Pesos optimizados
        weights = {"euler": 0.4, "density": 0.3, "stability": 0.3}
        integrity_score = 100.0 * (
            weights["euler"] * euler_factor
            + weights["density"] * density_factor
            + weights["stability"] * stability_factor
        )

        # 4. Penalizaciones por anomal√≠as cr√≠ticas
        penalty_multiplier = 1.0

        # Penalizaci√≥n por ciclos
        if metrics.beta_1 > 0:
            cycle_penalty = min(0.5, metrics.beta_1 * 0.1)
            penalty_multiplier -= cycle_penalty

        # Penalizaci√≥n por sinergia de riesgo
        if synergy["synergy_detected"]:
            synergy_penalty = min(0.3, synergy["synergy_score"] * 0.5)
            penalty_multiplier -= synergy_penalty

        # Penalizaci√≥n por nodos aislados/hu√©rfanos
        iso_count = len(anomalies["isolated_nodes"])
        orphan_count = len(anomalies["orphan_insumos"])
        anomaly_penalty = min(0.2, (iso_count + orphan_count) * 0.05)
        penalty_multiplier -= anomaly_penalty

        integrity_score *= max(0.0, penalty_multiplier)
        integrity_score = round(max(0.0, min(100.0, integrity_score)), 1)

        # 5. Clasificaci√≥n de complejidad
        complexity_score = (
            0.4 * (metrics.beta_1 / max(1, graph.number_of_nodes()))
            + 0.3 * density
            + 0.3 * (1.0 - metrics.euler_efficiency)
        )

        if complexity_score > 0.3:
            complexity_level = "Alta (Cr√≠tica)"
        elif complexity_score > 0.15:
            complexity_level = "Media"
        else:
            complexity_level = "Baja"

        # 6. Alertas de desperdicio
        waste_alerts = []

        if iso_count > 0:
            waste_alerts.append(f"üö® {iso_count} nodos aislados detectados (recursos no utilizados).")

        if orphan_count > 0:
            waste_alerts.append(f"‚ö†Ô∏è {orphan_count} insumos hu√©rfanos (sin APU padre).")

        if metrics.euler_efficiency < 0.6:
            waste_alerts.append(
                f"‚ö†Ô∏è Baja eficiencia topol√≥gica ({metrics.euler_efficiency:.2f}). "
                f"Exceso de conexiones redundantes."
            )

        if pyramid_stability < 1.0:
            waste_alerts.append(
                f"‚ö†Ô∏è Estabilidad piramidal baja ({pyramid_stability:.2f}). "
                f"Riesgo de estructura invertida."
            )

        # 7. Riesgos circulares
        circular_risks = []

        if metrics.beta_1 > 0:
            circular_risks.append(
                f"üö® CR√çTICO: {metrics.beta_1} ciclo(s) de dependencia detectados. "
                f"Riesgo de c√°lculos circulares."
            )

        if synergy["synergy_detected"]:
            circular_risks.append(
                f"üö® RIESGO SIST√âMICO: Sinergia de riesgo detectada "
                f"(score: {synergy['synergy_score']:.2f}). Efecto domin√≥ probable."
            )

        # 8. An√°lisis de riesgo financiero integrado
        financial_risk = None
        if financial_metrics:
            # Combinar riesgo topol√≥gico y financiero
            volatility = financial_metrics.get("volatility", 0.0)
            roi = financial_metrics.get("roi", 0.0)

            # Score de riesgo financiero base
            if roi < 0:
                financial_risk = "CR√çTICO"
            elif volatility > 0.25:
                financial_risk = "ALTO"
            elif volatility > 0.15:
                financial_risk = "MEDIO"
            else:
                financial_risk = "BAJO"

            # Escalaci√≥n por riesgos topol√≥gicos
            if (metrics.beta_1 > 2 or synergy["synergy_detected"]) and financial_risk in [
                "ALTO",
                "MEDIO",
            ]:
                financial_risk = "CAT√ÅSTROFICO"
            elif metrics.beta_1 > 0 and financial_risk == "ALTO":
                financial_risk = "MUY ALTO"

        # 9. Narrativa estrat√©gica
        strategic_narrative = self._generate_strategic_narrative(
            metrics, synergy, pyramid_stability, financial_risk
        )

        return ConstructionRiskReport(
            integrity_score=integrity_score,
            waste_alerts=waste_alerts,
            circular_risks=circular_risks,
            complexity_level=complexity_level,
            financial_risk_level=financial_risk,
            strategic_narrative=strategic_narrative,
            details={
                "metrics": asdict(metrics),
                "cycles": cycles,
                "anomalies": anomalies,
                "synergy_risk": synergy,
                "connectivity": connectivity,
                "pyramid_stability": pyramid_stability,
                "density": density,
                "financial_metrics_input": financial_metrics or {},
                "scoring_weights": weights,
                "penalty_multiplier": penalty_multiplier,
            },
        )

    def _generate_strategic_narrative(
        self,
        metrics: TopologicalMetrics,
        synergy: Dict[str, Any],
        stability: float,
        financial_risk: Optional[str],
    ) -> str:
        """Genera narrativa estrat√©gica integrada para decisores."""
        narratives = []

        # Narrativa topol√≥gica
        if metrics.is_simply_connected:
            narratives.append("Estructura topol√≥gica √≥ptima: simplemente conexa y ac√≠clica.")
        elif metrics.is_connected:
            narratives.append("Estructura conexa pero con complejidad c√≠clica.")
        else:
            narratives.append(f"Estructura fragmentada ({metrics.beta_0} componentes).")

        if metrics.beta_1 > 0:
            narratives.append(f"Presencia de {metrics.beta_1} ciclos de dependencia cr√≠tica.")

        if synergy["synergy_detected"]:
            narratives.append(
                f"Sinergia de riesgo detectada ({synergy['intersecting_cycles_count']} "
                f"intersecciones cr√≠ticas)."
            )

        # Narrativa de estabilidad
        if stability > 2.0:
            narratives.append("Pir√°mide presupuestaria robusta y bien balanceada.")
        elif stability > 1.0:
            narratives.append("Estabilidad piramidal adecuada.")
        else:
            narratives.append("ALERTA: Estabilidad piramidal comprometida.")

        # Narrativa financiera integrada
        if financial_risk:
            risk_map = {
                "BAJO": "Riesgo financiero bajo. ",
                "MEDIO": "Riesgo financiero moderado. ",
                "ALTO": "üö® Riesgo financiero alto. ",
                "MUY ALTO": "üö®üö® Riesgo financiero muy alto. ",
                "CR√çTICO": "üö®üö®üö® RIESGO FINANCIERO CR√çTICO. ",
                "CAT√ÅSTROFICO": "üíÄ RIESGO CAT√ÅSTROFICO DETECTADO. ",
            }
            narratives.append(risk_map.get(financial_risk, ""))

        # Recomendaci√≥n final
        if metrics.beta_1 == 0 and stability > 1.5 and financial_risk in [None, "BAJO"]:
            narratives.append("‚úÖ RECOMENDACI√ìN: Estructura aprobada para ejecuci√≥n.")
        elif metrics.beta_1 > 0 or stability < 1.0:
            narratives.append("‚ö†Ô∏è RECOMENDACI√ìN: Requiere revisi√≥n t√©cnica urgente.")
        else:
            narratives.append("‚ÑπÔ∏è RECOMENDACI√ìN: Monitoreo continuo recomendado.")

        return " ".join(narratives)


### propuesta 2


# M√©todos Refinados para BudgetGraphBuilder

def _sanitize_code(self, value: Any) -> str:
    """
    Sanitiza el c√≥digo o identificador asegurando una cadena limpia y normalizada.

    Aplica normalizaci√≥n Unicode y elimina caracteres de control invisibles.

    Args:
        value: Valor a sanitizar (cualquier tipo).

    Returns:
        Cadena sanitizada, normalizada y en may√∫sculas para consistencia.
    """
    if pd.isna(value) or value is None:
        return ""
    sanitized = str(value).strip()
    # Eliminar caracteres de control y espacios m√∫ltiples
    sanitized = " ".join(sanitized.split())
    return sanitized

def _safe_float(self, value: Any, default: float = 0.0) -> float:
    """
    Convierte un valor a float de manera segura con soporte para formatos locales.

    Maneja separadores de miles (comas) y valores nulos de manera robusta.

    Args:
        value: Valor a convertir.
        default: Valor por defecto si la conversi√≥n falla.

    Returns:
        Valor num√©rico convertido o el default.
    """
    if pd.isna(value) or value is None:
        return default
    try:
        if isinstance(value, (int, float)):
            return float(value)
        # Manejar strings con formato de n√∫mero (ej: "1,234.56" o "1.234,56")
        str_value = str(value).strip()
        # Detectar formato con coma como separador de miles
        if "," in str_value and "." in str_value:
            if str_value.rfind(",") < str_value.rfind("."):
                str_value = str_value.replace(",", "")
            else:
                str_value = str_value.replace(".", "").replace(",", ".")
        elif "," in str_value and "." not in str_value:
            # Podr√≠a ser separador decimal o de miles
            # Heur√≠stica: si hay m√°s de 2 d√≠gitos despu√©s de la coma, es miles
            parts = str_value.split(",")
            if len(parts) == 2 and len(parts[1]) <= 2:
                str_value = str_value.replace(",", ".")
            else:
                str_value = str_value.replace(",", "")
        return float(str_value)
    except (ValueError, TypeError, AttributeError):
        return default

def _upsert_edge(
    self, G: nx.DiGraph, u: str, v: str, unit_cost: float, quantity: float, idx: int
) -> bool:
    """
    Inserta o actualiza una arista aplicando agregaci√≥n de cantidades y costos.

    Implementa el patr√≥n Upsert con sem√°ntica de acumulaci√≥n para modelar
    m√∫ltiples instancias de la misma relaci√≥n APU ‚Üí Insumo.

    Args:
        G: Grafo dirigido destino.
        u: Nodo origen (APU).
        v: Nodo destino (Insumo).
        unit_cost: Costo unitario del insumo.
        quantity: Cantidad utilizada.
        idx: √çndice original en el DataFrame fuente.

    Returns:
        True si la arista fue creada, False si fue actualizada.
    """
    total_cost = unit_cost * quantity

    if G.has_edge(u, v):
        edge = G[u][v]
        edge["quantity"] += quantity
        edge["total_cost"] += total_cost
        edge["occurrence_count"] += 1
        edge.setdefault("original_indices", []).append(idx)
        return False

    G.add_edge(
        u, v,
        quantity=quantity,
        unit_cost=unit_cost,
        total_cost=total_cost,
        occurrence_count=1,
        original_indices=[idx],
    )
    return True

def _compute_graph_statistics(self, G: nx.DiGraph) -> Dict[str, int]:
    """
    Calcula estad√≠sticas del grafo en una √∫nica pasada sobre los nodos.

    Complejidad temporal: O(V) donde V es el n√∫mero de v√©rtices.
    Complejidad espacial: O(1) auxiliar.

    Args:
        G: Grafo construido.

    Returns:
        Diccionario con conteos por tipo de nodo y totales.
    """
    stats = {
        "chapter_count": 0,
        "apu_count": 0,
        "insumo_count": 0,
        "inferred_count": 0,
        "total_nodes": G.number_of_nodes(),
        "total_edges": G.number_of_edges(),
    }

    type_counters = {"CAPITULO": "chapter_count", "APU": "apu_count", "INSUMO": "insumo_count"}

    for _, data in G.nodes(data=True):
        node_type = data.get("type")
        if node_type in type_counters:
            stats[type_counters[node_type]] += 1
            if node_type == "APU" and data.get("inferred", False):
                stats["inferred_count"] += 1

    return stats

def _process_presupuesto_row(
    self, G: nx.DiGraph, row: pd.Series, idx: int, chapter_cols: List[str]
) -> None:
    """
    Procesa una fila del presupuesto creando nodos APU y conexiones jer√°rquicas.

    Extrae la informaci√≥n de cap√≠tulo si est√° disponible y establece
    las relaciones PROYECTO -> CAP√çTULO -> APU.

    Args:
        G: Grafo destino.
        row: Fila del DataFrame de presupuesto.
        idx: √çndice de la fila.
        chapter_cols: Lista de posibles nombres de columna para cap√≠tulos.
    """
    apu_code = self._sanitize_code(row.get(ColumnNames.CODIGO_APU))
    if not apu_code:
        return

    # Crear nodo APU (Nivel 2)
    attrs = self._create_apu_attributes(row, source="presupuesto", idx=idx, inferred=False)
    G.add_node(apu_code, **attrs)

    # Buscar y establecer jerarqu√≠a de cap√≠tulo
    chapter_name = None
    for col in chapter_cols:
        val = self._sanitize_code(row.get(col))
        if val:
            chapter_name = val
            break

    if chapter_name:
        if chapter_name not in G:
            G.add_node(
                chapter_name,
                type="CAPITULO",
                level=1,
                description=f"Cap√≠tulo: {chapter_name}",
            )
            G.add_edge(self.ROOT_NODE, chapter_name, relation="CONTAINS")
        G.add_edge(chapter_name, apu_code, relation="CONTAINS")
    else:
        G.add_edge(self.ROOT_NODE, apu_code, relation="CONTAINS")

def _process_apu_detail_row(self, G: nx.DiGraph, row: pd.Series, idx: int) -> None:
    """
    Procesa una fila de detalle APU creando nodos Insumo y aristas.

    Maneja la inferencia de APUs que aparecen en detalle pero no en presupuesto.

    Args:
        G: Grafo destino.
        row: Fila del DataFrame de detalle de APUs.
        idx: √çndice de la fila.
    """
    apu_code = self._sanitize_code(row.get(ColumnNames.CODIGO_APU))
    insumo_desc = self._sanitize_code(row.get(ColumnNames.DESCRIPCION_INSUMO))

    if not apu_code or not insumo_desc:
        return

    # Inferir APU si no existe
    if apu_code not in G:
        attrs = self._create_apu_attributes(row, source="detail", idx=idx, inferred=True)
        G.add_node(apu_code, **attrs)
        G.add_edge(self.ROOT_NODE, apu_code, relation="CONTAINS_INFERRED")

    # Crear o reutilizar nodo Insumo
    if insumo_desc not in G:
        attrs = self._create_insumo_attributes(row, insumo_desc, source="detail", idx=idx)
        G.add_node(insumo_desc, **attrs)

    # Establecer relaci√≥n APU -> Insumo con agregaci√≥n
    qty = self._safe_float(row.get(ColumnNames.CANTIDAD_APU))
    cost = self._safe_float(row.get(ColumnNames.COSTO_INSUMO_EN_APU))
    self._upsert_edge(G, apu_code, insumo_desc, cost, qty, idx)

def build(
    self, presupuesto_df: pd.DataFrame, apus_detail_df: pd.DataFrame
) -> nx.DiGraph:
    """
    Construye un grafo dirigido piramidal representando la topolog√≠a del presupuesto.

    Estructura Jer√°rquica:
        Nivel 0: PROYECTO_TOTAL (Ra√≠z √∫nica)
        Nivel 1: Cap√≠tulos (agrupaci√≥n l√≥gica)
        Nivel 2: APUs (An√°lisis de Precios Unitarios)
        Nivel 3: Insumos (recursos at√≥micos)

    El grafo resultante es un DAG (Directed Acyclic Graph) en estructuras sanas,
    donde los ciclos indican errores de referencia circular en costos.

    Args:
        presupuesto_df: DataFrame con estructura de presupuesto (APUs y cap√≠tulos).
        apus_detail_df: DataFrame con detalle de composici√≥n de APUs (insumos).

    Returns:
        Grafo dirigido con la topolog√≠a del presupuesto etiquetada.
    """
    G = nx.DiGraph(name="BudgetTopology")
    self.logger.info("Iniciando construcci√≥n del Grafo Piramidal de Presupuesto...")

    # Nivel 0: Nodo Ra√≠z
    G.add_node(self.ROOT_NODE, type="ROOT", level=0, description="Proyecto Completo")

    # Columnas candidatas para identificar cap√≠tulos
    chapter_cols = ["CAPITULO", "CATEGORIA", "TITULO"]

    # Niveles 1 y 2: Procesar Presupuesto
    if presupuesto_df is not None and not presupuesto_df.empty:
        available_chapter_cols = [c for c in chapter_cols if c in presupuesto_df.columns]
        for idx, row in presupuesto_df.iterrows():
            self._process_presupuesto_row(G, row, idx, available_chapter_cols)

    # Nivel 3: Procesar Detalle de APUs (Insumos)
    if apus_detail_df is not None and not apus_detail_df.empty:
        for idx, row in apus_detail_df.iterrows():
            self._process_apu_detail_row(G, row, idx)

    stats = self._compute_graph_statistics(G)
    self.logger.info(f"Grafo Piramidal construido: {stats}")
    return G


# M√©todos Refinados para BusinessTopologicalAnalyzer

def calculate_euler_efficiency(self, graph: nx.DiGraph) -> float:
    """
    Calcula la Eficiencia de Euler normalizada como medida de redundancia estructural.

    Fundamento Topol√≥gico:
    - Un √°rbol spanning tiene exactamente V-1 aristas (m√≠nima conectividad).
    - Aristas adicionales (E - V + 1) representan redundancia/ciclos.
    - La eficiencia mide qu√© tan cerca est√° la estructura de un √°rbol puro.

    F√≥rmula: Œ∑ = 1 / (1 + Œ± * (E - V + 1) / V)
    donde Œ± es un factor de sensibilidad (usamos Œ±=1 para comportamiento lineal).

    Interpretaci√≥n para Presupuestos:
    - Œ∑ ‚âà 1.0: Estructura arb√≥rea limpia (ideal para jerarqu√≠as de costos).
    - Œ∑ < 0.5: Alta redundancia estructural (posibles dependencias circulares).
    - Œ∑ ‚Üí 0: Grafo denso con m√∫ltiples caminos de costo (dif√≠cil auditor√≠a).

    Args:
        graph: Grafo dirigido a analizar.

    Returns:
        Eficiencia normalizada en el rango [0.0, 1.0].
    """
    n_nodes = graph.number_of_nodes()
    n_edges = graph.number_of_edges()

    if n_nodes <= 1:
        return 1.0  # Grafo trivial es perfectamente eficiente

    # Exceso de aristas sobre un √°rbol spanning
    # Para un √°rbol: E = V - 1, por lo que excess = E - (V - 1) = E - V + 1
    excess_edges = max(0, n_edges - n_nodes + 1)

    # Normalizaci√≥n con decaimiento hiperb√≥lico
    efficiency = 1.0 / (1.0 + excess_edges / n_nodes)

    return round(efficiency, 4)

def calculate_betti_numbers(self, graph: nx.DiGraph) -> TopologicalMetrics:
    """
    Calcula los N√∫meros de Betti del 1-complejo simplicial subyacente al grafo.

    Fundamento de Topolog√≠a Algebraica:
    Los n√∫meros de Betti son invariantes topol√≥gicos que caracterizan
    la estructura homol√≥gica del espacio:

    - Œ≤‚ÇÄ (Betti-0): dim(H‚ÇÄ) = n√∫mero de componentes conexas.
      Mide la fragmentaci√≥n del espacio de costos.

    - Œ≤‚ÇÅ (Betti-1): dim(H‚ÇÅ) = n√∫mero de ciclos independientes.
      Para un 1-complejo: Œ≤‚ÇÅ = E - V + Œ≤‚ÇÄ (por la f√≥rmula de Euler-Poincar√©).
      Mide la complejidad c√≠clica (referencias circulares en costos).

    - œá (Caracter√≠stica de Euler): œá = Œ≤‚ÇÄ - Œ≤‚ÇÅ = V - E.
      Invariante global que resume la topolog√≠a.

    Teorema Aplicado: Para un CW-complejo 1-dimensional (grafo),
    œá = V - E = Œ£(-1)^k * Œ≤‚Çñ = Œ≤‚ÇÄ - Œ≤‚ÇÅ

    Args:
        graph: Grafo dirigido representando la topolog√≠a de negocio.

    Returns:
        TopologicalMetrics con invariantes homol√≥gicos calculados.
    """
    n_nodes = graph.number_of_nodes()
    n_edges = graph.number_of_edges()

    if n_nodes == 0:
        return TopologicalMetrics(
            beta_0=0, beta_1=0, euler_characteristic=0, euler_efficiency=1.0
        )

    # Convertir a grafo no dirigido para an√°lisis de componentes conexas
    # Usamos conversi√≥n simple (no MultiGraph) para conteo correcto
    undirected = graph.to_undirected(as_view=False)

    # Œ≤‚ÇÄ: Componentes conexas (0-√©simo grupo de homolog√≠a)
    beta_0 = nx.number_connected_components(undirected)

    # Œ≤‚ÇÅ: Ciclos independientes (1-er grupo de homolog√≠a)
    # De la f√≥rmula de Euler para 1-complejos: œá = V - E = Œ≤‚ÇÄ - Œ≤‚ÇÅ
    # Por lo tanto: Œ≤‚ÇÅ = Œ≤‚ÇÄ - œá = Œ≤‚ÇÄ - V + E
    beta_1 = max(0, n_edges - n_nodes + beta_0)

    # Caracter√≠stica de Euler
    chi = n_nodes - n_edges  # Equivalente a Œ≤‚ÇÄ - Œ≤‚ÇÅ

    efficiency = self.calculate_euler_efficiency(graph)

    return TopologicalMetrics(
        beta_0=beta_0,
        beta_1=beta_1,
        euler_characteristic=chi,
        euler_efficiency=efficiency,
    )

def calculate_pyramid_stability(self, graph: nx.DiGraph) -> float:
    """
    Calcula el √çndice de Estabilidad Piramidal (Œ®) en una √∫nica pasada.

    El √≠ndice Œ® mide la salud estructural de la jerarqu√≠a de costos:
    - Una pir√°mide estable tiene base ancha (muchos insumos) y v√©rtice estrecho (pocos APUs).
    - Una pir√°mide invertida indica riesgo de colapso estructural.

    F√≥rmula: Œ® = (N_insumos / N_apus) √ó (1 / œÅ)
    donde œÅ es la densidad del grafo.

    Interpretaci√≥n:
    - Œ® > 10: Estructura robusta con base de recursos diversificada.
    - 1 < Œ® < 10: Estructura moderada, revisar dependencias.
    - Œ® < 1: Pir√°mide invertida, alto riesgo de cuellos de botella.

    Args:
        graph: Grafo del presupuesto.

    Returns:
        √çndice de estabilidad (0.0 si el c√°lculo no es posible).
    """
    num_apus = 0
    num_insumos = 0

    # √önica pasada sobre nodos
    for _, data in graph.nodes(data=True):
        node_type = data.get("type")
        if node_type == "APU":
            num_apus += 1
        elif node_type == "INSUMO":
            num_insumos += 1

    if num_apus == 0:
        return 0.0

    density = nx.density(graph)
    if density == 0:
        return 0.0

    base_ratio = num_insumos / num_apus
    stability = base_ratio / density

    return round(stability, 2)

def _get_raw_cycles(self, graph: nx.DiGraph) -> Tuple[List[List[str]], bool]:
    """
    Extrae ciclos simples del grafo con l√≠mite de seguridad.

    Utiliza el algoritmo de Johnson para encontrar ciclos simples,
    con truncamiento para evitar explosi√≥n combinatoria en grafos densos.

    Complejidad: O((V + E)(C + 1)) donde C es el n√∫mero de ciclos.

    Args:
        graph: Grafo dirigido a analizar.

    Returns:
        Tupla de (lista de ciclos como listas de nodos, flag de truncamiento).
    """
    cycles: List[List[str]] = []
    truncated = False

    try:
        cycle_generator = nx.simple_cycles(graph)
        for count, cycle in enumerate(cycle_generator, start=1):
            cycles.append(cycle)
            if count >= self.max_cycles:
                truncated = True
                self.logger.warning(
                    f"Detecci√≥n de ciclos truncada en {self.max_cycles}. "
                    "Grafo posiblemente muy denso."
                )
                break
    except nx.NetworkXError as e:
        self.logger.error(f"Error de NetworkX detectando ciclos: {e}")
    except Exception as e:
        self.logger.error(f"Error inesperado detectando ciclos: {e}", exc_info=True)

    return cycles, truncated

def _format_cycles(self, raw_cycles: List[List[str]]) -> List[str]:
    """
    Formatea ciclos crudos a representaci√≥n de string legible.

    Args:
        raw_cycles: Lista de ciclos como listas de nodos.

    Returns:
        Lista de ciclos formateados como "A ‚Üí B ‚Üí C ‚Üí A".
    """
    return [" ‚Üí ".join(map(str, cycle + [cycle[0]])) for cycle in raw_cycles]

def _detect_cycles(self, graph: nx.DiGraph) -> Tuple[List[str], bool]:
    """
    Detecta y formatea ciclos en el grafo.

    Args:
        graph: Grafo a analizar.

    Returns:
        Tupla de (ciclos formateados, flag de truncamiento).
    """
    raw_cycles, truncated = self._get_raw_cycles(graph)
    return self._format_cycles(raw_cycles), truncated

def _identify_critical_nodes(
    self, graph: nx.DiGraph, percentile: float = 0.9
) -> set:
    """
    Identifica nodos cr√≠ticos bas√°ndose en centralidad de grado.

    Los nodos cr√≠ticos son aquellos con grado en el percentil superior,
    representando puntos de alta conectividad y potencial propagaci√≥n de riesgo.

    Args:
        graph: Grafo a analizar.
        percentile: Percentil umbral para considerar un nodo cr√≠tico.

    Returns:
        Conjunto de identificadores de nodos cr√≠ticos.
    """
    degrees = dict(graph.degree())
    if not degrees:
        return set()

    sorted_degrees = sorted(degrees.values(), reverse=True)
    threshold_idx = max(0, int(len(sorted_degrees) * (1 - percentile)))
    degree_threshold = max(2, sorted_degrees[threshold_idx] if sorted_degrees else 0)

    return {node for node, degree in degrees.items() if degree >= degree_threshold}

def detect_risk_synergy(
    self, graph: nx.DiGraph, raw_cycles: Optional[List[List[str]]] = None
) -> Dict[str, Any]:
    """
    Detecta Sinergia de Riesgo mediante an√°lisis de intersecci√≥n de ciclos.

    Modelo Te√≥rico (Producto Cup Simplificado):
    En cohomolog√≠a, el producto cup Œ± ‚à™ Œ≤ detecta intersecciones no triviales.
    Aqu√≠ simulamos este concepto: si dos ciclos comparten nodos cr√≠ticos,
    sus riesgos interact√∫an multiplicativamente (efecto domin√≥).

    Implicaci√≥n de Negocio:
    - Ciclos disjuntos: riesgos independientes y aditivos.
    - Ciclos intersectantes en nodos cr√≠ticos: riesgo sist√©mico amplificado.

    Args:
        graph: Grafo de presupuesto.
        raw_cycles: Ciclos pre-calculados (optimizaci√≥n para evitar rec√°lculo).

    Returns:
        Diccionario con detecci√≥n de sinergia, nodos compartidos y conteo.
    """
    if raw_cycles is None:
        raw_cycles, _ = self._get_raw_cycles(graph)

    result = {
        "synergy_detected": False,
        "shared_nodes": [],
        "intersecting_cycles_count": 0,
    }

    if len(raw_cycles) < 2:
        return result

    critical_nodes = self._identify_critical_nodes(graph)
    cycle_sets = [set(cycle) for cycle in raw_cycles]

    shared_critical: set = set()
    intersecting_count = 0

    # Comparaci√≥n por pares O(n¬≤) - aceptable dado max_cycles
    for i, set_i in enumerate(cycle_sets):
        for set_j in cycle_sets[i + 1:]:
            critical_intersection = set_i & set_j & critical_nodes
            if critical_intersection:
                shared_critical |= critical_intersection
                intersecting_count += 1

    result["synergy_detected"] = len(shared_critical) > 0
    result["shared_nodes"] = sorted(shared_critical)
    result["intersecting_cycles_count"] = intersecting_count

    return result

def _classify_anomalous_nodes(
    self, graph: nx.DiGraph
) -> Dict[str, List[Dict[str, Any]]]:
    """
    Clasifica nodos en categor√≠as an√≥malas en una √∫nica pasada eficiente.

    Categor√≠as de Anomal√≠a:
    - Aislados: Nodos sin conexiones (in_degree = out_degree = 0).
    - Hu√©rfanos: Insumos sin APU padre (in_degree = 0).
    - Vac√≠os: APUs sin insumos hijos (out_degree = 0).

    Complejidad: O(V) tiempo, O(A) espacio donde A es el n√∫mero de anomal√≠as.

    Args:
        graph: Grafo a analizar.

    Returns:
        Diccionario con listas de nodos an√≥malos por categor√≠a.
    """
    result: Dict[str, List[Dict[str, Any]]] = {
        "isolated_nodes": [],
        "orphan_insumos": [],
        "empty_apus": [],
    }

    # Pre-calcular grados para evitar llamadas repetidas
    in_degrees = dict(graph.in_degree())
    out_degrees = dict(graph.out_degree())

    for node, data in graph.nodes(data=True):
        node_type = data.get("type")

        # Ignorar nodo ra√≠z
        if node_type == "ROOT":
            continue

        in_deg = in_degrees.get(node, 0)
        out_deg = out_degrees.get(node, 0)

        node_info = {
            "id": node,
            "type": node_type,
            "description": data.get("description", ""),
            "inferred": data.get("inferred", False),
            "in_degree": in_deg,
            "out_degree": out_deg,
        }

        is_isolated = in_deg == 0 and out_deg == 0

        if is_isolated:
            result["isolated_nodes"].append(node_info)
            # Un insumo aislado tambi√©n es hu√©rfano
            if node_type == "INSUMO":
                result["orphan_insumos"].append(node_info)
        elif node_type == "INSUMO" and in_deg == 0:
            result["orphan_insumos"].append(node_info)
        elif node_type == "APU" and out_deg == 0:
            result["empty_apus"].append(node_info)

    return result

def _identify_critical_resources(
    self, graph: nx.DiGraph, top_n: int = 5
) -> List[Dict[str, Any]]:
    """
    Identifica los recursos (insumos) m√°s cr√≠ticos por centralidad de grado entrante.

    Los insumos con alto grado entrante son utilizados por m√∫ltiples APUs,
    representando puntos cr√≠ticos donde variaciones de precio impactan ampliamente.

    Args:
        graph: Grafo a analizar.
        top_n: N√∫mero de recursos top a retornar.

    Returns:
        Lista ordenada de recursos cr√≠ticos con metadatos.
    """
    resources = [
        {
            "id": node,
            "in_degree": graph.in_degree(node),
            "description": data.get("description", ""),
        }
        for node, data in graph.nodes(data=True)
        if data.get("type") == "INSUMO" and graph.in_degree(node) > 0
    ]

    resources.sort(key=lambda x: x["in_degree"], reverse=True)
    return resources[:top_n]

def _compute_connectivity_analysis(self, graph: nx.DiGraph) -> Dict[str, Any]:
    """
    Analiza propiedades de conectividad del grafo dirigido.

    M√©tricas Calculadas:
    - is_dag: Si el grafo es ac√≠clico (ideal para estructuras de costo).
    - num_wcc: N√∫mero de componentes d√©bilmente conexas.
    - is_weakly_connected: Si existe camino no dirigido entre cualquier par.
    - SCCs no triviales: Componentes fuertemente conexas con >1 nodo (ciclos).

    Args:
        graph: Grafo a analizar.

    Returns:
        Diccionario con m√©tricas de conectividad.
    """
    sccs = list(nx.strongly_connected_components(graph))
    non_trivial_sccs = [list(c) for c in sccs if len(c) > 1]

    return {
        "is_dag": nx.is_directed_acyclic_graph(graph),
        "num_wcc": nx.number_weakly_connected_components(graph),
        "is_weakly_connected": nx.is_weakly_connected(graph) if graph.number_of_nodes() > 0 else True,
        "num_non_trivial_scc": len(non_trivial_sccs),
        "non_trivial_scc": non_trivial_sccs,
    }

def _compute_integrity_score(
    self,
    metrics: TopologicalMetrics,
    synergy: Dict[str, Any],
    anomalies: Dict[str, List[Dict[str, Any]]],
) -> float:
    """
    Calcula la puntuaci√≥n de integridad estructural basada en m√∫ltiples factores.

    Modelo de Penalizaci√≥n:
    - Ciclos (Œ≤‚ÇÅ > 0): -50 puntos (riesgo cr√≠tico de circularidad).
    - Sinergia de riesgo: -20 puntos (efecto domin√≥ potencial).
    - Nodos aislados: -2 puntos cada uno (m√°ximo -30).
    - Insumos hu√©rfanos: -1 punto cada uno (m√°ximo -20).

    Args:
        metrics: M√©tricas topol√≥gicas calculadas.
        synergy: Resultado de detecci√≥n de sinergia de riesgo.
        anomalies: Clasificaci√≥n de nodos an√≥malos.

    Returns:
        Puntuaci√≥n de integridad en rango [0, 100].
    """
    score = 100.0

    # Penalizaci√≥n por ciclos (cr√≠tico)
    if metrics.beta_1 > 0:
        score -= 50

    # Penalizaci√≥n por sinergia de riesgo
    if synergy.get("synergy_detected", False):
        score -= 20

    # Penalizaci√≥n por nodos aislados
    isolated_count = len(anomalies.get("isolated_nodes", []))
    score -= min(30, isolated_count * 2)

    # Penalizaci√≥n por insumos hu√©rfanos
    orphan_count = len(anomalies.get("orphan_insumos", []))
    score -= min(20, orphan_count)

    return max(0.0, score)

def _determine_complexity_level(
    self, metrics: TopologicalMetrics, density: float
) -> str:
    """
    Determina el nivel de complejidad estructural del grafo.

    Criterios:
    - Alta (Cr√≠tica): Presencia de ciclos (Œ≤‚ÇÅ > 0).
    - Alta: Densidad > 10%.
    - Media: Densidad entre 5% y 10%.
    - Baja: Densidad < 5%.

    Args:
        metrics: M√©tricas topol√≥gicas.
        density: Densidad del grafo.

    Returns:
        Nivel de complejidad como string descriptivo.
    """
    if metrics.beta_1 > 0:
        return "Alta (Cr√≠tica)"
    if density > 0.10:
        return "Alta"
    if density > 0.05:
        return "Media"
    return "Baja"

def _generate_waste_alerts(
    self,
    anomalies: Dict[str, List[Dict[str, Any]]],
    metrics: TopologicalMetrics,
    pyramid_stability: float,
    node_count: int,
) -> List[str]:
    """
    Genera alertas de posible desperdicio basadas en anomal√≠as estructurales.

    Args:
        anomalies: Clasificaci√≥n de nodos an√≥malos.
        metrics: M√©tricas topol√≥gicas.
        pyramid_stability: √çndice de estabilidad piramidal.
        node_count: N√∫mero total de nodos en el grafo.

    Returns:
        Lista de mensajes de alerta.
    """
    alerts = []

    isolated_count = len(anomalies.get("isolated_nodes", []))
    orphan_count = len(anomalies.get("orphan_insumos", []))

    if isolated_count > 0:
        alerts.append(f"Alerta: {isolated_count} Insumos no utilizados.")

    if orphan_count > 0:
        alerts.append(f"Alerta: {orphan_count} Recursos sin asignaci√≥n a APUs.")

    if metrics.euler_efficiency < 0.5:
        alerts.append(
            f"Alerta de Gesti√≥n: Baja Eficiencia de Euler ({metrics.euler_efficiency:.2f}). "
            "Sobrecarga de enlaces."
        )

    if pyramid_stability < 10.0 and node_count > 10:
        alerts.append(
            f"Alerta Estructural: Baja estabilidad piramidal ({pyramid_stability:.1f}). "
            "Posible estructura invertida o excesivamente compleja."
        )

    return alerts

def _generate_circular_risks(
    self, metrics: TopologicalMetrics, synergy: Dict[str, Any]
) -> List[str]:
    """
    Genera alertas de riesgos circulares basadas en topolog√≠a.

    Args:
        metrics: M√©tricas topol√≥gicas.
        synergy: Resultado de detecci√≥n de sinergia.

    Returns:
        Lista de mensajes de riesgo circular.
    """
    risks = []

    if metrics.beta_1 > 0:
        risks.append("CR√çTICO: Referencias circulares detectadas.")

    if synergy.get("synergy_detected", False):
        count = synergy.get("intersecting_cycles_count", 0)
        risks.append(
            f"RIESGO SIST√âMICO: Sinergia detectada entre {count} ciclos. "
            "Efecto Domin√≥ probable."
        )

    return risks

def _assess_financial_risk(
    self,
    metrics: TopologicalMetrics,
    synergy: Dict[str, Any],
    financial_metrics: Optional[Dict[str, Any]],
) -> Optional[str]:
    """
    Eval√∫a el nivel de riesgo financiero combinando topolog√≠a y m√©tricas financieras.

    Modelo de Riesgo Compuesto:
    El riesgo financiero se escala a CATASTR√ìFICO cuando hay convergencia
    de riesgo topol√≥gico (ciclos/sinergia) y alto riesgo financiero.

    Args:
        metrics: M√©tricas topol√≥gicas.
        synergy: Resultado de sinergia de riesgo.
        financial_metrics: M√©tricas financieras opcionales.

    Returns:
        Nivel de riesgo o None si no hay m√©tricas financieras.
    """
    if not financial_metrics:
        return None

    volatility = financial_metrics.get("volatility", 0.0)
    roi = financial_metrics.get("roi", 0.0)

    # Clasificaci√≥n base
    if roi < 0:
        risk_level = "CR√çTICO"
    elif volatility > 0.20:
        risk_level = "ALTO"
    elif volatility > 0.10:
        risk_level = "MEDIO"
    else:
        risk_level = "BAJO"

    # Escalamiento por convergencia de riesgos
    topological_risk = metrics.beta_1 > 0 or synergy.get("synergy_detected", False)
    if topological_risk and risk_level in ("ALTO", "CR√çTICO"):
        risk_level = "CAT√ÅSTROFICO"

    return risk_level

def generate_executive_report(
    self, graph: nx.DiGraph, financial_metrics: Optional[Dict[str, Any]] = None
) -> ConstructionRiskReport:
    """
    Genera un reporte ejecutivo de riesgos integrando an√°lisis topol√≥gico y financiero.

    El reporte sintetiza m√∫ltiples dimensiones de an√°lisis en una estructura
    consumible por stakeholders t√©cnicos y de negocio.

    Args:
        graph: Grafo a reportar.
        financial_metrics: M√©tricas financieras opcionales para an√°lisis combinado.

    Returns:
        ConstructionRiskReport con evaluaci√≥n completa.
    """
    # C√°lculos base
    metrics = self.calculate_betti_numbers(graph)
    raw_cycles, truncated = self._get_raw_cycles(graph)
    cycles = self._format_cycles(raw_cycles)
    synergy = self.detect_risk_synergy(graph, raw_cycles)
    anomalies = self._classify_anomalous_nodes(graph)
    pyramid_stability = self.calculate_pyramid_stability(graph)
    density = nx.density(graph) if graph.number_of_nodes() > 0 else 0.0

    # Evaluaciones derivadas
    integrity_score = self._compute_integrity_score(metrics, synergy, anomalies)
    complexity = self._determine_complexity_level(metrics, density)
    waste_alerts = self._generate_waste_alerts(
        anomalies, metrics, pyramid_stability, graph.number_of_nodes()
    )
    circular_risks = self._generate_circular_risks(metrics, synergy)
    financial_risk = self._assess_financial_risk(metrics, synergy, financial_metrics)

    return ConstructionRiskReport(
        integrity_score=integrity_score,
        waste_alerts=waste_alerts,
        circular_risks=circular_risks,
        complexity_level=complexity,
        financial_risk_level=financial_risk,
        details={
            "metrics": asdict(metrics),
            "cycles": cycles,
            "cycles_truncated": truncated,
            "anomalies": anomalies,
            "density": density,
            "pyramid_stability": pyramid_stability,
            "synergy_risk": synergy,
            "financial_metrics_input": financial_metrics or {},
        },
    )

def audit_integration_homology(
    self, graph_a: nx.DiGraph, graph_b: nx.DiGraph
) -> Dict[str, Any]:
    """
    Ejecuta el Test de Mayer-Vietoris para detectar ciclos emergentes en fusiones.

    Fundamento Topol√≥gico:
    La secuencia exacta de Mayer-Vietoris relaciona la homolog√≠a de un espacio
    con la de sus partes:
        ... ‚Üí H‚Çô(A‚à©B) ‚Üí H‚Çô(A) ‚äï H‚Çô(B) ‚Üí H‚Çô(A‚à™B) ‚Üí H‚Çô‚Çã‚ÇÅ(A‚à©B) ‚Üí ...

    Para n=1, el homomorfismo conector Œî: H‚ÇÅ(A‚à™B) ‚Üí H‚ÇÄ(A‚à©B) detecta
    ciclos emergentes que no exist√≠an en las partes individuales.

    Interpretaci√≥n Simplificada:
    ŒîŒ≤‚ÇÅ = Œ≤‚ÇÅ(A‚à™B) - (Œ≤‚ÇÅ(A) + Œ≤‚ÇÅ(B))
    - ŒîŒ≤‚ÇÅ > 0: La fusi√≥n cre√≥ nuevos ciclos (CONFLICTO).
    - ŒîŒ≤‚ÇÅ = 0: Fusi√≥n topol√≥gicamente neutra (LIMPIA).
    - ŒîŒ≤‚ÇÅ < 0: La fusi√≥n simplific√≥ estructura (OPTIMIZACI√ìN).

    Args:
        graph_a: Primer grafo (ej: Cap√≠tulo A del presupuesto).
        graph_b: Segundo grafo (ej: Cap√≠tulo B del presupuesto).

    Returns:
        Diccionario con status, delta, detalles y narrativa.
    """
    metrics_a = self.calculate_betti_numbers(graph_a)
    metrics_b = self.calculate_betti_numbers(graph_b)

    # Uni√≥n de grafos preservando atributos
    graph_union = nx.compose(graph_a, graph_b)
    metrics_union = self.calculate_betti_numbers(graph_union)

    # Diferencial homol√≥gico (homomorfismo conector simplificado)
    emergent_cycles = metrics_union.beta_1 - (metrics_a.beta_1 + metrics_b.beta_1)

    # Diagn√≥stico
    if emergent_cycles > 0:
        verdict = "INTEGRATION_CONFLICT"
    elif emergent_cycles < 0:
        verdict = "TOPOLOGY_SIMPLIFIED"
    else:
        verdict = "CLEAN_MERGE"

    return {
        "status": verdict,
        "delta_beta_1": emergent_cycles,
        "details": {
            "beta_1_A": metrics_a.beta_1,
            "beta_1_B": metrics_b.beta_1,
            "beta_1_Union": metrics_union.beta_1,
            "beta_0_A": metrics_a.beta_0,
            "beta_0_B": metrics_b.beta_0,
            "beta_0_Union": metrics_union.beta_0,
        },
        "narrative": self._generate_mayer_vietoris_narrative(emergent_cycles),
    }

def _interpret_topology(self, metrics: TopologicalMetrics) -> Dict[str, str]:
    """
    Genera interpretaciones sem√°nticas de las m√©tricas topol√≥gicas.

    Traduce invariantes abstractos a descripciones comprensibles para
    usuarios no especializados en topolog√≠a algebraica.

    Args:
        metrics: M√©tricas a interpretar.

    Returns:
        Diccionario con interpretaciones por m√©trica.
    """
    connectivity_status = "Espacio conexo" if metrics.is_connected else "Espacio fragmentado"
    cycle_status = "Estructura ac√≠clica" if metrics.beta_1 == 0 else "Complejidad c√≠clica presente"

    return {
        "beta_0": f"{metrics.beta_0} componente(s) conexa(s). {connectivity_status}.",
        "beta_1": f"{metrics.beta_1} ciclo(s) independiente(s). {cycle_status}.",
        "euler": f"Caracter√≠stica de Euler: œá = {metrics.euler_characteristic}",
        "efficiency": f"Eficiencia de Euler: {metrics.euler_efficiency:.2%}",
        "summary": (
            "Topolog√≠a √≥ptima para auditor√≠a." if metrics.is_simply_connected
            else "Requiere revisi√≥n de dependencias." if metrics.beta_1 > 0
            else "Estructura fragmentada, verificar integridad."
        ),
    }
