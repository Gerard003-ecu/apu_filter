### Propuesta 1

"""
═══════════════════════════════════════════════════════════════════════════════
PYRAMID OBSERVABILITY TEST SUITE
═══════════════════════════════════════════════════════════════════════════════

Arquitectura de Estratos (Fibración Algebraica):

    WISDOM (0)     ──┐
        ↑            │  Cada nivel es una "fibra" que proyecta
    STRATEGY (1)   ──┤  hacia el nivel superior. Los morfismos
        ↑            │  preservan invariantes topológicos.
    TACTICS (2)    ──┤
        ↑            │
    PHYSICS (3)    ──┘  Base de la pirámide (datos crudos)

Propiedades Matemáticas Verificadas:
    - Números de Betti: b₀ (componentes conexas), b₁ (ciclos independientes)
    - Característica de Euler: χ = V - E = b₀ - b₁
    - Invariante de conexidad: Grafo débilmente conexo
    - Propiedad DAG: Sin ciclos dirigidos

═══════════════════════════════════════════════════════════════════════════════
"""

import pytest
from unittest.mock import MagicMock, patch
import networkx as nx
from datetime import datetime
from typing import Dict, List, Tuple, Optional, NamedTuple
from dataclasses import dataclass, field
from enum import IntEnum

from app.schemas import Stratum
from agent.apu_agent import AutonomousAgent, SystemStatus
from app.telemetry_narrative import TelemetryNarrator
from app.telemetry import TelemetryContext, StepStatus, TelemetrySpan
from app.topology_viz import convert_graph_to_cytoscape_elements, AnomalyData


# ═══════════════════════════════════════════════════════════════════════════════
# DOMAIN MODELS FOR TESTING
# ═══════════════════════════════════════════════════════════════════════════════

class StratumLevel(IntEnum):
    """
    Mapeo de estratos a niveles jerárquicos.
    
    La estructura sigue una fibración donde cada nivel
    proyecta hacia el nivel superior mediante un morfismo
    que preserva la coherencia estructural.
    """
    WISDOM = 0      # Síntesis final - punto fijo del funtor
    STRATEGY = 1    # Decisiones de alto nivel
    TACTICS = 2     # Operaciones y cálculos
    PHYSICS = 3     # Datos crudos y sensores


class BettiNumbers(NamedTuple):
    """
    Números de Betti para caracterización topológica.
    
    Para un complejo simplicial K:
    - b₀: dim(H₀(K)) = componentes conexas
    - b₁: dim(H₁(K)) = "agujeros" o ciclos independientes
    
    Teorema: Para un árbol, b₀ = 1 y b₁ = 0
    """
    b0: int
    b1: int
    
    @property
    def euler_characteristic(self) -> int:
        """χ = b₀ - b₁ (para complejos 1-dimensionales)"""
        return self.b0 - self.b1
    
    @property
    def is_tree_topology(self) -> bool:
        """Verifica si corresponde a topología de árbol."""
        return self.b0 == 1 and self.b1 == 0


@dataclass
class PhysicsMetrics:
    """Métricas del estrato físico (FluxCondenser)."""
    voltage: float
    saturation: float
    
    @property
    def status(self) -> str:
        """Determina estado basado en umbrales."""
        if self.voltage > 0.7 or self.saturation > 0.8:
            return "CRITICAL"
        elif self.voltage > 0.5 or self.saturation > 0.6:
            return "WARNING"
        return "NOMINAL"


@dataclass
class TopologyHealth:
    """Estado de salud topológica del sistema."""
    betti: BettiNumbers
    is_connected: bool
    health_score: float = 1.0
    
    def validate_consistency(self) -> bool:
        """
        Verifica consistencia lógica.
        
        Invariante: Si b₀ = 1 entonces is_connected debe ser True
        """
        if self.betti.b0 == 1:
            return self.is_connected
        return not self.is_connected


@dataclass 
class HierarchicalNode:
    """Nodo en la jerarquía del grafo."""
    id: str
    node_type: str
    level: int
    description: str = ""


# ═══════════════════════════════════════════════════════════════════════════════
# TEST HELPERS
# ═══════════════════════════════════════════════════════════════════════════════

class CytoscapeElementParser:
    """Utilidades para parsear elementos Cytoscape."""
    
    @staticmethod
    def extract_node_ids(elements: List[Dict]) -> List[str]:
        """Extrae IDs de nodos (elementos sin 'source')."""
        return [
            e['data']['id']
            for e in elements
            if 'source' not in e['data']
        ]
    
    @staticmethod
    def extract_edges(elements: List[Dict]) -> List[Tuple[str, str]]:
        """Extrae pares (source, target) de aristas."""
        return [
            (e['data']['source'], e['data']['target'])
            for e in elements
            if 'source' in e['data']
        ]
    
    @staticmethod
    def reconstruct_graph(elements: List[Dict]) -> nx.DiGraph:
        """Reconstruye un DiGraph desde elementos Cytoscape."""
        G = nx.DiGraph()
        node_ids = CytoscapeElementParser.extract_node_ids(elements)
        edges = CytoscapeElementParser.extract_edges(elements)
        G.add_nodes_from(node_ids)
        G.add_edges_from(edges)
        return G


class SpanFactory:
    """Factory para crear TelemetrySpans de prueba."""
    
    @staticmethod
    def create(
        name: str,
        stratum: Stratum,
        status: StepStatus,
        errors: Optional[List[Dict]] = None,
        level: int = 0
    ) -> TelemetrySpan:
        """
        Crea un span de telemetría con los parámetros dados.
        
        Args:
            name: Nombre identificador del span
            stratum: Estrato al que pertenece
            status: Estado de ejecución
            errors: Lista de errores (opcional)
            level: Profundidad en el árbol de spans
        """
        span = TelemetrySpan(name=name, level=level, stratum=stratum)
        span.status = status
        span.errors = errors or []
        return span
    
    @staticmethod
    def create_success(name: str, stratum: Stratum) -> TelemetrySpan:
        """Atajo para crear span exitoso."""
        return SpanFactory.create(name, stratum, StepStatus.SUCCESS)
    
    @staticmethod
    def create_failure(
        name: str,
        stratum: Stratum,
        error_message: str,
        error_type: str = "Error"
    ) -> TelemetrySpan:
        """Atajo para crear span fallido con error."""
        return SpanFactory.create(
            name=name,
            stratum=stratum,
            status=StepStatus.FAILURE,
            errors=[{"message": error_message, "type": error_type}]
        )


# ═══════════════════════════════════════════════════════════════════════════════
# TEST SUITE
# ═══════════════════════════════════════════════════════════════════════════════

class TestPyramidObservability:
    """
    Suite de pruebas para la observabilidad de la pirámide de estratos.
    
    Verifica que el sistema satisface los invariantes topológicos
    y la coherencia entre estratos siguiendo el principio de
    causalidad bottom-up.
    """

    # ═══════════════════════════════════════════════════════════════════
    # FIXTURES
    # ═══════════════════════════════════════════════════════════════════
    
    @pytest.fixture
    def mock_session(self):
        """Session HTTP mockeada para el agente."""
        with patch('agent.apu_agent.requests.Session') as session:
            yield session
    
    @pytest.fixture
    def agent(self, mock_session) -> AutonomousAgent:
        """
        Instancia del agente autónomo con dependencias mockeadas.
        
        El agente actúa como el "observador" en nuestro sistema,
        midiendo el estado de cada estrato.
        """
        agent = AutonomousAgent()
        agent.topology = MagicMock()
        return agent
    
    @pytest.fixture
    def narrator(self) -> TelemetryNarrator:
        """Narrador de telemetría para análisis de causa raíz."""
        return TelemetryNarrator()
    
    @pytest.fixture
    def anomaly_data(self) -> AnomalyData:
        """Datos de anomalías vacíos para pruebas base."""
        return AnomalyData()
    
    @pytest.fixture
    def hierarchical_graph(self) -> nx.DiGraph:
        """
        Grafo jerárquico de prueba que modela la estructura piramidal.
        
        Topología:
        ┌─────────────────────────────────────────┐
        │  PROJECT (L0)                           │
        │     │                                   │
        │     └──▶ CHAPTER_1 (L1)                 │
        │              │                          │
        │              └──▶ APU_1 (L2)            │
        │                      │                  │
        │                      └──▶ INSUMO_1 (L3) │
        └─────────────────────────────────────────┘
        
        Propiedades:
        - Es un árbol (b₀=1, b₁=0)
        - Es un DAG (sin ciclos dirigidos)
        - Cada arista va de nivel n a nivel n+1
        """
        G = nx.DiGraph()
        
        nodes = [
            HierarchicalNode("PROJECT", "BUDGET", StratumLevel.WISDOM, "Main Project"),
            HierarchicalNode("CHAPTER_1", "CHAPTER", StratumLevel.STRATEGY, "Foundations"),
            HierarchicalNode("APU_1", "APU", StratumLevel.TACTICS, "Concrete Activity"),
            HierarchicalNode("INSUMO_1", "INSUMO", StratumLevel.PHYSICS, "Material A"),
        ]
        
        for node in nodes:
            G.add_node(
                node.id,
                type=node.node_type,
                level=node.level,
                description=node.description
            )
        
        # Aristas: flujo descendente PROJECT → CHAPTER → APU → INSUMO
        edges = [
            ("PROJECT", "CHAPTER_1"),
            ("CHAPTER_1", "APU_1"),
            ("APU_1", "INSUMO_1"),
        ]
        G.add_edges_from(edges)
        
        return G
    
    @pytest.fixture
    def multi_branch_graph(self) -> nx.DiGraph:
        """
        Grafo con múltiples ramas para tests de complejidad.
        
        Topología:
                PROJECT
               /       \
          CHAPTER_1   CHAPTER_2
              |           |
           APU_1       APU_2
              |           |
          INSUMO_1   INSUMO_2
        
        Propiedades: b₀=1 (conexo), b₁=0 (árbol)
        """
        G = nx.DiGraph()
        
        nodes_data = [
            ("PROJECT", "BUDGET", 0),
            ("CHAPTER_1", "CHAPTER", 1),
            ("CHAPTER_2", "CHAPTER", 1),
            ("APU_1", "APU", 2),
            ("APU_2", "APU", 2),
            ("INSUMO_1", "INSUMO", 3),
            ("INSUMO_2", "INSUMO", 3),
        ]
        
        for node_id, node_type, level in nodes_data:
            G.add_node(node_id, type=node_type, level=level)
        
        edges = [
            ("PROJECT", "CHAPTER_1"),
            ("PROJECT", "CHAPTER_2"),
            ("CHAPTER_1", "APU_1"),
            ("CHAPTER_2", "APU_2"),
            ("APU_1", "INSUMO_1"),
            ("APU_2", "INSUMO_2"),
        ]
        G.add_edges_from(edges)
        
        return G

    # ═══════════════════════════════════════════════════════════════════
    # AGENT TESTS - Salud por Estrato
    # ═══════════════════════════════════════════════════════════════════
    
    class TestPhysicsStratum:
        """Tests para el estrato PHYSICS (base de la pirámide)."""
        
        @pytest.fixture
        def agent_with_mock(self, mock_session):
            """Agent con session mockeada."""
            with patch('agent.apu_agent.requests.Session'):
                yield AutonomousAgent()
        
        @pytest.mark.parametrize("voltage,saturation,expected_status", [
            (0.3, 0.5, "NOMINAL"),      # Operación normal
            (0.8, 0.9, "CRITICAL"),     # Sobrecarga crítica
            (0.0, 0.0, "NOMINAL"),      # Estado de reposo
            (0.55, 0.65, "WARNING"),    # Zona de advertencia
        ])
        def test_physics_health_status_mapping(
            self,
            agent_with_mock,
            voltage: float,
            saturation: float,
            expected_status: str
        ):
            """
            Verifica el mapeo correcto de métricas físicas a estados.
            
            El estrato PHYSICS implementa la función:
            f: (voltage, saturation) → {NOMINAL, WARNING, CRITICAL}
            """
            with patch.object(agent_with_mock, 'observe') as mock_observe:
                mock_telemetry = MagicMock()
                mock_telemetry.flyback_voltage = voltage
                mock_telemetry.saturation = saturation
                mock_observe.return_value = mock_telemetry
                
                health = agent_with_mock.get_stratum_health(Stratum.PHYSICS)
                
                assert health['stratum'] == 'PHYSICS'
                assert health['voltage'] == pytest.approx(voltage, rel=1e-6)
                assert health['saturation'] == pytest.approx(saturation, rel=1e-6)
                assert health['status'] in ['NOMINAL', 'WARNING', 'CRITICAL']
        
        def test_physics_metrics_boundary_conditions(self, agent_with_mock):
            """
            Verifica comportamiento en condiciones límite.
            
            Condiciones de borde:
            - voltage = 0.0 (mínimo)
            - voltage = 1.0 (máximo)
            - saturation transitando umbrales
            """
            boundary_cases = [
                (0.0, 0.0),   # Mínimo absoluto
                (1.0, 1.0),   # Máximo absoluto
                (0.5, 0.5),   # Punto medio
                (0.7, 0.8),   # Exactamente en umbral crítico
            ]
            
            for voltage, saturation in boundary_cases:
                with patch.object(agent_with_mock, 'observe') as mock_observe:
                    mock_telemetry = MagicMock()
                    mock_telemetry.flyback_voltage = voltage
                    mock_telemetry.saturation = saturation
                    mock_observe.return_value = mock_telemetry
                    
                    health = agent_with_mock.get_stratum_health(Stratum.PHYSICS)
                    
                    # Debe retornar estructura válida sin excepciones
                    assert 'stratum' in health
                    assert 'status' in health
    
    class TestTacticsStratum:
        """Tests para el estrato TACTICS (topología)."""
        
        @pytest.mark.parametrize("b0,b1,is_connected,is_valid_tree", [
            (1, 0, True, True),     # Árbol perfecto (topología ideal)
            (2, 0, False, False),   # Dos componentes desconectadas
            (1, 1, True, False),    # Contiene un ciclo
            (3, 2, False, False),   # Múltiples componentes con ciclos
        ])
        def test_tactics_betti_numbers_interpretation(
            self,
            mock_session,
            b0: int,
            b1: int,
            is_connected: bool,
            is_valid_tree: bool
        ):
            """
            Verifica la interpretación correcta de números de Betti.
            
            Teorema Fundamental:
            Para un grafo G con V vértices y E aristas:
            - b₀ = número de componentes conexas
            - b₁ = E - V + b₀ (ciclos independientes)
            - χ(G) = V - E = b₀ - b₁
            
            Para un árbol: b₀ = 1, b₁ = 0, χ = 1
            """
            with patch('agent.apu_agent.requests.Session'):
                agent = AutonomousAgent()
                agent.topology = MagicMock()
                
                mock_topo_health = MagicMock()
                mock_topo_health.betti.b0 = b0
                mock_topo_health.betti.b1 = b1
                mock_topo_health.betti.is_connected = is_connected
                mock_topo_health.health_score = 0.95 if is_valid_tree else 0.5
                agent.topology.get_topological_health.return_value = mock_topo_health
                
                health = agent.get_stratum_health(Stratum.TACTICS)
                
                assert health['stratum'] == 'TACTICS'
                assert health['betti_0'] == b0
                assert health['betti_1'] == b1
                assert health['is_connected'] is is_connected
                
                # Verificar invariantes matemáticos
                betti = BettiNumbers(b0=b0, b1=b1)
                assert betti.is_tree_topology == is_valid_tree
                
                # Verificar consistencia lógica
                topo_health = TopologyHealth(betti=betti, is_connected=is_connected)
                if b0 == 1:
                    assert topo_health.validate_consistency() == is_connected
    
    class TestStrategyStratum:
        """Tests para el estrato STRATEGY (decisiones)."""
        
        @pytest.mark.parametrize("status,decision,risk_expected", [
            (SystemStatus.NOMINAL, "HEARTBEAT", False),
            (SystemStatus.DEGRADED, "SCALE_DOWN", True),
            (SystemStatus.CRITICAL, "EMERGENCY_STOP", True),
        ])
        def test_strategy_risk_detection(
            self,
            mock_session,
            status: SystemStatus,
            decision: str,
            risk_expected: bool
        ):
            """
            Verifica la detección de riesgo en el estrato estratégico.
            
            La función de riesgo mapea:
            r: SystemStatus → {True, False}
            donde r(NOMINAL) = False, r(_) = True
            """
            with patch('agent.apu_agent.requests.Session'):
                agent = AutonomousAgent()
                agent._last_status = status
                agent._last_decision = MagicMock()
                agent._last_decision.name = decision
                
                health = agent.get_stratum_health(Stratum.STRATEGY)
                
                assert health['stratum'] == 'STRATEGY'
                assert health['risk_detected'] is risk_expected
                assert health['last_decision'] == decision
    
    class TestWisdomStratum:
        """Tests para el estrato WISDOM (síntesis)."""
        
        def test_wisdom_verdict_synthesis(self, mock_session):
            """
            Verifica la síntesis final en el estrato WISDOM.
            
            WISDOM actúa como el punto fijo del funtor de observabilidad:
            F(WISDOM) = colim(F(PHYSICS), F(TACTICS), F(STRATEGY))
            """
            with patch('agent.apu_agent.requests.Session'):
                agent = AutonomousAgent()
                
                health = agent.get_stratum_health(Stratum.WISDOM)
                
                assert health['stratum'] == 'WISDOM'
                assert health['verdict'] in ['NOMINAL', 'WARNING', 'CRITICAL', 'UNKNOWN']

    # ═══════════════════════════════════════════════════════════════════
    # TELEMETRY NARRATOR TESTS - Análisis de Causa Raíz
    # ═══════════════════════════════════════════════════════════════════
    
    class TestRootCauseAnalysis:
        """Tests para el análisis de causa raíz del narrador."""
        
        @pytest.fixture
        def narrator(self) -> TelemetryNarrator:
            return TelemetryNarrator()
        
        def test_root_cause_physics_failure(self, narrator):
            """
            Verifica detección de causa raíz en estrato PHYSICS.
            
            Principio: Un fallo en la base propaga errores hacia arriba.
            """
            context = TelemetryContext()
            context.root_spans = [
                SpanFactory.create_failure(
                    name="flux_condenser",
                    stratum=Stratum.PHYSICS,
                    error_message="High Voltage Detected",
                    error_type="PhysicsError"
                )
            ]
            
            root = narrator.get_root_cause_stratum(context)
            
            assert root == Stratum.PHYSICS
        
        def test_root_cause_tactics_when_physics_ok(self, narrator):
            """
            Verifica que TACTICS es causa raíz cuando PHYSICS está OK.
            
            Si la base está sana, el error se origina en un estrato superior.
            """
            context = TelemetryContext()
            context.root_spans = [
                SpanFactory.create_success("load_data", Stratum.PHYSICS),
                SpanFactory.create_failure(
                    name="calculate_costs",
                    stratum=Stratum.TACTICS,
                    error_message="Cycle detected in graph",
                    error_type="TopologyError"
                )
            ]
            
            root = narrator.get_root_cause_stratum(context)
            
            assert root == Stratum.TACTICS
        
        @pytest.mark.parametrize("failing_stratum,preceding_ok", [
            (Stratum.PHYSICS, []),
            (Stratum.TACTICS, [Stratum.PHYSICS]),
            (Stratum.STRATEGY, [Stratum.PHYSICS, Stratum.TACTICS]),
            (Stratum.WISDOM, [Stratum.PHYSICS, Stratum.TACTICS, Stratum.STRATEGY]),
        ])
        def test_root_cause_stratum_isolation(
            self,
            narrator,
            failing_stratum: Stratum,
            preceding_ok: List[Stratum]
        ):
            """
            Verifica el aislamiento de causa raíz para cada estrato.
            
            El algoritmo implementa búsqueda bottom-up:
            1. Ordenar spans por nivel de estrato (ascendente)
            2. El primer estrato con fallo es la causa raíz
            
            Esto modela la causalidad física donde los efectos
            propagan de niveles inferiores a superiores.
            """
            context = TelemetryContext()
            spans = []
            
            # Crear spans exitosos para estratos precedentes
            for stratum in preceding_ok:
                spans.append(SpanFactory.create_success(
                    f"operation_{stratum.name.lower()}",
                    stratum
                ))
            
            # Crear span fallido para el estrato objetivo
            spans.append(SpanFactory.create_failure(
                name=f"operation_{failing_stratum.name.lower()}",
                stratum=failing_stratum,
                error_message=f"Error in {failing_stratum.name}"
            ))
            
            context.root_spans = spans
            
            root = narrator.get_root_cause_stratum(context)
            
            assert root == failing_stratum
        
        def test_root_cause_with_multiple_failures(self, narrator):
            """
            Con múltiples fallos, debe identificar el de menor nivel.
            
            Si PHYSICS y TACTICS fallan, PHYSICS es la causa raíz
            (principio de causalidad ascendente).
            """
            context = TelemetryContext()
            context.root_spans = [
                SpanFactory.create_failure(
                    "sensor_read", Stratum.PHYSICS, "Sensor malfunction"
                ),
                SpanFactory.create_failure(
                    "route_calculation", Stratum.TACTICS, "Invalid graph state"
                ),
            ]
            
            root = narrator.get_root_cause_stratum(context)
            
            # PHYSICS tiene menor nivel, debe ser la causa raíz
            assert root == Stratum.PHYSICS

    # ═══════════════════════════════════════════════════════════════════
    # TOPOLOGY VISUALIZATION TESTS
    # ═══════════════════════════════════════════════════════════════════
    
    class TestTopologyFiltering:
        """Tests para el filtrado de visualización topológica."""
        
        @pytest.fixture
        def parser(self) -> CytoscapeElementParser:
            return CytoscapeElementParser()
        
        @pytest.mark.parametrize("stratum_filter,expected_nodes,excluded_nodes", [
            # PHYSICS (3): Solo nivel más bajo
            (3, ["INSUMO_1"], ["APU_1", "CHAPTER_1", "PROJECT"]),
            # TACTICS (2): Ventana de niveles 2-3
            (2, ["APU_1", "INSUMO_1"], ["CHAPTER_1", "PROJECT"]),
            # STRATEGY (1): Ventana de niveles 1-2
            (1, ["CHAPTER_1", "APU_1"], ["INSUMO_1", "PROJECT"]),
            # WISDOM (0): Ventana de niveles 0-1
            (0, ["PROJECT", "CHAPTER_1"], ["APU_1", "INSUMO_1"]),
        ])
        def test_stratum_node_filtering(
            self,
            hierarchical_graph,
            anomaly_data,
            parser,
            stratum_filter: int,
            expected_nodes: List[str],
            excluded_nodes: List[str]
        ):
            """
            Verifica el filtrado correcto de nodos por estrato.
            
            El filtrado implementa una ventana deslizante:
            filter(level=n) → {nodos con level ∈ [n, n+1]}
            
            Esto modela una restricción del funtor a una
            subcategoría de estratos adyacentes.
            """
            elements = convert_graph_to_cytoscape_elements(
                hierarchical_graph,
                anomaly_data,
                stratum_filter=stratum_filter
            )
            
            node_ids = parser.extract_node_ids(elements)
            
            for expected in expected_nodes:
                assert expected in node_ids, (
                    f"Nodo '{expected}' debería estar visible "
                    f"con stratum_filter={stratum_filter}"
                )
            
            for excluded in excluded_nodes:
                assert excluded not in node_ids, (
                    f"Nodo '{excluded}' NO debería estar visible "
                    f"con stratum_filter={stratum_filter}"
                )
        
        def test_no_filter_returns_all_nodes(
            self,
            hierarchical_graph,
            anomaly_data,
            parser
        ):
            """
            Sin filtro, se retorna el grafo completo.
            
            Esto representa el funtor identidad: F(G) = G
            """
            elements = convert_graph_to_cytoscape_elements(
                hierarchical_graph,
                anomaly_data,
                stratum_filter=None
            )
            
            node_ids = parser.extract_node_ids(elements)
            
            assert len(node_ids) == 4
            assert set(node_ids) == {"PROJECT", "CHAPTER_1", "APU_1", "INSUMO_1"}
        
        @pytest.mark.parametrize("stratum_filter", [0, 1, 2, 3, None])
        def test_edge_node_consistency(
            self,
            hierarchical_graph,
            anomaly_data,
            parser,
            stratum_filter: Optional[int]
        ):
            """
            Verifica que las aristas son consistentes con nodos visibles.
            
            Invariante del Subgrafo Inducido:
            ∀ arista (u,v) ∈ E': u ∈ V' ∧ v ∈ V'
            
            Donde V' y E' son los nodos y aristas del subgrafo filtrado.
            """
            elements = convert_graph_to_cytoscape_elements(
                hierarchical_graph,
                anomaly_data,
                stratum_filter=stratum_filter
            )
            
            node_ids = set(parser.extract_node_ids(elements))
            edges = parser.extract_edges(elements)
            
            for source, target in edges:
                assert source in node_ids, (
                    f"Arista ({source} → {target}) tiene origen "
                    f"fuera de nodos visibles con filter={stratum_filter}"
                )
                assert target in node_ids, (
                    f"Arista ({source} → {target}) tiene destino "
                    f"fuera de nodos visibles con filter={stratum_filter}"
                )
    
    class TestTopologyInvariants:
        """Tests para invariantes topológicos de la visualización."""
        
        @pytest.fixture
        def parser(self) -> CytoscapeElementParser:
            return CytoscapeElementParser()
        
        def test_hierarchical_edge_direction(
            self,
            hierarchical_graph,
            anomaly_data,
            parser
        ):
            """
            Verifica que las aristas siguen la dirección jerárquica.
            
            Invariante: ∀ arista (u,v): level(u) < level(v)
            
            Esto asegura que el grafo es un DAG con flujo descendente.
            """
            elements = convert_graph_to_cytoscape_elements(
                hierarchical_graph,
                anomaly_data,
                stratum_filter=None
            )
            
            node_levels = {
                node: data['level']
                for node, data in hierarchical_graph.nodes(data=True)
            }
            
            edges = parser.extract_edges(elements)
            
            for source, target in edges:
                source_level = node_levels[source]
                target_level = node_levels[target]
                
                assert source_level < target_level, (
                    f"Arista ({source} → {target}) viola orden jerárquico: "
                    f"level({source})={source_level} >= level({target})={target_level}"
                )
        
        def test_edge_level_adjacency(
            self,
            hierarchical_graph,
            anomaly_data,
            parser
        ):
            """
            Verifica que las aristas conectan niveles adyacentes.
            
            Invariante: ∀ arista (u,v): |level(v) - level(u)| = 1
            
            Esto asegura que no hay "saltos" en la jerarquía.
            """
            elements = convert_graph_to_cytoscape_elements(
                hierarchical_graph,
                anomaly_data,
                stratum_filter=None
            )
            
            node_levels = {
                node: data['level']
                for node, data in hierarchical_graph.nodes(data=True)
            }
            
            edges = parser.extract_edges(elements)
            
            for source, target in edges:
                level_diff = node_levels[target] - node_levels[source]
                
                assert level_diff == 1, (
                    f"Arista ({source} → {target}) salta niveles: "
                    f"diferencia = {level_diff}, esperado = 1"
                )
        
        def test_reconstructed_graph_is_dag(
            self,
            hierarchical_graph,
            anomaly_data,
            parser
        ):
            """
            Verifica que el grafo reconstruido es un DAG válido.
            
            Un DAG tiene las propiedades:
            1. Es dirigido (DiGraph)
            2. No contiene ciclos dirigidos
            """
            elements = convert_graph_to_cytoscape_elements(
                hierarchical_graph,
                anomaly_data,
                stratum_filter=None
            )
            
            G = parser.reconstruct_graph(elements)
            
            assert isinstance(G, nx.DiGraph)
            assert nx.is_directed_acyclic_graph(G), (
                "El grafo debe ser acíclico dirigido (DAG)"
            )
        
        def test_reconstructed_graph_connectivity(
            self,
            hierarchical_graph,
            anomaly_data,
            parser
        ):
            """
            Verifica la conectividad del grafo reconstruido.
            
            Para nuestra estructura jerárquica:
            - Debe ser débilmente conexo (ignorando direcciones)
            - b₀ = 1 (una sola componente)
            """
            elements = convert_graph_to_cytoscape_elements(
                hierarchical_graph,
                anomaly_data,
                stratum_filter=None
            )
            
            G = parser.reconstruct_graph(elements)
            
            assert nx.is_weakly_connected(G), (
                "El grafo jerárquico debe ser débilmente conexo"
            )
            
            # Verificar número de componentes (b₀)
            num_components = nx.number_weakly_connected_components(G)
            assert num_components == 1, (
                f"Esperado b₀=1 componente, encontrado {num_components}"
            )
    
    class TestMultiBranchGraph:
        """Tests con grafos de múltiples ramas."""
        
        @pytest.fixture
        def parser(self) -> CytoscapeElementParser:
            return CytoscapeElementParser()
        
        def test_multi_branch_preserves_tree_topology(
            self,
            multi_branch_graph,
            anomaly_data,
            parser
        ):
            """
            Verifica que grafos multi-rama mantienen topología de árbol.
            
            Un árbol con n nodos tiene exactamente n-1 aristas.
            """
            elements = convert_graph_to_cytoscape_elements(
                multi_branch_graph,
                anomaly_data,
                stratum_filter=None
            )
            
            node_ids = parser.extract_node_ids(elements)
            edges = parser.extract_edges(elements)
            
            n_nodes = len(node_ids)
            n_edges = len(edges)
            
            # Propiedad de árbol: |E| = |V| - 1
            assert n_edges == n_nodes - 1, (
                f"Para un árbol: |E| = |V| - 1. "
                f"Encontrado: |E|={n_edges}, |V|={n_nodes}"
            )
        
        def test_multi_branch_euler_characteristic(
            self,
            multi_branch_graph,
            anomaly_data,
            parser
        ):
            """
            Verifica la característica de Euler del grafo multi-rama.
            
            χ(G) = V - E = b₀ - b₁
            
            Para un árbol: χ = 1 (una componente, sin ciclos)
            """
            elements = convert_graph_to_cytoscape_elements(
                multi_branch_graph,
                anomaly_data,
                stratum_filter=None
            )
            
            node_ids = parser.extract_node_ids(elements)
            edges = parser.extract_edges(elements)
            
            euler_char = len(node_ids) - len(edges)
            
            # Para árbol conexo: χ = 1
            assert euler_char == 1, (
                f"Característica de Euler para árbol debe ser 1, "
                f"encontrado χ = {euler_char}"
            )

    # ═══════════════════════════════════════════════════════════════════
    # INTEGRATION TESTS - Coherencia Entre Componentes
    # ═══════════════════════════════════════════════════════════════════
    
    class TestCrossComponentIntegration:
        """Tests de integración entre componentes del sistema."""
        
        @pytest.fixture
        def narrator(self) -> TelemetryNarrator:
            return TelemetryNarrator()
        
        @pytest.fixture
        def parser(self) -> CytoscapeElementParser:
            return CytoscapeElementParser()
        
        def test_cascade_failure_detection(self, mock_session, narrator):
            """
            Verifica detección de fallos en cascada entre estratos.
            
            Escenario: Fallo en PHYSICS debe identificarse como
            causa raíz incluso si otros estratos también fallan.
            """
            with patch('agent.apu_agent.requests.Session'):
                agent = AutonomousAgent()
                
                with patch.object(agent, 'observe') as mock_observe:
                    # Simular condición crítica
                    mock_telemetry = MagicMock()
                    mock_telemetry.flyback_voltage = 0.95
                    mock_telemetry.saturation = 0.98
                    mock_observe.return_value = mock_telemetry
                    
                    physics_health = agent.get_stratum_health(Stratum.PHYSICS)
                    
                    # Crear contexto de telemetría reflejando el fallo
                    context = TelemetryContext()
                    context.root_spans = [
                        SpanFactory.create_failure(
                            "flux_overflow",
                            Stratum.PHYSICS,
                            f"Voltage critical: {physics_health['voltage']}"
                        )
                    ]
                    
                    root = narrator.get_root_cause_stratum(context)
                    
                    assert root == Stratum.PHYSICS
        
        def test_topology_health_visualization_consistency(
            self,
            mock_session,
            hierarchical_graph,
            anomaly_data,
            parser
        ):
            """
            Verifica consistencia entre salud topológica y visualización.
            
            Si el agente reporta b₀=1, b₁=0 (árbol), la visualización
            debe mostrar un grafo conexo sin ciclos.
            """
            with patch('agent.apu_agent.requests.Session'):
                agent = AutonomousAgent()
                agent.topology = MagicMock()
                
                # Configurar topología sana
                mock_topo_health = MagicMock()
                mock_topo_health.betti.b0 = 1
                mock_topo_health.betti.b1 = 0
                mock_topo_health.betti.is_connected = True
                agent.topology.get_topological_health.return_value = mock_topo_health
                
                tactics_health = agent.get_stratum_health(Stratum.TACTICS)
                
                # Verificar reporte del agente
                assert tactics_health['betti_0'] == 1
                assert tactics_health['betti_1'] == 0
                
                # Verificar consistencia con visualización
                elements = convert_graph_to_cytoscape_elements(
                    hierarchical_graph,
                    anomaly_data,
                    stratum_filter=None
                )
                
                G = parser.reconstruct_graph(elements)
                
                # El grafo visual debe ser conexo (b₀=1)
                assert nx.is_weakly_connected(G)
                
                # El grafo visual debe ser DAG (b₁=0 implica sin ciclos)
                assert nx.is_directed_acyclic_graph(G)
        
        def test_stratum_order_mathematical_consistency(self):
            """
            Verifica la consistencia matemática del orden de estratos.
            
            Los estratos forman un orden parcial:
            WISDOM < STRATEGY < TACTICS < PHYSICS
            
            Este orden induce una filtración sobre el espacio de estados.
            """
            stratum_values = {
                Stratum.WISDOM: StratumLevel.WISDOM,
                Stratum.STRATEGY: StratumLevel.STRATEGY,
                Stratum.TACTICS: StratumLevel.TACTICS,
                Stratum.PHYSICS: StratumLevel.PHYSICS,
            }
            
            # Verificar orden total
            ordered = sorted(stratum_values.items(), key=lambda x: x[1])
            expected_order = [
                Stratum.WISDOM,
                Stratum.STRATEGY,
                Stratum.TACTICS,
                Stratum.PHYSICS
            ]
            
            actual_order = [s for s, _ in ordered]
            
            assert actual_order == expected_order, (
                f"Orden de estratos incorrecto: {actual_order}"
            )
            
            # Verificar transitividad
            for i, (s1, l1) in enumerate(ordered):
                for s2, l2 in ordered[i+1:]:
                    assert l1 < l2, (
                        f"Violación de transitividad: "
                        f"{s1}({l1}) debería ser < {s2}({l2})"
                    )


### Propuesta 2

"""
Suite de Tests Refinada: Observabilidad del Sistema de Pirámide DIKW
======================================================================

Tests refinados para la observabilidad completa del sistema:
1. AutonomousAgent - Salud por estrato con análisis de integridad
2. TelemetryNarrator - Análisis de causa raíz con teoría de grafos de fallos
3. TopologyVisualizer - Filtrado y visualización con teoría de homología aplicada

Arquitectura de Tests Mejorada:
- TestAgentObservability: Análisis del agente con monitoreo proactivo
- TestNarratorRootCause: Teoría de grafos para análisis de fallos
- TestTopologyFiltering: Filtrado topológico con preservación de homología
- TestCrossStratumPropagation: Propagación de anomalías entre estratos
- TestObservabilityMetrics: Métricas cuantitativas de observabilidad

Principios Matemáticos Aplicados:
- Teoría de grafos para análisis de fallos
- Homología algebraica para filtrado topológico
- Teoría de información para métricas de observabilidad
- Análisis de propagación basado en cadenas de Markov
"""

from __future__ import annotations

import pytest
from unittest.mock import MagicMock, patch, PropertyMock
import networkx as nx
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set, Tuple, Any
import numpy as np
from collections import defaultdict

from app.schemas import Stratum
from agent.apu_agent import AutonomousAgent, SystemStatus
from app.telemetry_narrative import TelemetryNarrator, StratumTopology
from app.telemetry import TelemetryContext, StepStatus, TelemetrySpan
from app.topology_viz import convert_graph_to_cytoscape_elements, AnomalyData


# ============================================================================
# UTILIDADES AVANZADAS PARA TESTS
# ============================================================================

class ObservabilityTestUtils:
    """Utilidades avanzadas para tests de observabilidad."""
    
    @staticmethod
    def create_layered_telemetry_graph(
        failures_by_stratum: Dict[Stratum, int] = None,
        nesting_depth: int = 3,
        span_count: int = 10
    ) -> TelemetryContext:
        """
        Crea un grafo de telemetría en capas con fallos controlados.
        
        Args:
            failures_by_stratum: Diccionario de fallos por estrato
            nesting_depth: Profundidad máxima de anidamiento
            span_count: Número total de spans
        
        Returns:
            Contexto de telemetría estructurado
        """
        context = TelemetryContext()
        
        # Configuración por defecto: sin fallos
        if failures_by_stratum is None:
            failures_by_stratum = {}
        
        # Crear spans organizados por estrato
        strata_spans = defaultdict(list)
        
        for i in range(span_count):
            # Asignar estrato cíclicamente
            stratum_idx = i % len(Stratum)
            stratum = list(Stratum)[stratum_idx]
            
            # Crear span con anidamiento
            parent = None
            if i > 0 and nesting_depth > 1:
                parent_idx = (i - 1) % len(strata_spans[stratum])
                if strata_spans[stratum]:
                    parent = strata_spans[stratum][parent_idx]
            
            span = TelemetrySpan(
                name=f"{stratum.name.lower()}_span_{i}",
                level=nesting_depth - (i % nesting_depth) - 1,
                stratum=stratum
            )
            
            # Aplicar fallos según configuración
            if stratum in failures_by_stratum and i < failures_by_stratum[stratum]:
                span.status = StepStatus.FAILURE
                span.errors.append({
                    "message": f"Controlled failure in {stratum.name}",
                    "type": f"{stratum.name}Error",
                    "timestamp": datetime.utcnow().isoformat()
                })
            else:
                span.status = StepStatus.SUCCESS
            
            span.end_time = span.start_time + timedelta(milliseconds=100 + i * 10)
            
            # Registrar métricas simuladas
            span.metrics = {
                "processing_time": float(span.end_time - span.start_time),
                "memory_usage": 50.0 + i * 5.0,
                "success_rate": 0.95 if span.status == StepStatus.SUCCESS else 0.0
            }
            
            # Conectar con padre si existe
            if parent:
                parent.children.append(span)
            else:
                context.root_spans.append(span)
            
            strata_spans[stratum].append(span)
        
        return context
    
    @staticmethod
    def analyze_failure_propagation_graph(
        context: TelemetryContext,
        narrator: TelemetryNarrator
    ) -> Dict[Stratum, Dict[str, Any]]:
        """
        Analiza propagación de fallos usando teoría de grafos.
        
        Args:
            context: Contexto de telemetría
            narrator: Narrador para análisis
        
        Returns:
            Análisis de propagación por estrato
        """
        # Extraer grafo de dependencias de spans
        G = nx.DiGraph()
        node_data = {}
        
        def add_span_to_graph(span: TelemetrySpan, depth: int = 0):
            node_id = f"{span.stratum.name}_{id(span)}"
            G.add_node(node_id, 
                      stratum=span.stratum,
                      status=span.status,
                      depth=depth,
                      error_count=len(span.errors))
            node_data[node_id] = span
            
            for child in span.children:
                child_id = f"{child.stratum.name}_{id(child)}"
                G.add_edge(node_id, child_id)
                add_span_to_graph(child, depth + 1)
        
        for span in context.root_spans:
            add_span_to_graph(span)
        
        # Análisis de propagación por estrato
        propagation_analysis = {}
        
        for stratum in Stratum:
            # Filtrar nodos por estrato
            stratum_nodes = [n for n, d in G.nodes(data=True) 
                           if d['stratum'] == stratum]
            
            if not stratum_nodes:
                continue
            
            # Calcular métricas de propagación
            failed_nodes = [n for n in stratum_nodes 
                          if G.nodes[n]['status'] == StepStatus.FAILURE]
            
            # Análisis de vecindad (fallos que afectan estratos adyacentes)
            adjacent_failures = []
            for failed_node in failed_nodes:
                # Vecinos ascendentes y descendentes
                predecessors = list(G.predecessors(failed_node))
                successors = list(G.successors(failed_node))
                
                for neighbor in predecessors + successors:
                    if G.nodes[neighbor]['status'] == StepStatus.FAILURE:
                        adjacent_failures.append((failed_node, neighbor))
            
            # Coeficiente de clustering de fallos
            if len(stratum_nodes) > 1:
                subgraph = G.subgraph(stratum_nodes)
                try:
                    clustering = nx.average_clustering(nx.Graph(subgraph))
                except:
                    clustering = 0.0
            else:
                clustering = 0.0
            
            propagation_analysis[stratum] = {
                "total_nodes": len(stratum_nodes),
                "failed_nodes": len(failed_nodes),
                "failure_rate": len(failed_nodes) / len(stratum_nodes),
                "adjacent_failures": len(adjacent_failures),
                "clustering_coefficient": clustering,
                "propagation_risk": len(adjacent_failures) / max(1, len(failed_nodes))
            }
        
        return propagation_analysis
    
    @staticmethod
    def create_topological_test_graph(
        add_cycles: bool = False,
        disconnected_components: int = 1,
        anomaly_density: float = 0.1
    ) -> Tuple[nx.DiGraph, AnomalyData]:
        """
        Crea grafo topológico de prueba con características controladas.
        
        Args:
            add_cycles: Añadir ciclos dirigidos
            disconnected_components: Número de componentes conexos
            anomaly_density: Densidad de anomalías (0-1)
        
        Returns:
            Grafo y datos de anomalías
        """
        G = nx.DiGraph()
        anomaly_data = AnomalyData()
        
        # Crear componentes según parámetro
        nodes_per_component = 10
        total_nodes = disconnected_components * nodes_per_component
        
        for comp in range(disconnected_components):
            offset = comp * nodes_per_component
            
            # Crear jerarquía por componente
            for i in range(nodes_per_component):
                node_id = f"NODE_{offset + i}"
                
                # Asignar nivel/estrato (0=WISDOM, 3=PHYSICS)
                level = i % 4
                node_type = ["BUDGET", "CHAPTER", "APU", "INSUMO"][level]
                
                G.add_node(node_id, 
                          type=node_type,
                          level=level,
                          description=f"{node_type} {offset + i}",
                          component=comp)
                
                # Añadir anomalías según densidad
                if np.random.random() < anomaly_density:
                    anomaly_data.anomalous_nodes.add(node_id)
                    anomaly_data.node_scores[node_id] = np.random.uniform(0.7, 1.0)
            
            # Conectar nodos en jerarquía
            for i in range(nodes_per_component - 1):
                source = f"NODE_{offset + i}"
                target = f"NODE_{offset + i + 1}"
                
                # Conectar solo si el target está en estrato inferior
                if G.nodes[target]['level'] > G.nodes[source]['level']:
                    G.add_edge(source, target)
                
                # Añadir anomalías en aristas
                if np.random.random() < anomaly_density * 0.5:
                    edge_key = (source, target)
                    anomaly_data.anomalous_edges.add(edge_key)
                    anomaly_data.edge_scores[edge_key] = np.random.uniform(0.5, 0.9)
        
        # Añadir ciclos si se solicita
        if add_cycles and total_nodes >= 3:
            # Crear ciclo entre los primeros 3 nodos de nivel similar
            cycle_nodes = [f"NODE_{i}" for i in range(min(3, total_nodes))]
            for i in range(len(cycle_nodes)):
                G.add_edge(cycle_nodes[i], cycle_nodes[(i + 1) % len(cycle_nodes)])
        
        return G, anomaly_data
    
    @staticmethod
    def calculate_observability_metrics(
        agent_health: Dict[Stratum, Dict],
        propagation_analysis: Dict[Stratum, Dict],
        filtering_efficiency: Dict[int, Dict]
    ) -> Dict[str, Any]:
        """
        Calcula métricas cuantitativas de observabilidad del sistema.
        
        Args:
            agent_health: Salud por estrato del agente
            propagation_analysis: Análisis de propagación
            filtering_efficiency: Eficiencia de filtrado por estrato
        
        Returns:
            Métricas consolidadas de observabilidad
        """
        metrics = {
            "stratum_coverage": {},
            "detection_latency": {},
            "resolution_capability": {},
            "system_observability_score": 0.0
        }
        
        # Cobertura por estrato
        for stratum in Stratum:
            if stratum in agent_health and stratum in propagation_analysis:
                coverage = {
                    "health_monitoring": 1.0 if agent_health[stratum] else 0.0,
                    "failure_detection": propagation_analysis[stratum]["failure_rate"] > 0,
                    "propagation_tracking": propagation_analysis[stratum]["adjacent_failures"] > 0
                }
                metrics["stratum_coverage"][stratum.name] = coverage
        
        # Latencia de detección (simulada)
        for stratum in Stratum:
            if stratum in propagation_analysis:
                failure_rate = propagation_analysis[stratum]["failure_rate"]
                # Modelo: mayor tasa de fallos → menor latencia (mejor detección)
                detection_latency = max(0.1, 1.0 - failure_rate * 0.9)
                metrics["detection_latency"][stratum.name] = detection_latency
        
        # Capacidad de resolución
        resolution_scores = []
        for stratum_filter, efficiency in filtering_efficiency.items():
            if efficiency["nodes_preserved"] > 0:
                resolution = efficiency["anomalies_preserved"] / efficiency["nodes_preserved"]
                resolution_scores.append(resolution)
        
        if resolution_scores:
            metrics["resolution_capability"] = {
                "min": min(resolution_scores),
                "max": max(resolution_scores),
                "mean": np.mean(resolution_scores),
                "std": np.std(resolution_scores)
            }
        
        # Score global de observabilidad
        coverage_score = len(metrics["stratum_coverage"]) / len(Stratum)
        latency_score = np.mean(list(metrics["detection_latency"].values())) if metrics["detection_latency"] else 0.5
        resolution_score = metrics["resolution_capability"].get("mean", 0.5) if metrics["resolution_capability"] else 0.5
        
        metrics["system_observability_score"] = (
            coverage_score * 0.4 +
            latency_score * 0.3 +
            resolution_score * 0.3
        )
        
        return metrics


# ============================================================================
# TESTS REFINADOS: AGENTE AUTÓNOMO
# ============================================================================

class TestAgentObservabilityRefined:
    """Tests refinados para observabilidad del agente autónomo."""
    
    def test_agent_stratum_health_with_integrity_analysis(self):
        """
        Test mejorado: Salud por estrato con análisis de integridad.
        
        Verifica:
        1. Completitud de métricas por estrato
        2. Consistencia entre estados
        3. Propagación de estados entre estratos
        4. Integridad semántica de respuestas
        """
        agent = AutonomousAgent()
        
        # Mock completo del sistema
        with patch.object(agent, 'observe') as mock_observe, \
             patch.object(agent, 'topology', create=True) as mock_topology, \
             patch('agent.apu_agent.SystemStatus') as mock_system_status:
            
            # Configurar mocks por estrato
            mock_telemetry = MagicMock()
            mock_telemetry.flyback_voltage = 0.3
            mock_telemetry.saturation = 0.5
            mock_telemetry.integrity_score = 0.95
            mock_telemetry.timestamp = datetime.utcnow()
            mock_observe.return_value = mock_telemetry
            
            # Mock de salud topológica
            mock_topo_health = MagicMock()
            mock_topo_health.betti.b0 = 1
            mock_topo_health.betti.b1 = 0
            mock_topo_health.betti.is_connected = True
            mock_topo_health.betti.euler_characteristic = 1
            mock_topo_health.health_score = 0.95
            mock_topo_health.anomaly_count = 2
            mock_topology.get_topological_health.return_value = mock_topo_health
            
            # Mock de estado del sistema
            mock_system_status.NOMINAL = "NOMINAL"
            agent._last_status = mock_system_status.NOMINAL
            agent._last_decision = MagicMock()
            agent._last_decision.name = "HEARTBEAT"
            agent._last_decision.confidence = 0.88
            agent._last_decision.timestamp = datetime.utcnow()
            
            # Test por cada estrato con análisis de integridad
            test_cases = [
                (Stratum.PHYSICS, {
                    "required_fields": ["voltage", "saturation", "integrity", "timestamp"],
                    "range_checks": {
                        "voltage": (0.0, 1.0),
                        "saturation": (0.0, 1.0),
                        "integrity": (0.9, 1.0)  # Debe ser alta
                    }
                }),
                (Stratum.TACTICS, {
                    "required_fields": ["betti_0", "betti_1", "is_connected", "euler", "health_score"],
                    "invariants": [
                        lambda h: h["betti_0"] >= 0,
                        lambda h: h["betti_1"] >= 0,
                        lambda h: h["euler"] == h["betti_0"] - h["betti_1"],
                        lambda h: 0.0 <= h["health_score"] <= 1.0
                    ]
                }),
                (Stratum.STRATEGY, {
                    "required_fields": ["risk_detected", "last_decision", "confidence", "status_age"],
                    "consistency_checks": [
                        lambda h: not h["risk_detected"] or h["confidence"] < 0.7,
                        lambda h: h["last_decision"] in ["HEARTBEAT", "INTERVENE", "ESCALATE"]
                    ]
                }),
                (Stratum.WISDOM, {
                    "required_fields": ["verdict", "rationale", "certainty"],
                    "semantic_checks": [
                        lambda h: h["verdict"] in ["NOMINAL", "CAUTION", "CRITICAL"],
                        lambda h: h["certainty"] >= 0.0 and h["certainty"] <= 1.0,
                        lambda h: len(h["rationale"]) > 0 if h["verdict"] != "NOMINAL" else True
                    ]
                })
            ]
            
            results = {}
            for stratum, checks in test_cases:
                health = agent.get_stratum_health(stratum)
                results[stratum] = health
                
                # Verificar campos requeridos
                for field in checks["required_fields"]:
                    assert field in health, f"Campo requerido faltante: {field} en {stratum}"
                
                # Verificar rangos numéricos
                if "range_checks" in checks:
                    for field, (min_val, max_val) in checks["range_checks"].items():
                        if field in health and isinstance(health[field], (int, float)):
                            assert min_val <= health[field] <= max_val, \
                                f"Rango inválido para {field} en {stratum}: {health[field]}"
                
                # Verificar invariantes
                if "invariants" in checks:
                    for i, invariant in enumerate(checks["invariants"]):
                        assert invariant(health), f"Invariante {i} violado en {stratum}"
                
                # Verificar consistencia
                if "consistency_checks" in checks:
                    for i, check in enumerate(checks["consistency_checks"]):
                        assert check(health), f"Consistencia {i} violada en {stratum}"
                
                # Verificar semántica
                if "semantic_checks" in checks:
                    for i, check in enumerate(checks["semantic_checks"]):
                        assert check(health), f"Semántica {i} violada en {stratum}"
            
            # Análisis de propagación entre estratos
            self._analyze_stratum_propagation(results)
            
            return results
    
    def _analyze_stratum_propagation(self, health_results: Dict[Stratum, Dict]):
        """
        Analiza propagación de estados entre estratos.
        
        Args:
            health_results: Resultados de salud por estrato
        """
        # Verificar que problemas en estratos inferiores se propaguen hacia arriba
        problem_severity = {
            "NOMINAL": 0,
            "CAUTION": 1,
            "CRITICAL": 2
        }
        
        # Orden de estratos (base a cima)
        strata_order = [Stratum.PHYSICS, Stratum.TACTICS, Stratum.STRATEGY, Stratum.WISDOM]
        
        current_severity = 0
        for stratum in strata_order:
            if stratum in health_results:
                verdict = health_results[stratum].get("verdict", "NOMINAL")
                stratum_severity = problem_severity.get(verdict, 0)
                
                # La severidad no debe disminuir al subir (problemas se propagan)
                assert stratum_severity >= current_severity, \
                    f"Severidad disminuye en {stratum}: {current_severity} -> {stratum_severity}"
                
                current_severity = stratum_severity
    
    def test_agent_health_with_simulated_failures(self):
        """
        Test con fallos simulados para verificar detección y reporte.
        """
        agent = AutonomousAgent()
        
        # Configurar mocks para simular diferentes escenarios de fallo
        test_scenarios = [
            {
                "name": "physics_failure",
                "stratum": Stratum.PHYSICS,
                "simulate_failure": lambda: setattr(agent, '_last_status', SystemStatus.CRITICAL),
                "expected_health": {"status": "CRITICAL", "voltage": 0.8}  # Alto voltaje
            },
            {
                "name": "topology_failure",
                "stratum": Stratum.TACTICS,
                "simulate_failure": lambda: setattr(
                    MagicMock(), 'betti',
                    MagicMock(b0=0, b1=5, is_connected=False, euler_characteristic=-5)
                ),
                "expected_health": {"is_connected": False, "betti_1": 5}
            },
            {
                "name": "strategy_risk",
                "stratum": Stratum.STRATEGY,
                "simulate_failure": lambda: setattr(
                    agent, '_last_decision',
                    MagicMock(name="ESCALATE", confidence=0.3)
                ),
                "expected_health": {"risk_detected": True, "confidence": 0.3}
            },
            {
                "name": "wisdom_critical",
                "stratum": Stratum.WISDOM,
                "simulate_failure": lambda: setattr(
                    agent, '_last_status', SystemStatus.CRITICAL
                ),
                "expected_health": {"verdict": "CRITICAL", "certainty": 0.9}
            }
        ]
        
        for scenario in test_scenarios:
            with patch.object(agent, 'observe') as mock_observe, \
                 patch.object(agent, 'topology', create=True) as mock_topology:
                
                # Simular fallo
                scenario["simulate_failure"]()
                
                # Configurar mocks según escenario
                if scenario["stratum"] == Stratum.PHYSICS:
                    mock_telemetry = MagicMock()
                    mock_telemetry.flyback_voltage = 0.8  # Voltaje crítico
                    mock_telemetry.saturation = 0.9
                    mock_observe.return_value = mock_telemetry
                
                elif scenario["stratum"] == Stratum.TACTICS:
                    mock_topo_health = MagicMock()
                    mock_topo_health.betti.b0 = 0
                    mock_topo_health.betti.b1 = 5
                    mock_topo_health.betti.is_connected = False
                    mock_topo_health.betti.euler_characteristic = -5
                    mock_topo_health.health_score = 0.2
                    mock_topology.get_topological_health.return_value = mock_topo_health
                
                # Obtener salud
                health = agent.get_stratum_health(scenario["stratum"])
                
                # Verificar detección de fallo
                for key, expected_value in scenario["expected_health"].items():
                    assert key in health, f"Campo {key} no encontrado en {scenario['name']}"
                    assert health[key] == expected_value, \
                        f"Valor incorrecto para {key} en {scenario['name']}: {health[key]} != {expected_value}"


# ============================================================================
# TESTS REFINADOS: NARRADOR DE TELEMETRÍA
# ============================================================================

class TestNarratorRootCauseRefined:
    """Tests refinados para análisis de causa raíz del narrador."""
    
    def test_root_cause_with_graph_theory_analysis(self):
        """
        Análisis de causa raíz usando teoría de grafos.
        
        Construye grafos de fallos y aplica algoritmos para identificar:
        1. Nodos fuente de fallos
        2. Componentes conectados de fallos
        3. Centralidad de nodos en propagación
        """
        narrator = TelemetryNarrator()
        utils = ObservabilityTestUtils()
        
        # Escenario 1: Fallo único en PHYSICS
        context1 = utils.create_layered_telemetry_graph(
            failures_by_stratum={Stratum.PHYSICS: 1}
        )
        
        root1 = narrator.get_root_cause_stratum(context1)
        assert root1 == Stratum.PHYSICS, f"Causa raíz incorrecta: {root1}"
        
        # Análisis de propagación
        propagation1 = utils.analyze_failure_propagation_graph(context1, narrator)
        assert propagation1[Stratum.PHYSICS]["failed_nodes"] == 1
        assert propagation1[Stratum.PHYSICS]["propagation_risk"] == 0.0  # Aislado
        
        # Escenario 2: Fallos en cadena (PHYSICS → TACTICS)
        context2 = utils.create_layered_telemetry_graph(
            failures_by_stratum={Stratum.PHYSICS: 2, Stratum.TACTICS: 1}
        )
        
        root2 = narrator.get_root_cause_stratum(context2)
        # El fallo más bajo (PHYSICS) debería ser la causa raíz
        assert root2 == Stratum.PHYSICS, f"Causa raíz en cadena incorrecta: {root2}"
        
        propagation2 = utils.analyze_failure_propagation_graph(context2, narrator)
        # Debería haber propagación entre estratos
        assert propagation2[Stratum.PHYSICS]["adjacent_failures"] > 0 or \
               propagation2[Stratum.TACTICS]["adjacent_failures"] > 0
        
        # Escenario 3: Fallos distribuidos con clustering
        context3 = utils.create_layered_telemetry_graph(
            failures_by_stratum={
                Stratum.PHYSICS: 3,
                Stratum.TACTICS: 2,
                Stratum.STRATEGY: 1
            }
        )
        
        root3 = narrator.get_root_cause_stratum(context3)
        # Con múltiples fallos, debería identificar el estrato base
        assert root3 == Stratum.PHYSICS, f"Causa raíz distribuida incorrecta: {root3}"
        
        propagation3 = utils.analyze_failure_propagation_graph(context3, narrator)
        
        # Verificar clustering de fallos
        for stratum in [Stratum.PHYSICS, Stratum.TACTICS]:
            if propagation3[stratum]["total_nodes"] > 1:
                clustering = propagation3[stratum]["clustering_coefficient"]
                # Con múltiples fallos cercanos, clustering debería ser > 0
                if propagation3[stratum]["failed_nodes"] > 1:
                    assert clustering > 0.0, \
                        f"Clustering cero con múltiples fallos en {stratum}"
        
        return {
            "scenario1": {"root": root1, "propagation": propagation1},
            "scenario2": {"root": root2, "propagation": propagation2},
            "scenario3": {"root": root3, "propagation": propagation3}
        }
    
    def test_root_cause_with_complex_nesting(self):
        """
        Test con anidamiento complejo y múltiples ramas de fallos.
        """
        narrator = TelemetryNarrator()
        context = TelemetryContext()
        
        # Crear estructura de árbol con múltiples ramas
        # Rama 1: PHYSICS → TACTICS → STRATEGY (todo exitoso)
        span_p1 = TelemetrySpan(name="physics_1", level=0, stratum=Stratum.PHYSICS)
        span_p1.status = StepStatus.SUCCESS
        
        span_t1 = TelemetrySpan(name="tactics_1", level=1, stratum=Stratum.TACTICS)
        span_t1.status = StepStatus.SUCCESS
        span_p1.children.append(span_t1)
        
        span_s1 = TelemetrySpan(name="strategy_1", level=2, stratum=Stratum.STRATEGY)
        span_s1.status = StepStatus.SUCCESS
        span_t1.children.append(span_s1)
        
        # Rama 2: PHYSICS (fallo) → TACTICS (fallo propagado)
        span_p2 = TelemetrySpan(name="physics_2", level=0, stratum=Stratum.PHYSICS)
        span_p2.status = StepStatus.FAILURE
        span_p2.errors.append({"message": "Critical physics failure", "type": "PhysicsError"})
        
        span_t2 = TelemetrySpan(name="tactics_2", level=1, stratum=Stratum.TACTICS)
        span_t2.status = StepStatus.FAILURE
        span_t2.errors.append({"message": "Propagated failure", "type": "TacticsError"})
        span_p2.children.append(span_t2)
        
        # Rama 3: PHYSICS (éxito) → TACTICS (éxito) → STRATEGY (fallo independiente)
        span_p3 = TelemetrySpan(name="physics_3", level=0, stratum=Stratum.PHYSICS)
        span_p3.status = StepStatus.SUCCESS
        
        span_t3 = TelemetrySpan(name="tactics_3", level=1, stratum=Stratum.TACTICS)
        span_t3.status = StepStatus.SUCCESS
        span_p3.children.append(span_t3)
        
        span_s3 = TelemetrySpan(name="strategy_3", level=2, stratum=Stratum.STRATEGY)
        span_s3.status = StepStatus.FAILURE
        span_s3.errors.append({"message": "Independent strategy failure", "type": "StrategyError"})
        span_t3.children.append(span_s3)
        
        context.root_spans = [span_p1, span_p2, span_p3]
        
        # Análisis de causa raíz
        root = narrator.get_root_cause_stratum(context)
        
        # Debería identificar PHYSICS como causa raíz (fallo más temprano)
        assert root == Stratum.PHYSICS, \
            f"Causa raíz en árbol complejo incorrecta: {root}. Esperado: PHYSICS"
        
        # Análisis de patrones de fallo
        failure_patterns = self._analyze_failure_patterns(context)
        
        # Verificar que se detecten múltiples patrones
        assert len(failure_patterns["isolated_failures"]) >= 1
        assert len(failure_patterns["propagation_chains"]) >= 1
        
        return {
            "root_cause": root,
            "failure_patterns": failure_patterns,
            "total_spans": len(context.root_spans) + 
                          sum(len(span.children) for span in context.root_spans) +
                          sum(len(span.children) for span in span_p1.children + 
                              span_p2.children + span_p3.children)
        }
    
    def _analyze_failure_patterns(self, context: TelemetryContext) -> Dict[str, List]:
        """
        Analiza patrones de fallo en el contexto.
        
        Args:
            context: Contexto de telemetría
        
        Returns:
            Patrones de fallo identificados
        """
        patterns = {
            "isolated_failures": [],  # Fallos sin propagación
            "propagation_chains": [],  # Cadenas de propagación
            "clustered_failures": []   # Grupos de fallos cercanos
        }
        
        # Recorrer árbol de spans
        def analyze_span(span: TelemetrySpan, path: List[str] = None):
            if path is None:
                path = []
            
            current_path = path + [span.name]
            
            if span.status == StepStatus.FAILURE:
                # Verificar si tiene hijos fallidos (propagación)
                child_failures = [c for c in span.children if c.status == StepStatus.FAILURE]
                
                if child_failures:
                    patterns["propagation_chains"].append({
                        "root": span.name,
                        "stratum": span.stratum.name,
                        "path": current_path,
                        "propagation_depth": len(child_failures)
                    })
                else:
                    patterns["isolated_failures"].append({
                        "span": span.name,
                        "stratum": span.stratum.name,
                        "path": current_path
                    })
            
            # Analizar hijos
            for child in span.children:
                analyze_span(child, current_path)
        
        for span in context.root_spans:
            analyze_span(span)
        
        # Identificar clusters (fallos cercanos en el árbol)
        all_failures = []
        def collect_failures(span: TelemetrySpan, depth: int = 0):
            if span.status == StepStatus.FAILURE:
                all_failures.append((span.name, span.stratum, depth))
            for child in span.children:
                collect_failures(child, depth + 1)
        
        for span in context.root_spans:
            collect_failures(span)
        
        # Agrupar fallos por profundidad y estrato
        from collections import defaultdict
        depth_groups = defaultdict(list)
        for name, stratum, depth in all_failures:
            depth_groups[depth].append((name, stratum))
        
        for depth, failures in depth_groups.items():
            if len(failures) >= 2:  # Múltiples fallos a misma profundidad
                patterns["clustered_failures"].append({
                    "depth": depth,
                    "failures": failures,
                    "count": len(failures)
                })
        
        return patterns


# ============================================================================
# TESTS REFINADOS: FILTRADO TOPOLÓGICO
# ============================================================================

class TestTopologyFilteringRefined:
    """Tests refinados para filtrado topológico con preservación de homología."""
    
    def test_filtering_with_homology_preservation(self):
        """
        Test de filtrado que preserva propiedades homológicas.
        
        Verifica que el filtrado por estrato mantenga:
        1. Conectividad de componentes
        2. Número de Betti (β₀, β₁)
        3. Característica de Euler
        4. Anomalías relevantes
        """
        utils = ObservabilityTestUtils()
        
        # Crear grafo de prueba con estructura conocida
        G, anomaly_data = utils.create_topological_test_graph(
            add_cycles=True,
            disconnected_components=2,
            anomaly_density=0.2
        )
        
        # Calcular propiedades homológicas originales
        original_properties = self._calculate_homological_properties(G)
        
        # Test para cada filtro de estrato
        filtering_results = {}
        
        for stratum_filter in [None, 0, 1, 2, 3]:
            elements = convert_graph_to_cytoscape_elements(
                G, anomaly_data, stratum_filter=stratum_filter
            )
            
            # Reconstruir grafo filtrado
            filtered_nodes = [e['data']['id'] for e in elements 
                            if 'source' not in e['data']]
            filtered_edges = [(e['data']['source'], e['data']['target']) 
                            for e in elements if 'source' in e['data']]
            
            G_filtered = nx.DiGraph()
            for node in filtered_nodes:
                G_filtered.add_node(node, **G.nodes[node])
            for source, target in filtered_edges:
                G_filtered.add_edge(source, target)
            
            # Calcular propiedades del grafo filtrado
            filtered_properties = self._calculate_homological_properties(G_filtered)
            
            # Verificar preservación según filtro
            if stratum_filter is not None:
                # Todos los nodos filtrados deben tener nivel >= stratum_filter
                for node in filtered_nodes:
                    node_level = G.nodes[node].get('level', 0)
                    assert node_level >= stratum_filter, \
                        f"Nodo con nivel {node_level} en filtro {stratum_filter}"
            
            # Verificar preservación de anomalías
            anomalies_preserved = len(anomaly_data.anomalous_nodes.intersection(set(filtered_nodes)))
            total_anomalies = len(anomaly_data.anomalous_nodes)
            
            filtering_results[stratum_filter] = {
                "nodes": len(filtered_nodes),
                "edges": len(filtered_edges),
                "anomalies_preserved": anomalies_preserved,
                "anomaly_preservation_rate": anomalies_preserved / max(1, total_anomalies),
                "homology_preserved": self._compare_homology(
                    original_properties, filtered_properties, stratum_filter
                ),
                "betti_0": filtered_properties["betti_0"],
                "betti_1": filtered_properties["betti_1"],
                "euler_characteristic": filtered_properties["euler_characteristic"]
            }
        
        # Análisis de eficiencia de filtrado
        efficiency_analysis = self._analyze_filtering_efficiency(filtering_results)
        
        # Verificar propiedades de filtrado
        self._validate_filtering_properties(filtering_results)
        
        return {
            "original_graph": {
                "nodes": G.number_of_nodes(),
                "edges": G.number_of_edges(),
                "components": original_properties["components"],
                "betti_0": original_properties["betti_0"],
                "betti_1": original_properties["betti_1"]
            },
            "filtering_results": filtering_results,
            "efficiency_analysis": efficiency_analysis
        }
    
    def _calculate_homological_properties(self, G: nx.DiGraph) -> Dict[str, Any]:
        """Calcula propiedades homológicas de un grafo."""
        # Para grafos dirigidos, convertimos a no dirigido para análisis homológico
        if G.is_directed():
            G_undirected = G.to_undirected()
        else:
            G_undirected = G
        
        # Número de componentes conexos (β₀)
        components = list(nx.connected_components(G_undirected))
        betti_0 = len(components)
        
        # Número de ciclos (β₁) aproximado
        # Para grafos: β₁ = |E| - |V| + |C|
        betti_1 = G_undirected.number_of_edges() - G_undirected.number_of_nodes() + betti_0
        betti_1 = max(0, betti_1)  # No negativo
        
        # Característica de Euler
        euler_characteristic = betti_0 - betti_1
        
        return {
            "components": components,
            "betti_0": betti_0,
            "betti_1": betti_1,
            "euler_characteristic": euler_characteristic,
            "nodes": G_undirected.number_of_nodes(),
            "edges": G_undirected.number_of_edges()
        }
    
    def _compare_homology(self, original: Dict, filtered: Dict, stratum_filter: int) -> bool:
        """
        Compara propiedades homológicas después del filtrado.
        
        Args:
            original: Propiedades originales
            filtered: Propiedades filtradas
            stratum_filter: Nivel de filtrado
        
        Returns:
            True si se preservan propiedades clave
        """
        # Para filtros estrictos, permitimos cambios en homología
        if stratum_filter is not None and stratum_filter >= 2:
            # Filtros altos pueden cambiar conectividad
            return True
        
        # Para filtros bajos o sin filtro, preservar componentes
        if original["betti_0"] > 0 and filtered["betti_0"] == 0:
            return False  # Perdimos todos los componentes
        
        # Preservar signo de característica de Euler para estructuras básicas
        if original["euler_characteristic"] > 0 and filtered["euler_characteristic"] <= 0:
            return False
        
        return True
    
    def _analyze_filtering_efficiency(self, filtering_results: Dict) -> Dict[str, Any]:
        """Analiza eficiencia del filtrado por estrato."""
        efficiencies = []
        
        for stratum, results in filtering_results.items():
            if stratum is not None and "nodes" in results and results["nodes"] > 0:
                # Eficiencia: anomalías preservadas por nodo
                efficiency = results["anomalies_preserved"] / results["nodes"]
                efficiencies.append({
                    "stratum": stratum,
                    "efficiency": efficiency,
                    "anomaly_rate": results["anomaly_preservation_rate"],
                    "node_reduction": 1.0 - (results["nodes"] / filtering_results[None]["nodes"])
                })
        
        if efficiencies:
            avg_efficiency = np.mean([e["efficiency"] for e in efficiencies])
            avg_anomaly_rate = np.mean([e["anomaly_rate"] for e in efficiencies])
            avg_reduction = np.mean([e["node_reduction"] for e in efficiencies])
        else:
            avg_efficiency = avg_anomaly_rate = avg_reduction = 0.0
        
        return {
            "per_stratum": efficiencies,
            "average_efficiency": avg_efficiency,
            "average_anomaly_rate": avg_anomaly_rate,
            "average_node_reduction": avg_reduction,
            "optimal_stratum": max(efficiencies, key=lambda x: x["efficiency"])["stratum"] 
                              if efficiencies else None
        }
    
    def _validate_filtering_properties(self, filtering_results: Dict):
        """Valida propiedades matemáticas del filtrado."""
        
        # Propiedad 1: Monotonicidad
        # A mayor filtro, menos nodos (o igual)
        strata = [s for s in filtering_results.keys() if s is not None]
        strata.sort()
        
        prev_nodes = filtering_results[None]["nodes"]
        for stratum in strata:
            current_nodes = filtering_results[stratum]["nodes"]
            assert current_nodes <= prev_nodes, \
                f"Filtrado no monotónico: {stratum} tiene {current_nodes} > {prev_nodes}"
            prev_nodes = current_nodes
        
        # Propiedad 2: Preservación de anomalías proporcional
        # La tasa de preservación de anomalías debe ser >= tasa de preservación de nodos
        for stratum in strata:
            if filtering_results[stratum]["nodes"] > 0:
                node_preservation = filtering_results[stratum]["nodes"] / filtering_results[None]["nodes"]
                anomaly_preservation = filtering_results[stratum]["anomaly_preservation_rate"]
                
                # Permitir cierta tolerancia
                assert anomaly_preservation >= node_preservation * 0.7, \
                    f"Anomalías no preservadas en filtro {stratum}: " \
                    f"anomalías={anomaly_preservation:.2f}, nodos={node_preservation:.2f}"
        
        # Propiedad 3: Consistencia de Betti numbers
        # β₁ no puede aumentar sin aumentar β₀ significativamente
        for stratum in strata:
            betti_0 = filtering_results[stratum]["betti_0"]
            betti_1 = filtering_results[stratum]["betti_1"]
            
            # Para grafos conexos: β₁ ≤ |E| - |V| + 1
            max_betti_1 = filtering_results[stratum]["edges"] - filtering_results[stratum]["nodes"] + betti_0
            assert betti_1 <= max_betti_1, \
                f"β₁ inválido en filtro {stratum}: {betti_1} > {max_betti_1}"


# ============================================================================
# TESTS REFINADOS: PROPAGACIÓN CRUZADA DE ESTRATOS
# ============================================================================

class TestCrossStratumPropagationRefined:
    """Tests refinados para propagación de anomalías entre estratos."""
    
    def test_anomaly_propagation_analysis(self):
        """
        Analiza propagación de anomalías entre estratos usando cadenas de Markov.
        
        Modela la propagación como proceso estocástico donde:
        - Estados: Estratos (PHYSICS, TACTICS, STRATEGY, WISDOM)
        - Transiciones: Probabilidad de propagación entre estratos
        - Absorción: Estado WISDOM como absorbente (decisión final)
        """
        utils = ObservabilityTestUtils()
        
        # Crear múltiples escenarios de fallo
        scenarios = [
            {"name": "physics_origin", "failures": {Stratum.PHYSICS: 3}},
            {"name": "tactics_origin", "failures": {Stratum.TACTICS: 2}},
            {"name": "mixed_origin", "failures": {Stratum.PHYSICS: 2, Stratum.TACTICS: 1}},
            {"name": "widespread", "failures": {Stratum.PHYSICS: 1, Stratum.TACTICS: 1, 
                                              Stratum.STRATEGY: 1}}
        ]
        
        propagation_results = {}
        
        for scenario in scenarios:
            # Crear contexto con fallos específicos
            context = utils.create_layered_telemetry_graph(
                failures_by_stratum=scenario["failures"],
                span_count=20
            )
            
            # Analizar propagación
            narrator = TelemetryNarrator()
            propagation = utils.analyze_failure_propagation_graph(context, narrator)
            
            # Calcular matriz de transición estimada
            transition_matrix = self._estimate_transition_matrix(propagation)
            
            # Calcular estados absorbentes
            absorbing_probabilities = self._calculate_absorbing_probabilities(transition_matrix)
            
            # Simular propagación
            simulation_results = self._simulate_propagation(transition_matrix, iterations=1000)
            
            propagation_results[scenario["name"]] = {
                "propagation_analysis": propagation,
                "transition_matrix": transition_matrix,
                "absorbing_probabilities": absorbing_probabilities,
                "simulation_results": simulation_results,
                "summary": self._summarize_propagation_risk(propagation, absorbing_probabilities)
            }
        
        # Análisis comparativo
        comparative_analysis = self._compare_propagation_scenarios(propagation_results)
        
        # Verificar principios de propagación
        self._validate_propagation_principles(propagation_results)
        
        return {
            "scenarios": propagation_results,
            "comparative_analysis": comparative_analysis,
            "principles_validated": True
        }
    
    def _estimate_transition_matrix(self, propagation: Dict[Stratum, Dict]) -> np.ndarray:
        """Estima matriz de transición de Markov desde análisis de propagación."""
        # Mapeo de estratos a índices
        strata = [Stratum.PHYSICS, Stratum.TACTICS, Stratum.STRATEGY, Stratum.WISDOM]
        stratum_to_idx = {s: i for i, s in enumerate(strata)}
        
        # Inicializar matriz 4x4
        transition = np.zeros((4, 4))
        
        # Estimar transiciones basadas en fallos adyacentes
        for stratum, data in propagation.items():
            i = stratum_to_idx[stratum]
            
            # Probabilidad de permanecer en mismo estrato
            if data["total_nodes"] > 0:
                failure_rate = data["failure_rate"]
                transition[i, i] = 1.0 - failure_rate * 0.5  # Estimación
            
            # Probabilidad de propagar hacia arriba
            if stratum != Stratum.WISDOM:
                next_stratum_idx = i + 1
                propagation_risk = data["propagation_risk"]
                transition[i, next_stratum_idx] = propagation_risk * 0.8  # Estimación
            
            # Ajustar para que filas sumen 1
            row_sum = transition[i, :].sum()
            if row_sum > 0:
                transition[i, :] /= row_sum
            else:
                transition[i, i] = 1.0  # Estado absorbente
        
        # WISDOM es estado absorbente
        transition[3, :] = [0, 0, 0, 1]
        
        return transition
    
    def _calculate_absorbing_probabilities(self, transition_matrix: np.ndarray) -> np.ndarray:
        """Calcula probabilidades de absorción para cada estado."""
        # Estados transitorios: 0, 1, 2 (PHYSICS, TACTICS, STRATEGY)
        # Estado absorbente: 3 (WISDOM)
        
        Q = transition_matrix[:3, :3]  # Parte transitoria
        R = transition_matrix[:3, 3:]  # Parte absorbente
        
        # Matriz fundamental: (I - Q)^-1
        I = np.eye(3)
        fundamental = np.linalg.inv(I - Q)
        
        # Probabilidades de absorción
        absorbing_probs = fundamental @ R
        
        return absorbing_probs
    
    def _simulate_propagation(self, transition_matrix: np.ndarray, 
                             iterations: int = 1000) -> Dict[int, List]:
        """Simula propagación usando cadena de Markov."""
        strata = ["PHYSICS", "TACTICS", "STRATEGY", "WISDOM"]
        
        # Iniciar desde cada estrato (excepto WISDOM)
        results = {i: [] for i in range(3)}
        
        for start_state in range(3):
            for _ in range(iterations):
                state = start_state
                path = [state]
                
                while state != 3:  # Mientras no se absorba en WISDOM
                    # Transicionar según matriz
                    state = np.random.choice(4, p=transition_matrix[state, :])
                    path.append(state)
                
                results[start_state].append({
                    "absorption_time": len(path) - 1,  # Pasos hasta absorción
                    "path": path,
                    "absorbed_in": 3  # Siempre WISDOM
                })
        
        # Resumir resultados
        summary = {}
        for start_state, simulations in results.items():
            absorption_times = [s["absorption_time"] for s in simulations]
            summary[start_state] = {
                "stratum": strata[start_state],
                "mean_absorption_time": np.mean(absorption_times),
                "std_absorption_time": np.std(absorption_times),
                "min_absorption_time": min(absorption_times),
                "max_absorption_time": max(absorption_times),
                "absorption_probability": 1.0  # Siempre se absorbe en WISDOM
            }
        
        return summary
    
    def _summarize_propagation_risk(self, propagation: Dict, 
                                   absorbing_probs: np.ndarray) -> Dict[str, Any]:
        """Resume riesgo de propagación."""
        risk_summary = {}
        
        for i, stratum in enumerate([Stratum.PHYSICS, Stratum.TACTICS, Stratum.STRATEGY]):
            if stratum in propagation:
                risk_summary[stratum.name] = {
                    "immediate_failure_rate": propagation[stratum]["failure_rate"],
                    "propagation_risk": propagation[stratum]["propagation_risk"],
                    "absorption_probability": float(absorbing_probs[i, 0]),
                    "expected_impact": propagation[stratum]["failure_rate"] * 
                                     propagation[stratum]["propagation_risk"]
                }
        
        # Riesgo global
        immediate_risks = [v["immediate_failure_rate"] for v in risk_summary.values()]
        propagation_risks = [v["propagation_risk"] for v in risk_summary.values()]
        
        risk_summary["GLOBAL"] = {
            "mean_immediate_risk": np.mean(immediate_risks) if immediate_risks else 0.0,
            "max_immediate_risk": max(immediate_risks) if immediate_risks else 0.0,
            "mean_propagation_risk": np.mean(propagation_risks) if propagation_risks else 0.0,
            "max_propagation_risk": max(propagation_risks) if propagation_risks else 0.0,
            "system_vulnerability": np.mean(immediate_risks) * np.mean(propagation_risks) 
                                   if immediate_risks and propagation_risks else 0.0
        }
        
        return risk_summary
    
    def _compare_propagation_scenarios(self, propagation_results: Dict) -> Dict[str, Any]:
        """Compara escenarios de propagación."""
        comparisons = {}
        
        scenarios = list(propagation_results.keys())
        
        for i, scenario1 in enumerate(scenarios):
            for scenario2 in scenarios[i+1:]:
                key = f"{scenario1}_vs_{scenario2}"
                
                risk1 = propagation_results[scenario1]["summary"]["GLOBAL"]["system_vulnerability"]
                risk2 = propagation_results[scenario2]["summary"]["GLOBAL"]["system_vulnerability"]
                
                comparisons[key] = {
                    "risk_ratio": risk1 / max(risk2, 0.001),
                    "risk_difference": risk1 - risk2,
                    "more_risky": scenario1 if risk1 > risk2 else scenario2,
                    "comparison": "Similar" if abs(risk1 - risk2) < 0.1 else "Different"
                }
        
        return comparisons
    
    def _validate_propagation_principles(self, propagation_results: Dict):
        """Valida principios fundamentales de propagación."""
        
        # Principio 1: Monotonicidad de riesgo
        # El riesgo debería aumentar o mantenerse al propagarse hacia arriba
        for scenario, results in propagation_results.items():
            summary = results["summary"]
            
            if all(s in summary for s in ["PHYSICS", "TACTICS", "STRATEGY"]):
                risk_physics = summary["PHYSICS"]["expected_impact"]
                risk_tactics = summary["TACTICS"]["expected_impact"]
                risk_strategy = summary["STRATEGY"]["expected_impact"]
                
                # Riesgo no debe disminuir drásticamente al subir
                assert risk_tactics >= risk_physics * 0.5, \
                    f"Riesgo disminuye demasiado de PHYSICS a TACTICS en {scenario}"
                assert risk_strategy >= risk_tactics * 0.5, \
                    f"Riesgo disminuye demasiado de TACTICS a STRATEGY en {scenario}"
        
        # Principio 2: Absorción segura
        # Todas las cadenas deben absorberse en WISDOM eventualmente
        for scenario, results in propagation_results.items():
            for start_state in range(3):
                absorption_prob = results["simulation_results"][start_state]["absorption_probability"]
                assert abs(absorption_prob - 1.0) < 0.01, \
                    f"Absorción incompleta en {scenario} desde {start_state}"
        
        # Principio 3: Consistencia temporal
        # Tiempos de absorción deben ser razonables
        for scenario, results in propagation_results.items():
            for start_state in range(3):
                mean_time = results["simulation_results"][start_state]["mean_absorption_time"]
                assert 1.0 <= mean_time <= 20.0, \
                    f"Tiempo de absorción irreal en {scenario}: {mean_time}"


# ============================================================================
# TESTS REFINADOS: MÉTRICAS DE OBSERVABILIDAD
# ============================================================================

class TestObservabilityMetricsRefined:
    """Tests refinados para métricas cuantitativas de observabilidad."""
    
    def test_comprehensive_observability_metrics(self):
        """
        Calcula métricas completas de observabilidad del sistema.
        
        Métricas calculadas:
        1. Cobertura por estrato
        2. Latencia de detección
        3. Precisión de diagnóstico
        4. Completitud de trazas
        5. Eficiencia de filtrado
        """
        utils = ObservabilityTestUtils()
        
        # Ejecutar tests de otros componentes para obtener datos
        agent_test = TestAgentObservabilityRefined()
        narrator_test = TestNarratorRootCauseRefined()
        filtering_test = TestTopologyFilteringRefined()
        
        # 1. Datos del agente
        agent_health = agent_test.test_agent_stratum_health_with_integrity_analysis()
        
        # 2. Datos del narrador
        narrator_results = narrator_test.test_root_cause_with_graph_theory_analysis()
        
        # Extraer análisis de propagación
        propagation_analysis = {}
        for scenario, data in narrator_results.items():
            if "propagation" in data:
                # Combinar análisis de propagación de todos los escenarios
                for stratum, analysis in data["propagation"].items():
                    if stratum not in propagation_analysis:
                        propagation_analysis[stratum] = analysis
                    else:
                        # Promediar métricas de múltiples escenarios
                        for key in analysis:
                            if isinstance(analysis[key], (int, float)):
                                if key in propagation_analysis[stratum]:
                                    propagation_analysis[stratum][key] = (
                                        propagation_analysis[stratum][key] + analysis[key]
                                    ) / 2
                                else:
                                    propagation_analysis[stratum][key] = analysis[key]
        
        # 3. Datos de filtrado
        filtering_results = filtering_test.test_filtering_with_homology_preservation()
        
        # Extraer eficiencia de filtrado
        filtering_efficiency = {}
        for stratum_filter, results in filtering_results["filtering_results"].items():
            filtering_efficiency[stratum_filter] = {
                "nodes_preserved": results["nodes"],
                "anomalies_preserved": results["anomalies_preserved"],
                "efficiency": results["anomaly_preservation_rate"]
            }
        
        # 4. Calcular métricas consolidadas
        observability_metrics = utils.calculate_observability_metrics(
            agent_health,
            propagation_analysis,
            filtering_efficiency
        )
        
        # 5. Métricas adicionales específicas
        additional_metrics = self._calculate_additional_metrics(
            agent_health, narrator_results, filtering_results
        )
        
        observability_metrics.update(additional_metrics)
        
        # 6. Validar métricas
        self._validate_observability_metrics(observability_metrics)
        
        # 7. Generar reporte
        report = self._generate_observability_report(observability_metrics)
        
        return {
            "metrics": observability_metrics,
            "report": report,
            "summary": self._summarize_observability_status(observability_metrics)
        }
    
    def _calculate_additional_metrics(self, agent_health: Dict, 
                                     narrator_results: Dict,
                                     filtering_results: Dict) -> Dict[str, Any]:
        """Calcula métricas adicionales de observabilidad."""
        metrics = {}
        
        # 1. Consistencia entre componentes
        consistency_checks = []
        
        # Verificar que todos los estratos estén cubiertos
        strata_covered = set(agent_health.keys())
        consistency_checks.append({
            "check": "stratum_coverage",
            "passed": len(strata_covered) == len(Stratum),
            "details": f"Cubiertos {len(strata_covered)} de {len(Stratum)} estratos"
        })
        
        # 2. Precisión de diagnóstico
        # En narrator_results, verificar que causa raíz sea consistente
        root_causes = [data["root"] for data in narrator_results.values() 
                      if "root" in data]
        if root_causes:
            most_common = max(set(root_causes), key=root_causes.count)
            precision = root_causes.count(most_common) / len(root_causes)
            metrics["diagnostic_precision"] = precision
        
        # 3. Completitud de trazas
        # Basado en filtering_results, cuánta estructura se preserva
        original_nodes = filtering_results["original_graph"]["nodes"]
        preserved_at_wisdom = filtering_results["filtering_results"][0]["nodes"]
        trace_completeness = preserved_at_wisdom / original_nodes
        metrics["trace_completeness"] = trace_completeness
        
        # 4. Eficiencia de almacenamiento
        # Relación entre nodos preservados y anomalías detectadas
        total_preserved_nodes = sum(
            r["nodes"] for r in filtering_results["filtering_results"].values()
        )
        total_anomalies = sum(
            r["anomalies_preserved"] for r in filtering_results["filtering_results"].values()
        )
        
        if total_preserved_nodes > 0:
            storage_efficiency = total_anomalies / total_preserved_nodes
            metrics["storage_efficiency"] = storage_efficiency
        
        # 5. Tiempo de diagnóstico
        # Estimación basada en complejidad
        avg_nodes_per_stratum = original_nodes / len(Stratum)
        # Modelo simplificado: tiempo ∝ log(nodos)
        diagnostic_time = np.log(avg_nodes_per_stratum + 1) * 100  # ms
        metrics["estimated_diagnostic_time_ms"] = diagnostic_time
        
        metrics["consistency_checks"] = consistency_checks
        metrics["passed_checks"] = sum(1 for c in consistency_checks if c["passed"])
        metrics["total_checks"] = len(consistency_checks)
        
        return metrics
    
    def _validate_observability_metrics(self, metrics: Dict[str, Any]):
        """Valida que las métricas cumplan umbrales mínimos."""
        
        # Umbrales mínimos
        thresholds = {
            "system_observability_score": 0.7,
            "diagnostic_precision": 0.8,
            "trace_completeness": 0.6,
            "storage_efficiency": 0.3,
            "estimated_diagnostic_time_ms": 500.0  # máximo 500ms
        }
        
        violations = []
        
        for metric, threshold in thresholds.items():
            if metric in metrics:
                value = metrics[metric]
                if metric == "estimated_diagnostic_time_ms":
                    if value > threshold:
                        violations.append(f"{metric}: {value:.1f} > {threshold}")
                else:
                    if value < threshold:
                        violations.append(f"{metric}: {value:.3f} < {threshold}")
        
        # Verificar consistencia
        if "passed_checks" in metrics and "total_checks" in metrics:
            consistency_rate = metrics["passed_checks"] / metrics["total_checks"]
            if consistency_rate < 0.8:
                violations.append(f"Consistency: {consistency_rate:.1%} < 80%")
        
        assert len(violations) == 0, f"Umbrales violados:\n" + "\n".join(violations)
    
    def _generate_observability_report(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Genera reporte ejecutivo de observabilidad."""
        
        # Calcular grados de observabilidad
        observability_score = metrics.get("system_observability_score", 0.0)
        
        if observability_score >= 0.9:
            observability_level = "EXCELENTE"
            recommendation = "Sistema completamente observable, mantener configuración"
        elif observability_score >= 0.7:
            observability_level = "BUENO"
            recommendation = "Sistema bien observable, monitorear tendencias"
        elif observability_score >= 0.5:
            observability_level = "MODERADO"
            recommendation = "Observabilidad aceptable, considerar mejoras en cobertura"
        else:
            observability_level = "CRÍTICO"
            recommendation = "Observabilidad insuficiente, requeridas mejoras inmediatas"
        
        # Identificar áreas de mejora
        improvement_areas = []
        
        if metrics.get("trace_completeness", 1.0) < 0.7:
            improvement_areas.append("Completitud de trazas")
        
        if metrics.get("diagnostic_precision", 1.0) < 0.85:
            improvement_areas.append("Precisión diagnóstica")
        
        if metrics.get("storage_efficiency", 1.0) < 0.4:
            improvement_areas.append("Eficiencia de almacenamiento")
        
        # Estratificar por estrato
        stratum_performance = {}
        if "stratum_coverage" in metrics:
            for stratum, coverage in metrics["stratum_coverage"].items():
                score = sum(coverage.values()) / len(coverage)
                stratum_performance[stratum] = {
                    "score": score,
                    "status": "OK" if score >= 0.8 else "NEEDS_IMPROVEMENT"
                }
        
        report = {
            "timestamp": datetime.utcnow().isoformat(),
            "observability_level": observability_level,
            "overall_score": observability_score,
            "recommendation": recommendation,
            "improvement_areas": improvement_areas,
            "stratum_performance": stratum_performance,
            "key_metrics": {
                "diagnostic_precision": metrics.get("diagnostic_precision", 0.0),
                "trace_completeness": metrics.get("trace_completeness", 0.0),
                "storage_efficiency": metrics.get("storage_efficiency", 0.0),
                "diagnostic_latency_ms": metrics.get("estimated_diagnostic_time_ms", 0.0)
            },
            "validation_result": "PASS" if len(improvement_areas) == 0 else "WARN"
        }
        
        return report
    
    def _summarize_observability_status(self, metrics: Dict[str, Any]) -> Dict[str, Any]:
        """Genera resumen ejecutivo del estado de observabilidad."""
        
        report = metrics.get("report", {})
        
        summary = {
            "status": report.get("validation_result", "UNKNOWN"),
            "level": report.get("observability_level", "UNKNOWN"),
            "score": report.get("overall_score", 0.0),
            "strengths": [],
            "weaknesses": report.get("improvement_areas", []),
            "recommended_actions": []
        }
        
        # Identificar fortalezas
        key_metrics = report.get("key_metrics", {})
        for metric, value in key_metrics.items():
            if metric == "diagnostic_precision" and value >= 0.9:
                summary["strengths"].append("Alta precisión diagnóstica")
            elif metric == "trace_completeness" and value >= 0.8:
                summary["strengths"].append("Trazas completas")
            elif metric == "storage_efficiency" and value >= 0.5:
                summary["strengths"].append("Almacenamiento eficiente")
            elif metric == "diagnostic_latency_ms" and value <= 200:
                summary["strengths"].append("Baja latencia diagnóstica")
        
        # Recomendar acciones
        if summary["score"] < 0.7:
            summary["recommended_actions"].extend([
                "Aumentar cobertura de instrumentación",
                "Mejorar filtrado de datos irrelevantes",
                "Implementar análisis predictivo"
            ])
        
        if "diagnostic_precision" in key_metrics and key_metrics["diagnostic_precision"] < 0.8:
            summary["recommended_actions"].append("Mejorar algoritmos de diagnóstico de causa raíz")
        
        return summary


# ============================================================================
# EJECUCIÓN DE TESTS COMPLETOS
# ============================================================================

if __name__ == "__main__":
    """
    Ejecución completa de todos los tests refinados.
    """
    
    print("=" * 80)
    print("SUITE DE TESTS REFINADA: OBSERVABILIDAD DE PIRÁMIDE DIKW")
    print("=" * 80)
    
    # Instanciar tests
    agent_tests = TestAgentObservabilityRefined()
    narrator_tests = TestNarratorRootCauseRefined()
    filtering_tests = TestTopologyFilteringRefined()
    propagation_tests = TestCrossStratumPropagationRefined()
    metrics_tests = TestObservabilityMetricsRefined()
    
    results = {}
    
    try:
        print("\n1. Ejecutando tests de agente autónomo...")
        results["agent"] = agent_tests.test_agent_stratum_health_with_integrity_analysis()
        print("   ✓ Tests de agente completados")
        
        print("\n2. Ejecutando tests de análisis de causa raíz...")
        results["narrator"] = narrator_tests.test_root_cause_with_graph_theory_analysis()
        print("   ✓ Tests de narrador completados")
        
        print("\n3. Ejecutando tests de filtrado topológico...")
        results["filtering"] = filtering_tests.test_filtering_with_homology_preservation()
        print("   ✓ Tests de filtrado completados")
        
        print("\n4. Ejecutando tests de propagación cruzada...")
        results["propagation"] = propagation_tests.test_anomaly_propagation_analysis()
        print("   ✓ Tests de propagación completados")
        
        print("\n5. Ejecutando tests de métricas de observabilidad...")
        results["metrics"] = metrics_tests.test_comprehensive_observability_metrics()
        print("   ✓ Tests de métricas completados")
        
        # Resumen final
        print("\n" + "=" * 80)
        print("RESUMEN FINAL DE OBSERVABILIDAD")
        print("=" * 80)
        
        if "metrics" in results and "summary" in results["metrics"]:
            summary = results["metrics"]["summary"]
            print(f"Estado del sistema: {summary['status']}")
            print(f"Nivel de observabilidad: {summary['level']}")
            print(f"Puntuación total: {summary['score']:.3f}")
            
            if summary['strengths']:
                print("\nFortalezas:")
                for strength in summary['strengths']:
                    print(f"  • {strength}")
            
            if summary['weaknesses']:
                print("\nÁreas de mejora:")
                for weakness in summary['weaknesses']:
                    print(f"  • {weakness}")
            
            if summary['recommended_actions']:
                print("\nAcciones recomendadas:")
                for action in summary['recommended_actions']:
                    print(f"  • {action}")
        
        print("\n" + "=" * 80)
        print("✓ Todos los tests refinados completados exitosamente")
        print("=" * 80)
        
    except Exception as e:
        print(f"\n✗ Error durante la ejecución de tests: {e}")
        import traceback
        traceback.print_exc()
        raise